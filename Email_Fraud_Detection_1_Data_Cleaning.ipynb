{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40db824c",
   "metadata": {},
   "source": [
    "# Email Fraud Detection: Data Cleaning and Combining\n",
    "\n",
    "**By Ross Willett**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b5a8b0",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Email-Fraud-Detection:-Data-Cleaning-and-Combining\" data-toc-modified-id=\"Email-Fraud-Detection:-Data-Cleaning-and-Combining-1\">Email Fraud Detection: Data Cleaning and Combining</a></span><ul class=\"toc-item\"><li><span><a href=\"#Project-Introduction\" data-toc-modified-id=\"Project-Introduction-1.1\">Project Introduction</a></span></li><li><span><a href=\"#File-Introduction\" data-toc-modified-id=\"File-Introduction-1.2\">File Introduction</a></span></li><li><span><a href=\"#Retrieving-and-Analyzing-Data\" data-toc-modified-id=\"Retrieving-and-Analyzing-Data-1.3\">Retrieving and Analyzing Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Kaggle-&quot;Fraud-Email-Datasets&quot;\" data-toc-modified-id=\"Kaggle-&quot;Fraud-Email-Datasets&quot;-1.3.1\">Kaggle \"Fraud Email Datasets\"</a></span></li><li><span><a href=\"#Kaggle-&quot;Phishing-Email-Data-by-Type&quot;\" data-toc-modified-id=\"Kaggle-&quot;Phishing-Email-Data-by-Type&quot;-1.3.2\">Kaggle \"Phishing Email Data by Type\"</a></span></li><li><span><a href=\"#Academic-Torrents-Emails\" data-toc-modified-id=\"Academic-Torrents-Emails-1.3.3\">Academic Torrents Emails</a></span></li><li><span><a href=\"#Apache-&quot;Spam-Assassin&quot;-Corpus-Emails\" data-toc-modified-id=\"Apache-&quot;Spam-Assassin&quot;-Corpus-Emails-1.3.4\">Apache \"Spam Assassin\" Corpus Emails</a></span></li></ul></li><li><span><a href=\"#Data-Frame-Cleaning\" data-toc-modified-id=\"Data-Frame-Cleaning-1.4\">Data Frame Cleaning</a></span></li><li><span><a href=\"#Conclusions\" data-toc-modified-id=\"Conclusions-1.5\">Conclusions</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33b0a7",
   "metadata": {},
   "source": [
    "## Project Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd105d",
   "metadata": {},
   "source": [
    "Each year, individuals and organizations are victims of fraud which lead to significant personal or organizational losses. Many of these victims are first contacted by criminals through email. The objective of this project is to provide a proof of concept that natural language processing and machine learning could be used to classify fraudulent or non-fraudulent (\"Ham\") emails based on their text content. Such a classifier could then be implemented by email applications to help prevent their users from becoming victims of fraud."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2a203",
   "metadata": {},
   "source": [
    "**IMPORTANT NOTE:**\n",
    "\n",
    "Throughout this project non-fraudulent emails will often be referred to as \"ham\" emails, as this is a term often used to refer to regular email communications in email classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738e1323",
   "metadata": {},
   "source": [
    "## File Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7949dff",
   "metadata": {},
   "source": [
    "Due to the scarcity of email data online (likely due to privacy concerns), data from several sources will be retrieved, analyzed, combined and cleaned to produce a data set suitable for analysis and model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08cac9",
   "metadata": {},
   "source": [
    "## Retrieving and Analyzing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9b38ff",
   "metadata": {},
   "source": [
    "The retrieval and analysis of the several data sources used for this project is detailed in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649d1207",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rosswillett/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/rosswillett/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import matrix and data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import regex library\n",
    "import re\n",
    "\n",
    "# Import custom text transformers\n",
    "from TextTransformers import extract_HTML_text, get_word_count, extract_text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2edd2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Pandas to show more columns/rows\n",
    "pd.options.display.max_columns = 2000\n",
    "pd.options.display.max_rows = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48584abf",
   "metadata": {},
   "source": [
    "### Kaggle \"Fraud Email Datasets\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908ca9b",
   "metadata": {},
   "source": [
    "The first data set that will be examined for cleaning and use is the \"Fraud Email Datasets\". (Located at https://www.kaggle.com/datasets/pramodgupta92/fraud-email-datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eefc1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11929, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11929 entries, 0 to 11928\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    11928 non-null  object\n",
      " 1   Class   11929 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 186.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read data from fraud_email_ data set and look at shape and dataframe info\n",
    "fraud_df = pd.read_csv('./data/fraud_email_.csv')\n",
    "print(fraud_df.shape)\n",
    "print(fraud_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97787db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supply Quality China's EXCLUSIVE dimensions at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over. SidLet me know. Thx.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Friend,Greetings to you.I wish to accost ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not a surprising assessment from Embassy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Class\n",
       "0  Supply Quality China's EXCLUSIVE dimensions at...      1\n",
       "1                         over. SidLet me know. Thx.      0\n",
       "2  Dear Friend,Greetings to you.I wish to accost ...      1\n",
       "3  MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....      1\n",
       "4          Not a surprising assessment from Embassy.      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at content of data\n",
    "fraud_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a264c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6742\n",
       "1    5187\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at split between fraud and regular emails\n",
    "fraud_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed04267",
   "metadata": {},
   "source": [
    "Initial analysis of the fraud email data set reveals there is a sizable 11,929 rows of email text data with a classifier indicating whether the email is fraudulent or not. Although missing the email subject and \"from\" address is not ideal, this source contains a significant volume of data which would prove valuable for use in this project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861b9948",
   "metadata": {},
   "source": [
    "### Kaggle \"Phishing Email Data by Type\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07dcbe",
   "metadata": {},
   "source": [
    "The next data set that will be examined for use is the \"Phishing Email Data by Type\" data set. (Located at https://www.kaggle.com/datasets/charlottehall/phishing-email-data-by-type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c8efc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159 entries, 0 to 158\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Subject  157 non-null    object\n",
      " 1   Text     159 non-null    object\n",
      " 2   Type     159 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Pull the data set into a CSV and look at the shape and column info for the data frame\n",
    "fraud_2_df = pd.read_csv('./data/phishing_data_by_type.csv')\n",
    "print(fraud_2_df.shape)\n",
    "print(fraud_2_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2b60d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP</td>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URGENT ASSISTANCE /RELATIONSHIP (P)</td>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOD DAY TO YOU</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from Mrs.Johnson</td>\n",
       "      <td>Goodday Dear\\n\\n\\nI know this mail will come t...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Co-Operation</td>\n",
       "      <td>FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Subject  \\\n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP   \n",
       "1         URGENT ASSISTANCE /RELATIONSHIP (P)   \n",
       "2                             GOOD DAY TO YOU   \n",
       "3                            from Mrs.Johnson   \n",
       "4                                Co-Operation   \n",
       "\n",
       "                                                Text   Type  \n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...  Fraud  \n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...  Fraud  \n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...  Fraud  \n",
       "3  Goodday Dear\\n\\n\\nI know this mail will come t...  Fraud  \n",
       "4  FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...  Fraud  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first few entries of data set\n",
    "fraud_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90144357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraud               0.251572\n",
       "Phishing            0.251572\n",
       "Commercial Spam     0.251572\n",
       "False Positives     0.245283\n",
       "Name: Type, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the split for the content type\n",
    "fraud_2_df['Type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8403fdb",
   "metadata": {},
   "source": [
    "This data set contains only 159 documents but appears to contain a decent diversity of both phishing and fraud emails. It isn't ideal that there are also commercial spam emails since this may create an additional challenge for the identifier. As such, this data set may have to undergo additional cleaning but is likely worth including."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53e645",
   "metadata": {},
   "source": [
    "### Academic Torrents Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33ce78",
   "metadata": {},
   "source": [
    "The next data set is composed of the content which was extracted from phishing email files retrieved from https://academictorrents.com/details/a77cda9a9d89a60dbdfbe581adf6e2df9197995a. The \"from\" address, subject and content was extracted from all of the emails in each folder and compiled into one csv per folder using the `email_extractor.py` script created for this purpose. These files need to be compiled into a singular csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae669935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array to append data frames with contents to\n",
    "phishing_extract_array = []\n",
    "# Iterate from 1 to 5 since there are that many phishing extract files\n",
    "for i in range(1, 5):\n",
    "    # Read the data from each phishing extract csv and put it into a data frame\n",
    "    phishing_extract = pd.read_csv(f'./data/phishing_extract_{i}.csv')\n",
    "    # Append the data frame to the array of data frames\n",
    "    phishing_extract_array.append(phishing_extract)\n",
    "\n",
    "# Create a data frame to store the combined data frames\n",
    "combined_phishing_extract_df = pd.concat(phishing_extract_array) \n",
    "# Drop duplicates in phishing extract data frame\n",
    "combined_phishing_extract_df.drop_duplicates(inplace=True)\n",
    "# Save phishing extract data frame to csv\n",
    "combined_phishing_extract_df.to_csv('./data/phishing_eml_extract_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb56db1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2416, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>\"eBay support\" &lt;service@ebay.com&gt;</td>\n",
       "      <td>Notification of Limited Account Access  -- eBa...</td>\n",
       "      <td>home pay register sign in/out services site ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>\"NCUA Departamnet\" &lt;ncua-065-617-349@ncua.gov&gt;</td>\n",
       "      <td>Sincerely, NCUA Account Review Department !</td>\n",
       "      <td>Dear Federal Credit Union account holder, This...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1553</th>\n",
       "      <td>\"eBay Inc.\" &lt;member@eBay.com&gt;</td>\n",
       "      <td>IMPORTANT: Alert from eBay</td>\n",
       "      <td>Message from eBay Member eBay My Messages -- 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>\"Paypal@\" &lt;passwords@paypal.com&gt;</td>\n",
       "      <td>Additional email address added to your PayPal ...</td>\n",
       "      <td>Youve added an additional email address to you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>\"National City\" &lt;cservice.refp56839606tl.cm@na...</td>\n",
       "      <td>Secure Confirmation!</td>\n",
       "      <td>Dear National City business client: The Nation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>\"PayPal Security Center\" &lt;service@paypal.com&gt;</td>\n",
       "      <td>Notification of Limited Account Access</td>\n",
       "      <td>Dear Sir,PayPal is committed to maintaining a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>\"Alaska USA\" &lt;service@alaskausa.org&gt;</td>\n",
       "      <td>Alaska USA FCU Verify Your Account</td>\n",
       "      <td>AlaskaUSA Dear Valued Customer, Our new securi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>\"PayPal Billing And Security Center\" &lt;Billing@...</td>\n",
       "      <td>Update Your PayPal Account Information</td>\n",
       "      <td>PayPal - Log In Sign Up Log Out Help Protect Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>\"service-paypal \" &lt;service@intl.paypal.com&gt;</td>\n",
       "      <td>PayPal Anti Fraud Service</td>\n",
       "      <td>PayPal September 2006 Dear user of PayPal serv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>\"Chase Trust And Safety Department\" &lt;account@c...</td>\n",
       "      <td>Password Change Required</td>\n",
       "      <td>Untitled Document Password change required Dea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   from  \\\n",
       "2028                  \"eBay support\" <service@ebay.com>   \n",
       "2330     \"NCUA Departamnet\" <ncua-065-617-349@ncua.gov>   \n",
       "1553                      \"eBay Inc.\" <member@eBay.com>   \n",
       "1000                   \"Paypal@\" <passwords@paypal.com>   \n",
       "1883  \"National City\" <cservice.refp56839606tl.cm@na...   \n",
       "2054      \"PayPal Security Center\" <service@paypal.com>   \n",
       "597                \"Alaska USA\" <service@alaskausa.org>   \n",
       "339   \"PayPal Billing And Security Center\" <Billing@...   \n",
       "2237        \"service-paypal \" <service@intl.paypal.com>   \n",
       "799   \"Chase Trust And Safety Department\" <account@c...   \n",
       "\n",
       "                                                subject  \\\n",
       "2028  Notification of Limited Account Access  -- eBa...   \n",
       "2330        Sincerely, NCUA Account Review Department !   \n",
       "1553                         IMPORTANT: Alert from eBay   \n",
       "1000  Additional email address added to your PayPal ...   \n",
       "1883                               Secure Confirmation!   \n",
       "2054             Notification of Limited Account Access   \n",
       "597                  Alaska USA FCU Verify Your Account   \n",
       "339              Update Your PayPal Account Information   \n",
       "2237                          PayPal Anti Fraud Service   \n",
       "799                            Password Change Required   \n",
       "\n",
       "                                                content  \n",
       "2028  home pay register sign in/out services site ma...  \n",
       "2330  Dear Federal Credit Union account holder, This...  \n",
       "1553  Message from eBay Member eBay My Messages -- 1...  \n",
       "1000  Youve added an additional email address to you...  \n",
       "1883  Dear National City business client: The Nation...  \n",
       "2054  Dear Sir,PayPal is committed to maintaining a ...  \n",
       "597   AlaskaUSA Dear Valued Customer, Our new securi...  \n",
       "339   PayPal - Log In Sign Up Log Out Help Protect Y...  \n",
       "2237  PayPal September 2006 Dear user of PayPal serv...  \n",
       "799   Untitled Document Password change required Dea...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all phishing data from the saved csv into a data frame\n",
    "phishing_extract_df = pd.read_csv('./data/phishing_eml_extract_full.csv')\n",
    "# Look at data frame shape\n",
    "print(phishing_extract_df.shape)\n",
    "# Display data frame content\n",
    "phishing_extract_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3d371",
   "metadata": {},
   "source": [
    "The data from the extracted emails includes 2,416 documents including a from address, a subject and the email content entirely consisting of phishing emails. This will prove to be a useful sample for the complete data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed669764",
   "metadata": {},
   "source": [
    "### Apache \"Spam Assassin\" Corpus Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5dc4a9",
   "metadata": {},
   "source": [
    "The next data set is composed of the content which was extracted from ham email files retrieved from the Apache \"Spam Assassin\" corpus located [here](https://spamassassin.apache.org/old/publiccorpus/). Since these emails were in .eml format but lacked the .eml extension, the `eml_rename.py` script was used to change the files to the appropriate .eml file type. The from, subject and content was extracted from all of the emails in each folder and compiled into one csv per folder using the `email_extractor.py` script, created for this purpose. These files need to be compiled into a singular csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8514f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array to store extracted data frames to\n",
    "ham_extract_array = []\n",
    "# Iterate over the number of csvs the data was separately stored in\n",
    "for i in range(1, 4):\n",
    "    # Read the data from each csv into a data frame\n",
    "    ham_extract = pd.read_csv(f'./data/ham_extract_{i}.csv')\n",
    "    # Append the data frame to the array of data frames\n",
    "    ham_extract_array.append(ham_extract)\n",
    "\n",
    "# Combine all the data frames into a singular one\n",
    "combined_ham_extract_df = pd.concat(ham_extract_array)\n",
    "# Remove all duplicate data frames\n",
    "combined_ham_extract_df.drop_duplicates(inplace=True)\n",
    "# Save the combined data frame to a csv file\n",
    "combined_ham_extract_df.to_csv('./data/ham_eml_extract_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "123d5603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3303, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>Julian Missig &lt;julian@jabber.org&gt;</td>\n",
       "      <td>Re: Limbo beta 2 ?</td>\n",
       "      <td>I realize this is an old thread, but I just ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>Peter Peltonen &lt;peter.peltonen@iki.fi&gt;</td>\n",
       "      <td>Re: New testing packages</td>\n",
       "      <td>Content-Disposition: inline To view this newsl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>\"Jim Whitehead\" &lt;ejw@cse.ucsc.edu&gt;</td>\n",
       "      <td>RE: Goodbye Global Warming</td>\n",
       "      <td>I am delurking to comment on the Salon article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1737</th>\n",
       "      <td>\"timothy_hodkinson\" &lt;mephistopheles29@hotmail....</td>\n",
       "      <td>[zzzzteana] Re: Archer-UK TV Alert</td>\n",
       "      <td>I installed Spamassassin 2.41 with Razor V2 th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3261</th>\n",
       "      <td>\"Ayn Rand Institute Media\" &lt;davidh@aynrand.org&gt;</td>\n",
       "      <td>GOVERNMENT REGULATION IS KILLING THE STOCK MARKET</td>\n",
       "      <td>PRESS RELEASE FROM THE AYN RAND INSTITUTE 2121...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>\"Joseph S. Barrera III\" &lt;joe@barrera.org&gt;</td>\n",
       "      <td>Re: SimPastry</td>\n",
       "      <td>Jim Whitehead wrote: http://www.research.micro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>kevin lyda &lt;kevin+dated+1028163438.f677b3@linu...</td>\n",
       "      <td>Re: [ILUG] Optimizing for Pentium Pt.2</td>\n",
       "      <td>On Fri, Jul 26, 2002 at 11:24:30PM 0100, John ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>pudge@perl.org</td>\n",
       "      <td>[use Perl] Stories for 2002-09-03</td>\n",
       "      <td>Content-Disposition: inline To view this newsl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>\"Jim Whitehead\" &lt;ejw@cse.ucsc.edu&gt;</td>\n",
       "      <td>RE: USA USA WE ARE NUMBER ....six.</td>\n",
       "      <td>chris arkenberg wrote: Cheers, Adam. Perhaps p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>\"John Hall\" &lt;johnhall@evergo.net&gt;</td>\n",
       "      <td>RE: Our friends the Palestinians, Our servants...</td>\n",
       "      <td>I actually thought of this kind of active chat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   from  \\\n",
       "2236                  Julian Missig <julian@jabber.org>   \n",
       "291              Peter Peltonen <peter.peltonen@iki.fi>   \n",
       "1165                 \"Jim Whitehead\" <ejw@cse.ucsc.edu>   \n",
       "1737  \"timothy_hodkinson\" <mephistopheles29@hotmail....   \n",
       "3261    \"Ayn Rand Institute Media\" <davidh@aynrand.org>   \n",
       "1896          \"Joseph S. Barrera III\" <joe@barrera.org>   \n",
       "2284  kevin lyda <kevin+dated+1028163438.f677b3@linu...   \n",
       "494                                      pudge@perl.org   \n",
       "2916                 \"Jim Whitehead\" <ejw@cse.ucsc.edu>   \n",
       "63                    \"John Hall\" <johnhall@evergo.net>   \n",
       "\n",
       "                                                subject  \\\n",
       "2236                                 Re: Limbo beta 2 ?   \n",
       "291                            Re: New testing packages   \n",
       "1165                         RE: Goodbye Global Warming   \n",
       "1737                 [zzzzteana] Re: Archer-UK TV Alert   \n",
       "3261  GOVERNMENT REGULATION IS KILLING THE STOCK MARKET   \n",
       "1896                                      Re: SimPastry   \n",
       "2284             Re: [ILUG] Optimizing for Pentium Pt.2   \n",
       "494                   [use Perl] Stories for 2002-09-03   \n",
       "2916                 RE: USA USA WE ARE NUMBER ....six.   \n",
       "63    RE: Our friends the Palestinians, Our servants...   \n",
       "\n",
       "                                                content  \n",
       "2236  I realize this is an old thread, but I just ha...  \n",
       "291   Content-Disposition: inline To view this newsl...  \n",
       "1165  I am delurking to comment on the Salon article...  \n",
       "1737  I installed Spamassassin 2.41 with Razor V2 th...  \n",
       "3261  PRESS RELEASE FROM THE AYN RAND INSTITUTE 2121...  \n",
       "1896  Jim Whitehead wrote: http://www.research.micro...  \n",
       "2284  On Fri, Jul 26, 2002 at 11:24:30PM 0100, John ...  \n",
       "494   Content-Disposition: inline To view this newsl...  \n",
       "2916  chris arkenberg wrote: Cheers, Adam. Perhaps p...  \n",
       "63    I actually thought of this kind of active chat...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the combined data from a csv into a data frame\n",
    "combined_ham_extract_df = pd.read_csv('./data/ham_eml_extract_full.csv')\n",
    "# Display the shape and content of the data frame\n",
    "print(combined_ham_extract_df.shape)\n",
    "combined_ham_extract_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d0277",
   "metadata": {},
   "source": [
    "The data from the extracted emails includes 2,416 documents including a \"from\" address, a subject and the email content entirely consisting of non-fraudulent emails. This will prove to be a useful source of non-fraudulent emails for the combined data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d288d1",
   "metadata": {},
   "source": [
    "## Data Frame Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65178afd",
   "metadata": {},
   "source": [
    "Now that the data sets have been acquired and cursorily examined, the next step will be to format them in the same manner and combine them into a singular data set for further cleaning and analysis. Since the data is largely composed of documents that only have a flag indicating fraud and the content (77% of all data), the final data set should only be composed of text content and a flag indicating fraud. Given this, all the data sets will be transformed to a standard format with a `content` column with the email text and a `fraud` column with a 1 or 0 flag indicating whether it is fraud or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540fb6d8",
   "metadata": {},
   "source": [
    "For the first data set, the columns will only have to be renamed to prepare for combining the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c63f6d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clean data frame for first data set\n",
    "fraud_clean_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f62ed280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'content' column for clean data frame\n",
    "fraud_clean_df['content'] = fraud_df['Text']\n",
    "# Set 'fraud' column for clean data frame\n",
    "fraud_clean_df['fraud'] = np.where(\n",
    "    fraud_df['Class'] == 1,\n",
    "    1,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88024478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supply Quality China's EXCLUSIVE dimensions at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over. SidLet me know. Thx.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Friend,Greetings to you.I wish to accost ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not a surprising assessment from Embassy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  fraud\n",
       "0  Supply Quality China's EXCLUSIVE dimensions at...      1\n",
       "1                         over. SidLet me know. Thx.      0\n",
       "2  Dear Friend,Greetings to you.I wish to accost ...      1\n",
       "3  MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....      1\n",
       "4          Not a surprising assessment from Embassy.      0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the contents of the clean data frame\n",
    "fraud_clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316db21a",
   "metadata": {},
   "source": [
    "In the second data set there is a mix of fraud, phishing, ham and commercial spam email types. The commercial spam will be removed from the data set as this type doesn't strictly fall into either the ham or fraud category and will likely only make identification more difficult for any models trained on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3903866f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP</td>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URGENT ASSISTANCE /RELATIONSHIP (P)</td>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOD DAY TO YOU</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from Mrs.Johnson</td>\n",
       "      <td>Goodday Dear\\n\\n\\nI know this mail will come t...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Co-Operation</td>\n",
       "      <td>FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Subject  \\\n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP   \n",
       "1         URGENT ASSISTANCE /RELATIONSHIP (P)   \n",
       "2                             GOOD DAY TO YOU   \n",
       "3                            from Mrs.Johnson   \n",
       "4                                Co-Operation   \n",
       "\n",
       "                                                Text   Type  \n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...  Fraud  \n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...  Fraud  \n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...  Fraud  \n",
       "3  Goodday Dear\\n\\n\\nI know this mail will come t...  Fraud  \n",
       "4  FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...  Fraud  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the data contained in the second fraud data set\n",
    "fraud_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "013fdb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data frame to store the cleaned data from the second data set in\n",
    "fraud_2_clean_df = pd.DataFrame()\n",
    "# Set the content column to the text of the second data set\n",
    "fraud_2_clean_df['content'] = fraud_2_df['Text']\n",
    "# Set a 'fraud' column flagging the fraud vs normal emails from the fraud data set\n",
    "fraud_2_clean_df['fraud'] = np.where(\n",
    "    (fraud_2_df['Type'] == 'Fraud') | (fraud_2_df['Type'] == 'Phishing'),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "# Remove the data identified as 'Commercial Spam' from the data set\n",
    "fraud_2_clean_df = fraud_2_clean_df[fraud_2_df['Type'] != 'Commercial Spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43c215de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goodday Dear\\n\\n\\nI know this mail will come t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  fraud\n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...      1\n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...      1\n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...      1\n",
       "3  Goodday Dear\\n\\n\\nI know this mail will come t...      1\n",
       "4  FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine content of cleaned data\n",
    "fraud_2_clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef31afe",
   "metadata": {},
   "source": [
    "All the data from the phishing email collection can be classified as fraud and all columns except the email text content dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cd7e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new clean data frame\n",
    "fraud_3_clean_df = pd.DataFrame()\n",
    "# Assign the 'content' of the new data frame to the text content of the phishing data frame\n",
    "fraud_3_clean_df['content'] = phishing_extract_df['content']\n",
    "# Set the fraud column to 1 for this data frame since all entries are fraudulent\n",
    "fraud_3_clean_df['fraud'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f7589b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear valued PayPal member, Due to recent fraud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit Union is constantly working to ensure s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit Union is constantly working to ensure s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Untitled Document Dear eBay Member, We regret ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear valued PayPal member, Due to recent fraud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  fraud\n",
       "0  Dear valued PayPal member, Due to recent fraud...      1\n",
       "1  Credit Union is constantly working to ensure s...      1\n",
       "2  Credit Union is constantly working to ensure s...      1\n",
       "3  Untitled Document Dear eBay Member, We regret ...      1\n",
       "4  Dear valued PayPal member, Due to recent fraud...      1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the content of the new data frame\n",
    "fraud_3_clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e652",
   "metadata": {},
   "source": [
    "All the data from the ham email collection can be classified as not fraud and all columns except the email text content dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e797cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new clean data frame\n",
    "fraud_4_clean_df = pd.DataFrame()\n",
    "# Assign the 'content' of the new data frame to the text content of the phishing data frame\n",
    "fraud_4_clean_df['content'] = combined_ham_extract_df['content']\n",
    "# Set the fraud column to 0 for this data frame since all entries are ham\n",
    "fraud_4_clean_df['fraud'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10abf2",
   "metadata": {},
   "source": [
    "Now that all the data has been put into data frames with a consistent format and flagged, they can be combined for further cleaning and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d3b94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a new data frame to the combined contents of all the cleaned data frames\n",
    "fraud_all_df = pd.concat([\n",
    "    fraud_clean_df,\n",
    "    fraud_2_clean_df,\n",
    "    fraud_3_clean_df,\n",
    "    fraud_4_clean_df\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4bbf454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all NA values from the new data frame\n",
    "fraud_all_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fc9f34e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14098</th>\n",
       "      <td>Untitled Document This email confirms that you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>Fyi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16240</th>\n",
       "      <td>I installed Spamassassin 2.41 with Razor V2 th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12492</th>\n",
       "      <td>Note: This is a service message with informati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8772</th>\n",
       "      <td>Sorry for the delay. Abt 15 minutes away. We h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3305</th>\n",
       "      <td>PLEASE IGNORE THIS MAIL IF YOU ARE NOT INTERES...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7096</th>\n",
       "      <td>Hello, I have got your contact in the cause of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6484</th>\n",
       "      <td>DR.SOLOMON AZEEZ FEDERAL MINISTRY OF PETROLUEM...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12464</th>\n",
       "      <td>Dear username, If you have ever needed a Visa ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7341</th>\n",
       "      <td>Fyi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  fraud\n",
       "14098  Untitled Document This email confirms that you...      1\n",
       "10390                                                Fyi      0\n",
       "16240  I installed Spamassassin 2.41 with Razor V2 th...      0\n",
       "12492  Note: This is a service message with informati...      1\n",
       "8772   Sorry for the delay. Abt 15 minutes away. We h...      0\n",
       "3305   PLEASE IGNORE THIS MAIL IF YOU ARE NOT INTERES...      1\n",
       "7096   Hello, I have got your contact in the cause of...      1\n",
       "6484   DR.SOLOMON AZEEZ FEDERAL MINISTRY OF PETROLUEM...      1\n",
       "12464  Dear username, If you have ever needed a Visa ...      1\n",
       "7341                                                 Fyi      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the content of the combined data frame\n",
    "fraud_all_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86b00f5",
   "metadata": {},
   "source": [
    "Now that the data frame has been combined, several functions are needed to perform additional cleaning and formatting, these functions were created and saved in the `TextTransformers.py` module. After inspecting the data frame contents, it became clear that the text content of some emails contains HTML. The text content needed to be extracted from the HTML content in these emails, and to this end a function was made to do so. This function is defined in the `TextTransformers.py` module under the name `extract_HTML_text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "861c4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows with HTML content in them a telltale sign of HTML content\n",
    "# existing in a string are the characters '</' which appear in closing tags of HTML\n",
    "rows_with_html = fraud_all_df['content'].str.lower().str.contains('</', na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9f06c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter down the data frame content to those containing HTML and\n",
    "# And assigns them to the same rows with the text content extracted\n",
    "fraud_all_df.loc[rows_with_html, ['content']] = fraud_all_df[rows_with_html]['content'].apply(extract_HTML_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fed279",
   "metadata": {},
   "source": [
    "Since the numerical values and any links will be removed following the English word filter and may represent useful information for identifying fraud emails, these values should be recorded in separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "92989af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets a count of all unsecured links in the text content (Note that unsecured links start with the 'http://' string)\n",
    "fraud_all_df['unsecure_link_count'] = fraud_all_df['content'].str.count('http://')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "88de3072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gets a count of all secure links in the text content (Note that secure links start with the 'https://' string)\n",
    "fraud_all_df['secure_link_count'] = fraud_all_df['content'].str.count('https://')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb221222",
   "metadata": {},
   "source": [
    "Since numerical values may appear within the content of these emails but may not be represented with consistent values, the number of numerical values that appear within an email should be recorded. The function below does this for the content of all email text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "38ad3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds all instances of numerically represented numbers in the text content,\n",
    "# counts them and adds them to a new column 'numbers count'\n",
    "fraud_all_df['numbers_count'] = fraud_all_df['content'].apply(lambda text: len(re.findall(r'\\d+', text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4cb1cf",
   "metadata": {},
   "source": [
    "In addition to the emails with text content there were also emails with non alpha-numeric characters and some emails which don't appear to contain any English words. As Such, a function was created to remove any unusual characters and non-english words. This custom function was created in the TextTransformers.py module under the name `extract_text_content` and will be used to transform the text content of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc6d153c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applies the english word extraction function to each content column and assigns the result to the content column\n",
    "fraud_all_df.loc[:, ['content']] = fraud_all_df['content'].apply(extract_text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "917e4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the get word count function to the content and assigns the result to a new column\n",
    "fraud_all_df['word_count'] = fraud_all_df['content'].apply(get_word_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549415a7",
   "metadata": {},
   "source": [
    "Now that any non-english words have been removed, the content can be filtered down to English word content and any empty, duplicate or null values removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca556955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all rows with empty text content\n",
    "fraud_all_df = fraud_all_df[fraud_all_df['content'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a0f4a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content                0\n",
       "fraud                  0\n",
       "unsecure_link_count    0\n",
       "secure_link_count      0\n",
       "numbers_count          0\n",
       "word_count             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure rows are Null\n",
    "fraud_all_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba1b2cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4067"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks for duplicates in the data\n",
    "fraud_all_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c95ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all duplicates in the data\n",
    "fraud_all_df.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "442ac7f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "      <th>unsecure_link_count</th>\n",
       "      <th>secure_link_count</th>\n",
       "      <th>numbers_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10416</th>\n",
       "      <td>is to a safe environment for its community of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2787</th>\n",
       "      <td>Dear Friend How are you today I know this mail...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6804</th>\n",
       "      <td>Sure Will send as soon as I can</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4921</th>\n",
       "      <td>Bank A well reputable financial institution wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10137</th>\n",
       "      <td>Untitled Document This message graphics If you...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881</th>\n",
       "      <td>IRREVOCABLE RELEASE OF YOUR have actually been...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7543</th>\n",
       "      <td>After nearly two of legal Senator was finally ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3038</th>\n",
       "      <td>May message</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924</th>\n",
       "      <td>Zenith House The CONFIDENTIALLY This and any w...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9568</th>\n",
       "      <td>was confirmed this afternoon Assistant Secreta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  fraud  \\\n",
       "10416  is to a safe environment for its community of ...      1   \n",
       "2787   Dear Friend How are you today I know this mail...      1   \n",
       "6804                     Sure Will send as soon as I can      0   \n",
       "4921   Bank A well reputable financial institution wi...      1   \n",
       "10137  Untitled Document This message graphics If you...      1   \n",
       "2881   IRREVOCABLE RELEASE OF YOUR have actually been...      1   \n",
       "7543   After nearly two of legal Senator was finally ...      0   \n",
       "3038                                         May message      0   \n",
       "6924   Zenith House The CONFIDENTIALLY This and any w...      1   \n",
       "9568   was confirmed this afternoon Assistant Secreta...      0   \n",
       "\n",
       "       unsecure_link_count  secure_link_count  numbers_count  word_count  \n",
       "10416                    0                  1              2         250  \n",
       "2787                     0                  0             38         245  \n",
       "6804                     0                  0              0           8  \n",
       "4921                     0                  0              3         144  \n",
       "10137                    0                  1              0          66  \n",
       "2881                     0                  0              5         215  \n",
       "7543                     0                  0              0          36  \n",
       "3038                     0                  0              4           2  \n",
       "6924                     0                  0              2         129  \n",
       "9568                     0                  0              5          14  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examines the final cleaned data frame\n",
    "fraud_all_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd34d9",
   "metadata": {},
   "source": [
    "Now that the data has been fully combined and cleaned using automation, it can be saved to a csv file for further manual evaluation and use for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53fd580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the resulting combined and cleaned data frame to a CSV\n",
    "fraud_all_df.to_csv('./data/fraud_all_data_clean_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8d0cf5",
   "metadata": {},
   "source": [
    "The data will now undergo additional manual inspection and cleaning to ensure the programatically cleaned data contains meaningful and useful results. During manual inspection two problems were noted. One problem was the use of the word \"China\" indicating a place which may unfairly bias results. In addition to this, the word \"yahoo\" appeared fairly prevalently among fraud emails, which may also lead to invalid accuracies. As such these will be programmatically removed and the data set saved to a final form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79d5dc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a pandas data frame\n",
    "fraud_data_man_clean = pd.read_csv('./data/fraud_all_data_clean_4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21fd62c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the use of the word 'China'\n",
    "fraud_data_man_clean['content'] = fraud_data_man_clean['content'].str.replace('China', '', case=False)\n",
    "# Remove the use of the word 'yahoo'\n",
    "fraud_data_man_clean['content'] = fraud_data_man_clean['content'].str.replace('yahoo', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99dbfbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the finally cleaned data set to a new file\n",
    "fraud_data_man_clean.to_csv('./data/fraud_all_data_clean_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6c8abb",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3939a",
   "metadata": {},
   "source": [
    "Despite the limited availability of email data, the combined and cleaned data produced from this processing should prove sufficient for training a model. Although the model produced from this data may not be suitable for a real world use, it should be sufficient for the purposes of a proof of concept."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone]",
   "language": "python",
   "name": "conda-env-capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "613px",
    "left": "147px",
    "top": "111.141px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
