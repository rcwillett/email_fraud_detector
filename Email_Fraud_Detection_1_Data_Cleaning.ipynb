{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40db824c",
   "metadata": {},
   "source": [
    "# Email Fraud Detection: Data Cleaning and Combining\n",
    "\n",
    "#### By Ross Willett"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b5a8b0",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Email-Fraud-Detection:-Data-Cleaning-and-Combining\" data-toc-modified-id=\"Email-Fraud-Detection:-Data-Cleaning-and-Combining-1\">Email Fraud Detection: Data Cleaning and Combining</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#By-Ross-Willett\" data-toc-modified-id=\"By-Ross-Willett-1.0.0.1\">By Ross Willett</a></span></li></ul></li></ul></li><li><span><a href=\"#Project-Introduction\" data-toc-modified-id=\"Project-Introduction-1.1\">Project Introduction</a></span></li><li><span><a href=\"#File-Introduction\" data-toc-modified-id=\"File-Introduction-1.2\">File Introduction</a></span></li><li><span><a href=\"#Retrieving-and-Analyzing-Data\" data-toc-modified-id=\"Retrieving-and-Analyzing-Data-1.3\">Retrieving and Analyzing Data</a></span></li><li><span><a href=\"#Data-Frame-Cleaning\" data-toc-modified-id=\"Data-Frame-Cleaning-1.4\">Data Frame Cleaning</a></span></li><li><span><a href=\"#Add-Enron\" data-toc-modified-id=\"Add-Enron-1.5\">Add Enron</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d33b0a7",
   "metadata": {},
   "source": [
    "## Project Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cd105d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "738e1323",
   "metadata": {},
   "source": [
    "## File Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7949dff",
   "metadata": {},
   "source": [
    "In this file, data from various sources will be retrieved, combined and cleaned to produce a data set suitable for analysis and model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac08cac9",
   "metadata": {},
   "source": [
    "## Retrieving and Analyzing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "649d1207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data science libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import regex library\n",
    "import re\n",
    "\n",
    "# Import BeautifulSoup for HTML parsing and handling\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Import NLTK for natural language processing\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2edd2ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Pandas to show all columns / rows\n",
    "pd.options.display.max_columns = 2000\n",
    "pd.options.display.max_rows = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e908ca9b",
   "metadata": {},
   "source": [
    "The first data set that will be examined for cleaning and use is the fraud_email_ data set. (Located at https://www.kaggle.com/datasets/pramodgupta92/fraud-email-datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eefc1259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11929, 2)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11929 entries, 0 to 11928\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    11928 non-null  object\n",
      " 1   Class   11929 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 186.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Read data from fraud_email_ data set and look at shape and dataframe info\n",
    "fraud_df = pd.read_csv('./data/fraud_email_.csv')\n",
    "print(fraud_df.shape)\n",
    "print(fraud_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97787db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supply Quality China's EXCLUSIVE dimensions at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over. SidLet me know. Thx.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Friend,Greetings to you.I wish to accost ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not a surprising assessment from Embassy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Class\n",
       "0  Supply Quality China's EXCLUSIVE dimensions at...      1\n",
       "1                         over. SidLet me know. Thx.      0\n",
       "2  Dear Friend,Greetings to you.I wish to accost ...      1\n",
       "3  MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....      1\n",
       "4          Not a surprising assessment from Embassy.      0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at content of data\n",
    "fraud_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a264c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6742\n",
       "1    5187\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at split between fraud and regular emails\n",
    "fraud_df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed04267",
   "metadata": {},
   "source": [
    "Initial analysis of the fraud email data set reveals there is a sizable 11,929 rows of email text data with a classifier indicating whether the email the text was taken from was fraudulent or not. Although missing the email subject and from address is not ideal, this is a significant source of data which should be used in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a07dcbe",
   "metadata": {},
   "source": [
    "The next data set that will be examined for use is the phishing_data_by_type data set. (Located at https://www.kaggle.com/datasets/charlottehall/phishing-email-data-by-type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8efc69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159, 3)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159 entries, 0 to 158\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Subject  157 non-null    object\n",
      " 1   Text     159 non-null    object\n",
      " 2   Type     159 non-null    object\n",
      "dtypes: object(3)\n",
      "memory usage: 3.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Pull the data set into a CSV and look at the shape and column info for the data frame\n",
    "fraud_2_df = pd.read_csv('./data/phishing_data_by_type.csv')\n",
    "print(fraud_2_df.shape)\n",
    "print(fraud_2_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2b60d9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP</td>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URGENT ASSISTANCE /RELATIONSHIP (P)</td>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOD DAY TO YOU</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from Mrs.Johnson</td>\n",
       "      <td>Goodday Dear\\n\\n\\nI know this mail will come t...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Co-Operation</td>\n",
       "      <td>FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Subject  \\\n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP   \n",
       "1         URGENT ASSISTANCE /RELATIONSHIP (P)   \n",
       "2                             GOOD DAY TO YOU   \n",
       "3                            from Mrs.Johnson   \n",
       "4                                Co-Operation   \n",
       "\n",
       "                                                Text   Type  \n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...  Fraud  \n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...  Fraud  \n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...  Fraud  \n",
       "3  Goodday Dear\\n\\n\\nI know this mail will come t...  Fraud  \n",
       "4  FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...  Fraud  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at first few entries of data set\n",
    "fraud_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90144357",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fraud               0.251572\n",
       "Phishing            0.251572\n",
       "Commercial Spam     0.251572\n",
       "False Positives     0.245283\n",
       "Name: Type, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the split for the content type\n",
    "fraud_2_df['Type'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8403fdb",
   "metadata": {},
   "source": [
    "This data set contains only 159 documents but appears to contain a decent diversity of both phishing and fraud emails. It isn't ideal that there are also commercial spam emails since this may create an additional challenge for the identifier. As such, this data set may have to undergo additional cleaning but is likely worth including."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a33ce78",
   "metadata": {},
   "source": [
    "The next data set is composed of the content which was extracted from phishing email files retrieved from https://academictorrents.com/details/a77cda9a9d89a60dbdfbe581adf6e2df9197995a. The from, subject and content was extracted from all of the emails in each folder and compiled into one csv per folder. These files need to be compiled into a singular csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae669935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array to append data frames with contents to\n",
    "phishing_extract_array = []\n",
    "# Iterate from 1 to 5 since there are that many phishing extract files\n",
    "for i in range(1, 5):\n",
    "    # Read the data from each phishing extract csv and put it into a data frame\n",
    "    phishing_extract = pd.read_csv(f'./data/phishing_extract_{i}.csv')\n",
    "    # Append the data frame to the array of data frames\n",
    "    phishing_extract_array.append(phishing_extract)\n",
    "\n",
    "# Create a data frame to store the combined data frames\n",
    "combined_phishing_extract_df = pd.concat(phishing_extract_array) \n",
    "# Drop duplicates in phishing extract data frame\n",
    "combined_phishing_extract_df.drop_duplicates(inplace=True)\n",
    "# Save phishing extract data frame to csv\n",
    "combined_phishing_extract_df.to_csv('./data/phishing_eml_extract_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb56db1b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2416, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1747</th>\n",
       "      <td>&lt;service@wellsfargo.com&gt;</td>\n",
       "      <td>Your Account Access Is Locked</td>\n",
       "      <td>We recently reviewed your account, and suspect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>\"Federal Credit Union\" &lt;acc-validity@ncua.gov&gt;</td>\n",
       "      <td>[*** POSIBLE SPAM***] FCU NOTICE: Important se...</td>\n",
       "      <td>Credit Union is constantly working to ensure s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>\"PayPal\" &lt;postmaster@paypal.com&gt;</td>\n",
       "      <td>Update your PayPal account</td>\n",
       "      <td>Dear Sir,PayPal is committed to maintaining a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>\"Dante Carmichael\" &lt;tkruk@rmsg.com&gt;</td>\n",
       "      <td>rolex mania is down</td>\n",
       "      <td>We only sell premium watches. Theres no bat te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1236</th>\n",
       "      <td>\"PayPal\" &lt;update@secure.account.login.info&gt;</td>\n",
       "      <td>* * New Updates For You * *</td>\n",
       "      <td>Security Measures - Are You Traveling PayPal i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>\"PayPal\" &lt;service@paypal.com&gt;</td>\n",
       "      <td>Notification of Limited Account Access - Case ...</td>\n",
       "      <td>Notification of Limited Account Access Dear Pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>\"PayPal Security Service\" &lt;security@paypal.com&gt;</td>\n",
       "      <td>IMPORTANT: Notification of limited accounts</td>\n",
       "      <td>Notification of Limited Account Access As part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1688</th>\n",
       "      <td>\"Commonwealth Bank of Australia.\" &lt;illdoo@aol....</td>\n",
       "      <td>Urgent Security Notification from Commonwealth...</td>\n",
       "      <td>Dear Commonwealth Bank customer, Commonwealth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>\"Fifth Third Bank\" &lt;services-id6764431ver@secu...</td>\n",
       "      <td>Fifth Third Bank Strongly Recommends. [Thu,\\n ...</td>\n",
       "      <td>Dear Fifth Third bank business/commercial cust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1233</th>\n",
       "      <td>\"PayPal Email ID PP321\" &lt;acc-overview@paypal.com&gt;</td>\n",
       "      <td>[*** POSIBLE SPAM***] PayPal Email ID PP321</td>\n",
       "      <td>Dear PayPal User Dear PayPal User, We recently...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   from  \\\n",
       "1747                           <service@wellsfargo.com>   \n",
       "742      \"Federal Credit Union\" <acc-validity@ncua.gov>   \n",
       "747                    \"PayPal\" <postmaster@paypal.com>   \n",
       "579                 \"Dante Carmichael\" <tkruk@rmsg.com>   \n",
       "1236        \"PayPal\" <update@secure.account.login.info>   \n",
       "643                       \"PayPal\" <service@paypal.com>   \n",
       "936     \"PayPal Security Service\" <security@paypal.com>   \n",
       "1688  \"Commonwealth Bank of Australia.\" <illdoo@aol....   \n",
       "1631  \"Fifth Third Bank\" <services-id6764431ver@secu...   \n",
       "1233  \"PayPal Email ID PP321\" <acc-overview@paypal.com>   \n",
       "\n",
       "                                                subject  \\\n",
       "1747                      Your Account Access Is Locked   \n",
       "742   [*** POSIBLE SPAM***] FCU NOTICE: Important se...   \n",
       "747                          Update your PayPal account   \n",
       "579                                 rolex mania is down   \n",
       "1236                        * * New Updates For You * *   \n",
       "643   Notification of Limited Account Access - Case ...   \n",
       "936         IMPORTANT: Notification of limited accounts   \n",
       "1688  Urgent Security Notification from Commonwealth...   \n",
       "1631  Fifth Third Bank Strongly Recommends. [Thu,\\n ...   \n",
       "1233        [*** POSIBLE SPAM***] PayPal Email ID PP321   \n",
       "\n",
       "                                                content  \n",
       "1747  We recently reviewed your account, and suspect...  \n",
       "742   Credit Union is constantly working to ensure s...  \n",
       "747   Dear Sir,PayPal is committed to maintaining a ...  \n",
       "579   We only sell premium watches. Theres no bat te...  \n",
       "1236  Security Measures - Are You Traveling PayPal i...  \n",
       "643   Notification of Limited Account Access Dear Pa...  \n",
       "936   Notification of Limited Account Access As part...  \n",
       "1688  Dear Commonwealth Bank customer, Commonwealth ...  \n",
       "1631  Dear Fifth Third bank business/commercial cust...  \n",
       "1233  Dear PayPal User Dear PayPal User, We recently...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read all phishing data from the saved csv into a data frame\n",
    "phishing_extract_df = pd.read_csv('./data/phishing_eml_extract_full.csv')\n",
    "# Look at data frame shape\n",
    "print(phishing_extract_df.shape)\n",
    "# Display data frame content\n",
    "phishing_extract_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3d371",
   "metadata": {},
   "source": [
    "The data from the extracted emails includes 2,416 documents including a from address, a subject and the email content entirely consisting of phishing emails. This will prove to be a useful sample for the complete data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5dc4a9",
   "metadata": {},
   "source": [
    "The next data set is composed of the content which was extracted from ham email files retrieved from the Apache \"Spam Assassin\" corpus located [here](https://spamassassin.apache.org/old/publiccorpus/). The from, subject and content was extracted from all of the emails in each folder and compiled into one csv per folder. These files need to be compiled into a singular csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8514f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create array to store extracted data frames to\n",
    "ham_extract_array = []\n",
    "# Iterate over the number of csvs the data was separately stored in\n",
    "for i in range(1, 4):\n",
    "    # Read the data from each csv into a data frame\n",
    "    ham_extract = pd.read_csv(f'./data/ham_extract_{i}.csv')\n",
    "    # Append the data frame to the array of data frames\n",
    "    ham_extract_array.append(ham_extract)\n",
    "\n",
    "# Combine all the data frames into a singular one\n",
    "combined_ham_extract_df = pd.concat(ham_extract_array)\n",
    "# Remove all duplicate data frames\n",
    "combined_ham_extract_df.drop_duplicates(inplace=True)\n",
    "# Save the combined data frame to a csv file\n",
    "combined_ham_extract_df.to_csv('./data/ham_eml_extract_full.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "123d5603",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3303, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3201</th>\n",
       "      <td>Daily Dilbert &lt;2.20290.44-t9bsgc0tYwDu.1@ummai...</td>\n",
       "      <td>Your Daily Dilbert 07/10/2002</td>\n",
       "      <td>E-mail error Youre subscribed to the HTML vers...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Mr. FoRK\" &lt;fork_list@hotmail.com&gt;</td>\n",
       "      <td>Am I This Or Not?</td>\n",
       "      <td>I actually thought of this kind of active chat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>Alvie &lt;bishop12@prodigy.net&gt;</td>\n",
       "      <td>RH 8 no DMA for DVD drive</td>\n",
       "      <td>----- Original Message ----- From: Joseph S. B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2177</th>\n",
       "      <td>Gary Lawrence Murphy &lt;garym@canada.com&gt;</td>\n",
       "      <td>Re: Al'Qaeda's fantasy ideology:  Policy Revie...</td>\n",
       "      <td>b bitbitch writes: b My only problem with this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>guardian &lt;rssfeeds@spamassassin.taint.org&gt;</td>\n",
       "      <td>Plans for new youth units blocked</td>\n",
       "      <td>I am delurking to comment on the Salon article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>pudge@perl.org</td>\n",
       "      <td>[use Perl] Headlines for 2002-09-17</td>\n",
       "      <td>I am delurking to comment on the Salon article...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2524</th>\n",
       "      <td>harley@argote.ch (Robert Harley)</td>\n",
       "      <td>Re: Infectious disease (was Re: Al'Qaeda's fan...</td>\n",
       "      <td>James Rogers wrote: ... As I understand it, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>zawodny &lt;rssfeeds@spamassassin.taint.org&gt;</td>\n",
       "      <td>Yahoo Finance RSS Beta</td>\n",
       "      <td>I actually thought of this kind of active chat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>Jacob Morzinski &lt;yyyyorzins@MIT.EDU&gt;</td>\n",
       "      <td>Re: bad focus/click behaviours</td>\n",
       "      <td>I installed Spamassassin 2.41 with Razor V2 th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2793</th>\n",
       "      <td>Rohit Khare &lt;khare@alumni.caltech.edu&gt;</td>\n",
       "      <td>Re: HD/ID: High-Def Independence Day</td>\n",
       "      <td>On Sunday, June 30, 2002, at 12:18 AM, Rohit K...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   from  \\\n",
       "3201  Daily Dilbert <2.20290.44-t9bsgc0tYwDu.1@ummai...   \n",
       "2                    \"Mr. FoRK\" <fork_list@hotmail.com>   \n",
       "787                        Alvie <bishop12@prodigy.net>   \n",
       "2177            Gary Lawrence Murphy <garym@canada.com>   \n",
       "1010         guardian <rssfeeds@spamassassin.taint.org>   \n",
       "1067                                     pudge@perl.org   \n",
       "2524                   harley@argote.ch (Robert Harley)   \n",
       "142           zawodny <rssfeeds@spamassassin.taint.org>   \n",
       "1477               Jacob Morzinski <yyyyorzins@MIT.EDU>   \n",
       "2793             Rohit Khare <khare@alumni.caltech.edu>   \n",
       "\n",
       "                                                subject  \\\n",
       "3201                      Your Daily Dilbert 07/10/2002   \n",
       "2                                     Am I This Or Not?   \n",
       "787                           RH 8 no DMA for DVD drive   \n",
       "2177  Re: Al'Qaeda's fantasy ideology:  Policy Revie...   \n",
       "1010                  Plans for new youth units blocked   \n",
       "1067                [use Perl] Headlines for 2002-09-17   \n",
       "2524  Re: Infectious disease (was Re: Al'Qaeda's fan...   \n",
       "142                              Yahoo Finance RSS Beta   \n",
       "1477                     Re: bad focus/click behaviours   \n",
       "2793               Re: HD/ID: High-Def Independence Day   \n",
       "\n",
       "                                                content  \n",
       "3201  E-mail error Youre subscribed to the HTML vers...  \n",
       "2     I actually thought of this kind of active chat...  \n",
       "787   ----- Original Message ----- From: Joseph S. B...  \n",
       "2177  b bitbitch writes: b My only problem with this...  \n",
       "1010  I am delurking to comment on the Salon article...  \n",
       "1067  I am delurking to comment on the Salon article...  \n",
       "2524  James Rogers wrote: ... As I understand it, th...  \n",
       "142   I actually thought of this kind of active chat...  \n",
       "1477  I installed Spamassassin 2.41 with Razor V2 th...  \n",
       "2793  On Sunday, June 30, 2002, at 12:18 AM, Rohit K...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the combined data from a csv into a data frame\n",
    "combined_ham_extract_df = pd.read_csv('./data/ham_eml_extract_full.csv')\n",
    "# Display the shape and content of the data frame\n",
    "print(combined_ham_extract_df.shape)\n",
    "combined_ham_extract_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317d0277",
   "metadata": {},
   "source": [
    "The data from the extracted emails includes 2,416 documents including a from address, a subject and the email content entirely consisting of \"ham\" emails. This will prove to be a useful source of data for the combined data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d288d1",
   "metadata": {},
   "source": [
    "## Data Frame Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65178afd",
   "metadata": {},
   "source": [
    "Now that the data sets have been acquired and cursorily examined, the next step will be to format them in the same manner and combine them into a singular data set for further cleaning and analysis. Since the data is largely composed of documents that only have a flag indicating fraud and the content (77% of all data), the final data set should be composed of content and a flag indicating fraud. Given this, all the data sets will be transformed to a standard format with a `content` column with the email text and a `fraud` column with a 1 or 0 flag indicating whether it is fraud or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c63f6d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize clean data frame for first data set\n",
    "fraud_clean_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f62ed280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'content' column for clean data frame\n",
    "fraud_clean_df['content'] = fraud_df['Text']\n",
    "# Set 'fraud' column for clean data frame\n",
    "fraud_clean_df['fraud'] = np.where(\n",
    "    fraud_df['Class'] == 1,\n",
    "    1,\n",
    "    0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88024478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supply Quality China's EXCLUSIVE dimensions at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>over. SidLet me know. Thx.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dear Friend,Greetings to you.I wish to accost ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not a surprising assessment from Embassy.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  fraud\n",
       "0  Supply Quality China's EXCLUSIVE dimensions at...      1\n",
       "1                         over. SidLet me know. Thx.      0\n",
       "2  Dear Friend,Greetings to you.I wish to accost ...      1\n",
       "3  MR. CHEUNG PUIHANG SENG BANK LTD.DES VOEUX RD....      1\n",
       "4          Not a surprising assessment from Embassy.      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the contents of the clean data frame\n",
    "fraud_clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316db21a",
   "metadata": {},
   "source": [
    "In the second data set there is a mix of fraud, phishing, ham and commercial spam email types. The commercial spam will be removed from the data set as this type doesn't strictly fall into either the ham or fraud category and will likely only make identification more difficult for any models trained on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3903866f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Text</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP</td>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URGENT ASSISTANCE /RELATIONSHIP (P)</td>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOD DAY TO YOU</td>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from Mrs.Johnson</td>\n",
       "      <td>Goodday Dear\\n\\n\\nI know this mail will come t...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Co-Operation</td>\n",
       "      <td>FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...</td>\n",
       "      <td>Fraud</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Subject  \\\n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP   \n",
       "1         URGENT ASSISTANCE /RELATIONSHIP (P)   \n",
       "2                             GOOD DAY TO YOU   \n",
       "3                            from Mrs.Johnson   \n",
       "4                                Co-Operation   \n",
       "\n",
       "                                                Text   Type  \n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...  Fraud  \n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...  Fraud  \n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...  Fraud  \n",
       "3  Goodday Dear\\n\\n\\nI know this mail will come t...  Fraud  \n",
       "4  FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...  Fraud  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the data contained in the second fraud data set\n",
    "fraud_2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "013fdb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the data frame to store the cleaned data from the second data set in\n",
    "fraud_2_clean_df = pd.DataFrame()\n",
    "# Set the content column to the text of the second data set\n",
    "fraud_2_clean_df['content'] = fraud_2_df['Text']\n",
    "# Set a 'fraud' column flagging the fraud vs normal emails from the fraud data set\n",
    "fraud_2_clean_df['fraud'] = np.where(\n",
    "    (fraud_2_df['Type'] == 'Fraud') | (fraud_2_df['Type'] == 'Phishing'),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "# Remove the data identified as 'Commercial Spam' from the data set\n",
    "fraud_2_clean_df = fraud_2_clean_df[fraud_2_df['Type'] != 'Commercial Spam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c215de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goodday Dear\\n\\n\\nI know this mail will come t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  fraud\n",
       "0  URGENT BUSINESS ASSISTANCE AND PARTNERSHIP.\\n\\...      1\n",
       "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...      1\n",
       "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...      1\n",
       "3  Goodday Dear\\n\\n\\nI know this mail will come t...      1\n",
       "4  FROM MR. GODWIN AKWESI\\nTEL: +233 208216645\\nF...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine content of cleaned data\n",
    "fraud_2_clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef31afe",
   "metadata": {},
   "source": [
    "All the data from the phishing email collection can be classified as fraud and all columns except the email text content dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cd7e573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new clean data frame\n",
    "fraud_3_clean_df = pd.DataFrame()\n",
    "# Assign the 'content' of the new data frame to the text content of the phishing data frame\n",
    "fraud_3_clean_df['content'] = phishing_extract_df['content']\n",
    "# Set the fraud column to 1 for this data frame since all entries are fraudulent\n",
    "fraud_3_clean_df['fraud'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f7589b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dear valued PayPal member, Due to recent fraud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Credit Union is constantly working to ensure s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit Union is constantly working to ensure s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Untitled Document Dear eBay Member, We regret ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dear valued PayPal member, Due to recent fraud...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  fraud\n",
       "0  Dear valued PayPal member, Due to recent fraud...      1\n",
       "1  Credit Union is constantly working to ensure s...      1\n",
       "2  Credit Union is constantly working to ensure s...      1\n",
       "3  Untitled Document Dear eBay Member, We regret ...      1\n",
       "4  Dear valued PayPal member, Due to recent fraud...      1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the content of the new data frame\n",
    "fraud_3_clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6e652",
   "metadata": {},
   "source": [
    "All the data from the ham email collection can be classified as not fraud and all columns except the email text content dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e797cad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize new clean data frame\n",
    "fraud_4_clean_df = pd.DataFrame()\n",
    "# Assign the 'content' of the new data frame to the text content of the phishing data frame\n",
    "fraud_4_clean_df['content'] = combined_ham_extract_df['content']\n",
    "# Set the fraud column to 0 for this data frame since all entries are ham\n",
    "fraud_4_clean_df['fraud'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e10abf2",
   "metadata": {},
   "source": [
    "Now that all the data has been put into data frames with a consistent format and flagged, they can be combined for further cleaning and processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d3b94ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a new data frame to the combined contents of all the cleaned data frames\n",
    "fraud_all_df = pd.concat([\n",
    "    fraud_clean_df,\n",
    "    fraud_2_clean_df,\n",
    "    fraud_3_clean_df,\n",
    "    fraud_4_clean_df\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b4bbf454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all NA values from the new data frame\n",
    "fraud_all_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fc9f34e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11617</th>\n",
       "      <td>Hello,I am looking for your cooperation in bui...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6476</th>\n",
       "      <td>Yes we figured that?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7790</th>\n",
       "      <td>Very much so. I am also making a few changes a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>Sigh - will send you traffic that lead to this...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9905</th>\n",
       "      <td>It is actually not a full cabinet meeting toda...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5603</th>\n",
       "      <td>Love the \"doctrine\" and I agree we need a heal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2342</th>\n",
       "      <td>Importance: HighFYI</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14019</th>\n",
       "      <td>Dear Citizens Bank and Charter One Bank custom...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16568</th>\n",
       "      <td>E Elias Sinderson writes: E Gary Lawrence Murp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6186</th>\n",
       "      <td>Sullivan Jacob J &lt;SullivanJJ©state.gov&gt;Thursda...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  fraud\n",
       "11617  Hello,I am looking for your cooperation in bui...      1\n",
       "6476                                Yes we figured that?      0\n",
       "7790   Very much so. I am also making a few changes a...      0\n",
       "1958   Sigh - will send you traffic that lead to this...      0\n",
       "9905   It is actually not a full cabinet meeting toda...      0\n",
       "5603   Love the \"doctrine\" and I agree we need a heal...      0\n",
       "2342                                 Importance: HighFYI      0\n",
       "14019  Dear Citizens Bank and Charter One Bank custom...      1\n",
       "16568  E Elias Sinderson writes: E Gary Lawrence Murp...      0\n",
       "6186   Sullivan Jacob J <SullivanJJ©state.gov>Thursda...      0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the content of the combined data frame\n",
    "fraud_all_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c4701c",
   "metadata": {},
   "source": [
    "Now that the data frame has been combined, several functions should be instantiated to perform additional cleaning and formatting. After inspecting the data frame contents, it became clear that the text content of some emails contains HTML. The text content should be extracted from the HTML content in these emails and to this end a function should be made to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a6cd5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines a function to extract text content from strings with HTML\n",
    "def extract_HTML_text(html):\n",
    "    '''\n",
    "    Accepts text content containing HTML and returns only the text content of the HMTML\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    html: A string which contains HTML encoded content\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Ret: A string which contains only the text from the HTML encoded content\n",
    "    \n",
    "    Example\n",
    "    ----------\n",
    "    >>>> extract_HTML_text('<div>Text</div>')\n",
    "    Text\n",
    "    '''\n",
    "    # Instantiate a BeautifulSoup object from the html string using BeautifulSoup\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    # Return the text content of the soupified html content\n",
    "    return soup.get_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b31f4a9",
   "metadata": {},
   "source": [
    "In addition to the emails with text content there were also emails with non alpha-numeric characters and some emails which don't appear to contain any English words. As Such, a function will be needed to remove any unusual characters and non-english words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe1ec6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rosswillett/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/rosswillett/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the NLTK punctuation package\n",
    "nltk.download('punkt')\n",
    "# Download the NLTK english words package\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e58cefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set containing all the english words from the NLTK corpus\n",
    "nltk_eng_words = set(nltk.corpus.words.words())\n",
    "# Instantiate a function to clean the text content of emails\n",
    "def extract_text_content (text):\n",
    "    '''\n",
    "    Accepts a string, filters non-alphabetical characters and non-english words and returns the resulting string\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: A string which needs to be filtered\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Ret: A string which contains only english words\n",
    "    \n",
    "    Example\n",
    "    ----------\n",
    "    >>>> extract_text_content('asjudehr hello_ 712753^!@54318 world!')\n",
    "    hello world\n",
    "    '''\n",
    "    # Removes any '=2C' strings from the text (This appears in certain text encodings between words)\n",
    "    filteredText = text.replace('=2C', '')\n",
    "    # Filters out any non-alphabetical or space characters from the text\n",
    "    characterFilteredText = re.sub(r'[^a-zA-Z\\s]', ' ', filteredText)\n",
    "    # Instantiates an array to contain the english words\n",
    "    englishWordOnlyTextArr = []\n",
    "    # Iterate over every word in the string picked up by the NLTK tokenizer\n",
    "    for word in nltk.word_tokenize(characterFilteredText):\n",
    "        # Set the word to lower case\n",
    "        lower_word = word.lower()\n",
    "        # Check if the word exists in the set of english words and has a length > 1\n",
    "        # And append the word the english word array if so\n",
    "        if lower_word in nltk_eng_words and len(word) > 1:\n",
    "            englishWordOnlyTextArr.append(word)\n",
    "        # If the word is only one character check if it is one of the two english words of one character\n",
    "        # If so, append the word to the english word array\n",
    "        elif lower_word == 'i' or lower_word == 'a':\n",
    "            englishWordOnlyTextArr.append(word)\n",
    "    # Return the english word arrray of the content joined by spaces\n",
    "    return ' '.join(englishWordOnlyTextArr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb41232",
   "metadata": {},
   "source": [
    "Since numerical values may appear within the content of these emails but may not be represented with consistent values, the number of numerical values that appear within an email should be recorded. A function will be needed to record this and has been created below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ef5c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate function to get word count in a string\n",
    "def get_word_count(text):\n",
    "    '''\n",
    "    Accepts a string and returns the number of words contained in that string\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: A string which contains words to be counted\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    Ret: An integer of the number of words contained in that string\n",
    "    \n",
    "    Example\n",
    "    ----------\n",
    "    >>>> get_word_count('goodbye cruel world')\n",
    "    3\n",
    "    '''\n",
    "    # Filter string to alphabetical characters and spaces only\n",
    "    alpha_only_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove any instances of repeated spaces\n",
    "    no_space_alpha_text = re.sub(r'\\s\\s+', ' ', text)\n",
    "    # split sentence into words by splitting on spaces\n",
    "    listofwords = alpha_only_text.split(' ')\n",
    "    # Return the length of the resulting word list\n",
    "    return len(listofwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404d81b1",
   "metadata": {},
   "source": [
    "Now that the functions to properly filter the email content have been created, these should be applied and any other relevant information moved into new columns. First the HTML content should be parsed to get the text content from the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "861c4cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the rows with HTML content in them a telltale sign of HTML content\n",
    "# existing in a string are the characters '</' which appear in closing tags of HTML\n",
    "rows_with_html = fraud_all_df['content'].str.lower().str.contains('</', na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9f06c8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter down the data frame content to those containing HTML and\n",
    "# And assigns them to the same rows with the text content extracted\n",
    "fraud_all_df.loc[rows_with_html, ['content']] = fraud_all_df[rows_with_html]['content'].apply(extract_HTML_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49fed279",
   "metadata": {},
   "source": [
    "Since the numerical values and any links will be removed following the English word filter and may represent useful information for identifying fraud emails, these values should be recorded in separate columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92989af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets a count of all unsecured links in the text content (Note that unsecured links start with the 'http://' string)\n",
    "fraud_all_df['unsecure_link_count'] = fraud_all_df['content'].str.count('http://')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88de3072",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gets a count of all secure links in the text content (Note that secure links start with the 'https://' string)\n",
    "fraud_all_df['secure_link_count'] = fraud_all_df['content'].str.count('https://')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "38ad3912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds all instances of numerically represented numbers in the text content,\n",
    "# counts them and adds them to a new column 'numbers count'\n",
    "fraud_all_df['numbers_count'] = fraud_all_df['content'].apply(lambda text: len(re.findall(r'\\d+', text)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f702789d",
   "metadata": {},
   "source": [
    "Now that any non-word based content has been stored, the content can be filtered down to English word content and any empty, duplicate or null values removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc6d153c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Applies the english word extraction function to each content column and assigns the result to the content column\n",
    "fraud_all_df.loc[:, ['content']] = fraud_all_df['content'].apply(extract_text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "917e4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the get word count function to the content and assigns the result to a new column\n",
    "fraud_all_df['word_count'] = fraud_all_df['content'].apply(get_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca556955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all rows with empty text content\n",
    "fraud_all_df = fraud_all_df[fraud_all_df['content'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2a0f4a28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content                0\n",
       "fraud                  0\n",
       "unsecure_link_count    0\n",
       "secure_link_count      0\n",
       "numbers_count          0\n",
       "word_count             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to ensure rows are Null\n",
    "fraud_all_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ba1b2cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4067"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checks for duplicates in the data\n",
    "fraud_all_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c95ee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes all duplicates in the data\n",
    "fraud_all_df.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "442ac7f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>fraud</th>\n",
       "      <th>unsecure_link_count</th>\n",
       "      <th>secure_link_count</th>\n",
       "      <th>numbers_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>I have it Or Message</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10499</th>\n",
       "      <td>New Page Important Notice Sept Dear Sir Madam ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8135</th>\n",
       "      <td>will get Rob to write him a note unless you al...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9169</th>\n",
       "      <td>am DEPART Private route State Department am AR...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2689</th>\n",
       "      <td>the following page from the to you Please clic...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6693</th>\n",
       "      <td>From Benjamin Cote West address A Day My name ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11874</th>\n",
       "      <td>On Tue wrote I have or which get used for diff...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8117</th>\n",
       "      <td>Yes Its a nice photo It could just be someone ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10380</th>\n",
       "      <td>Protect Your Account sure you never provide yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>Happy easter to you We just finished one hunt ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  fraud  \\\n",
       "9294                                I have it Or Message      0   \n",
       "10499  New Page Important Notice Sept Dear Sir Madam ...      1   \n",
       "8135   will get Rob to write him a note unless you al...      0   \n",
       "9169   am DEPART Private route State Department am AR...      0   \n",
       "2689   the following page from the to you Please clic...      1   \n",
       "6693   From Benjamin Cote West address A Day My name ...      1   \n",
       "11874  On Tue wrote I have or which get used for diff...      0   \n",
       "8117   Yes Its a nice photo It could just be someone ...      0   \n",
       "10380  Protect Your Account sure you never provide yo...      1   \n",
       "1157   Happy easter to you We just finished one hunt ...      0   \n",
       "\n",
       "       unsecure_link_count  secure_link_count  numbers_count  word_count  \n",
       "9294                     0                  0              0           5  \n",
       "10499                    0                  1              4         186  \n",
       "8135                     0                  0              0          17  \n",
       "9169                     0                  0             34          58  \n",
       "2689                     0                  0              6         247  \n",
       "6693                     0                  0             28         198  \n",
       "11874                    1                  0              9         161  \n",
       "8117                     0                  0              0          18  \n",
       "10380                    0                  1              2         160  \n",
       "1157                     0                  0              1          22  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examines the final cleaned data frame\n",
    "fraud_all_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00cd34d9",
   "metadata": {},
   "source": [
    "Now that the data has been fully combined and cleaned, it can be saved to a csv file for further evaluation and use for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "53fd580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves the resulting combined and cleaned data frame to a CSV\n",
    "fraud_all_df.to_csv('./data/fraud_all_data_clean_X.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e0024c",
   "metadata": {},
   "source": [
    "## Add Enron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fb4062aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "phishing_2_fraud_only = fraud_clean_df[fraud_clean_df['fraud'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15acec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_email_df = pd.read_csv('./data/enron_extracted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "820e692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_internal_df = enron_email_df[enron_email_df['from'].str.contains('@enron')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "42699dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>subject</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>52493</th>\n",
       "      <td>shirley.crenshaw@enron.com</td>\n",
       "      <td>move-team@enron.com</td>\n",
       "      <td>Computers from Research Group</td>\n",
       "      <td>Good morning all: This past weekend you moved ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20193</th>\n",
       "      <td>kate.symes@enron.com</td>\n",
       "      <td>andy.chen@enron.com</td>\n",
       "      <td>Re: Warning</td>\n",
       "      <td>Thanks - Enron designed that stationary specif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447804</th>\n",
       "      <td>darrell.schoolcraft@enron.com</td>\n",
       "      <td>steve.january@enron.com, kimberly.watson@enron...</td>\n",
       "      <td>TW Weekend scheduled volumes</td>\n",
       "      <td>March 2002 Scheduled Scheduled Friday 15 West ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89831</th>\n",
       "      <td>ted.murphy@enron.com</td>\n",
       "      <td>s..bradford@enron.com, r..brackett@enron.com, ...</td>\n",
       "      <td>Quick Update</td>\n",
       "      <td>Bill and Friends: FYI, things are still quite ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250452</th>\n",
       "      <td>lynn.blair@enron.com</td>\n",
       "      <td>tim.johanson@enron.com, john.williams@enron.co...</td>\n",
       "      <td>RE: Requested training by Xcel in Denver</td>\n",
       "      <td>Tim and Randy, how did the traning go Thanks. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62105</th>\n",
       "      <td>rebecca.mcdonald@enron.com</td>\n",
       "      <td>jeff.skilling@enron.com, kevin.hannon@enron.com</td>\n",
       "      <td>FW: Sale of Enron's Interest in Bachaquero</td>\n",
       "      <td>FYI -----Original Message----- From: Tortolero...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486224</th>\n",
       "      <td>maria.sandoval@enron.com</td>\n",
       "      <td>asandov225@aol.com, andrea.guillen@enron.com, ...</td>\n",
       "      <td>The Empty Chair</td>\n",
       "      <td>THE EMPTY CHAIR A mans daughter had asked the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109654</th>\n",
       "      <td>michele.winckowski@enron.com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FW: Something Worth Seeing</td>\n",
       "      <td>This is very powerful. Some photos are very gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308442</th>\n",
       "      <td>frank.davis@enron.com</td>\n",
       "      <td>tana.jones@enron.com</td>\n",
       "      <td>Pulp &amp; Paper Long Descriptions</td>\n",
       "      <td>Tana, Attached below are examples of EnronOnli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457221</th>\n",
       "      <td>maureen.mcvicker@enron.com</td>\n",
       "      <td>tom.briggs@enron.com</td>\n",
       "      <td>Re: Draft Wyden letter</td>\n",
       "      <td>Tom: What address should I use for the Sen. Wy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 from  \\\n",
       "52493      shirley.crenshaw@enron.com   \n",
       "20193            kate.symes@enron.com   \n",
       "447804  darrell.schoolcraft@enron.com   \n",
       "89831            ted.murphy@enron.com   \n",
       "250452           lynn.blair@enron.com   \n",
       "62105      rebecca.mcdonald@enron.com   \n",
       "486224       maria.sandoval@enron.com   \n",
       "109654   michele.winckowski@enron.com   \n",
       "308442          frank.davis@enron.com   \n",
       "457221     maureen.mcvicker@enron.com   \n",
       "\n",
       "                                                       to  \\\n",
       "52493                                 move-team@enron.com   \n",
       "20193                                 andy.chen@enron.com   \n",
       "447804  steve.january@enron.com, kimberly.watson@enron...   \n",
       "89831   s..bradford@enron.com, r..brackett@enron.com, ...   \n",
       "250452  tim.johanson@enron.com, john.williams@enron.co...   \n",
       "62105     jeff.skilling@enron.com, kevin.hannon@enron.com   \n",
       "486224  asandov225@aol.com, andrea.guillen@enron.com, ...   \n",
       "109654                                                NaN   \n",
       "308442                               tana.jones@enron.com   \n",
       "457221                               tom.briggs@enron.com   \n",
       "\n",
       "                                           subject  \\\n",
       "52493                Computers from Research Group   \n",
       "20193                                  Re: Warning   \n",
       "447804                TW Weekend scheduled volumes   \n",
       "89831                                 Quick Update   \n",
       "250452    RE: Requested training by Xcel in Denver   \n",
       "62105   FW: Sale of Enron's Interest in Bachaquero   \n",
       "486224                             The Empty Chair   \n",
       "109654                  FW: Something Worth Seeing   \n",
       "308442              Pulp & Paper Long Descriptions   \n",
       "457221                      Re: Draft Wyden letter   \n",
       "\n",
       "                                                  content  \n",
       "52493   Good morning all: This past weekend you moved ...  \n",
       "20193   Thanks - Enron designed that stationary specif...  \n",
       "447804  March 2002 Scheduled Scheduled Friday 15 West ...  \n",
       "89831   Bill and Friends: FYI, things are still quite ...  \n",
       "250452  Tim and Randy, how did the traning go Thanks. ...  \n",
       "62105   FYI -----Original Message----- From: Tortolero...  \n",
       "486224  THE EMPTY CHAIR A mans daughter had asked the ...  \n",
       "109654  This is very powerful. Some photos are very gr...  \n",
       "308442  Tana, Attached below are examples of EnronOnli...  \n",
       "457221  Tom: What address should I use for the Sen. Wy...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_internal_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30f9abbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "enron_internal_clean = pd.DataFrame()\n",
    "enron_internal_clean = enron_internal_df.copy()\n",
    "enron_internal_clean.loc[:, 'phishing'] = 0\n",
    "enron_internal_clean.drop(columns=['to', 'from', 'subject'], inplace=True)\n",
    "enron_internal_clean_sample = enron_internal_clean.sample(5656)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2c4cc2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([\n",
    "    phishing_2_fraud_only,\n",
    "    fraud_2_clean_df,\n",
    "    fraud_3_clean_df,\n",
    "    fraud_4_clean_df,\n",
    "    enron_internal_clean_sample\n",
    "], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "7e8e0f0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7138\n",
       "0    7138\n",
       "Name: phishing, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['fraud'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f44f9e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0e870a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_with_html = new_df['content'].str.lower().str.contains('</', na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7d0f525f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df.loc[rows_with_html, ['content']] = new_df[rows_with_html]['content'].apply(extract_HTML_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "32312f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['unsecure_link_count'] = new_df['content'].str.count('http://')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a939ce1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df['secure_link_count'] = new_df['content'].str.count('https://')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "272dc0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['numbers_count'] = new_df['content'].apply(lambda text: len(re.findall(r'\\d+', text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cb8b7fe4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_df.loc[:, ['content']] = new_df['content'].apply(extract_text_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "67b2d142",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['word_count'] = new_df['content'].apply(get_word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b70572ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[new_df['content'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e6bc7511",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "content                0\n",
       "phishing               0\n",
       "unsecure_link_count    0\n",
       "secure_link_count      0\n",
       "numbers_count          0\n",
       "word_count             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "64d8eb25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1474"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "58fda36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop_duplicates(inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "be8b7c78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>phishing</th>\n",
       "      <th>unsecure_link_count</th>\n",
       "      <th>secure_link_count</th>\n",
       "      <th>numbers_count</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Supply Quality China EXCLUSIVE at Unbeatable P...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dear Friend to you I wish to accost you with a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BANK BRANCH CENTRAL HONG HONG Let me start by ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from barrister friend I know that my letter wi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOLICITING FOR A BUSINESS VENTURE AND DEAR SIR...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12746</th>\n",
       "      <td>You know I must have received your message on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12747</th>\n",
       "      <td>AGRICULTURE Soft commodity find the going hard...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>358</td>\n",
       "      <td>7277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12748</th>\n",
       "      <td>I have your resume with my commentary to Bibi ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12749</th>\n",
       "      <td>Mark How should we handle this In the past I h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12750</th>\n",
       "      <td>No wonder you find it Keep looking cause I gue...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12751 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content  phishing  \\\n",
       "0      Supply Quality China EXCLUSIVE at Unbeatable P...         1   \n",
       "1      Dear Friend to you I wish to accost you with a...         1   \n",
       "2      BANK BRANCH CENTRAL HONG HONG Let me start by ...         1   \n",
       "3      from barrister friend I know that my letter wi...         1   \n",
       "4      SOLICITING FOR A BUSINESS VENTURE AND DEAR SIR...         1   \n",
       "...                                                  ...       ...   \n",
       "12746  You know I must have received your message on ...         0   \n",
       "12747  AGRICULTURE Soft commodity find the going hard...         0   \n",
       "12748  I have your resume with my commentary to Bibi ...         0   \n",
       "12749  Mark How should we handle this In the past I h...         0   \n",
       "12750  No wonder you find it Keep looking cause I gue...         0   \n",
       "\n",
       "       unsecure_link_count  secure_link_count  numbers_count  word_count  \n",
       "0                        0                  0             10         131  \n",
       "1                        0                  0              9         385  \n",
       "2                        1                  0              6         549  \n",
       "3                        0                  0             41         527  \n",
       "4                        0                  0             20         323  \n",
       "...                    ...                ...            ...         ...  \n",
       "12746                    0                  0              5          82  \n",
       "12747                    3                  0            358        7277  \n",
       "12748                    0                  0              0          31  \n",
       "12749                    0                  0             50         274  \n",
       "12750                    0                  0             38         373  \n",
       "\n",
       "[12751 rows x 6 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "840a3d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('./data/fraud_with_enron_data_clean_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bd4b53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:capstone]",
   "language": "python",
   "name": "conda-env-capstone-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "613px",
    "left": "224px",
    "top": "111.141px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
