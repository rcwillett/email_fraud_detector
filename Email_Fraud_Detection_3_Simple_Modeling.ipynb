{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf76cb3",
   "metadata": {},
   "source": [
    "# Email Fraud Detection: Simple Modeling\n",
    "\n",
    "#### Ross Willett"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7413b1b4",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Email-Fraud-Detection:-Simple-Modeling\" data-toc-modified-id=\"Email-Fraud-Detection:-Simple-Modeling-1\">Email Fraud Detection: Simple Modeling</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Ross-Willett\" data-toc-modified-id=\"Ross-Willett-1.0.0.1\">Ross Willett</a></span></li></ul></li></ul></li><li><span><a href=\"#File-Introduction\" data-toc-modified-id=\"File-Introduction-1.1\">File Introduction</a></span></li><li><span><a href=\"#Initial-Formatting\" data-toc-modified-id=\"Initial-Formatting-1.2\">Initial Formatting</a></span></li><li><span><a href=\"#Model-Building\" data-toc-modified-id=\"Model-Building-1.3\">Model Building</a></span><ul class=\"toc-item\"><li><span><a href=\"#Logistic-Regression-Model\" data-toc-modified-id=\"Logistic-Regression-Model-1.3.1\">Logistic Regression Model</a></span></li><li><span><a href=\"#SVM-Model\" data-toc-modified-id=\"SVM-Model-1.3.2\">SVM Model</a></span></li><li><span><a href=\"#KNN-Model\" data-toc-modified-id=\"KNN-Model-1.3.3\">KNN Model</a></span></li><li><span><a href=\"#Decision-Tree-Model\" data-toc-modified-id=\"Decision-Tree-Model-1.3.4\">Decision Tree Model</a></span></li><li><span><a href=\"#Naive-Bayes-Model\" data-toc-modified-id=\"Naive-Bayes-Model-1.3.5\">Naive Bayes Model</a></span></li><li><span><a href=\"#Comparing-The-Model-Results\" data-toc-modified-id=\"Comparing-The-Model-Results-1.3.6\">Comparing The Model Results</a></span></li><li><span><a href=\"#TFIDF-Vectorizer\" data-toc-modified-id=\"TFIDF-Vectorizer-1.3.7\">TFIDF Vectorizer</a></span></li><li><span><a href=\"#TFIDF-Logistic-Regression\" data-toc-modified-id=\"TFIDF-Logistic-Regression-1.3.8\">TFIDF Logistic Regression</a></span></li><li><span><a href=\"#TFIDF-SVM\" data-toc-modified-id=\"TFIDF-SVM-1.3.9\">TFIDF SVM</a></span></li><li><span><a href=\"#TFIDF-KNN\" data-toc-modified-id=\"TFIDF-KNN-1.3.10\">TFIDF KNN</a></span></li><li><span><a href=\"#TFIDF-Decision-Tree\" data-toc-modified-id=\"TFIDF-Decision-Tree-1.3.11\">TFIDF Decision Tree</a></span></li><li><span><a href=\"#TFIDF-Naive-Bayes\" data-toc-modified-id=\"TFIDF-Naive-Bayes-1.3.12\">TFIDF Naive Bayes</a></span></li><li><span><a href=\"#Comparing-TFIDF-and-Count-Vectorized-Results\" data-toc-modified-id=\"Comparing-TFIDF-and-Count-Vectorized-Results-1.3.13\">Comparing TFIDF and Count Vectorized Results</a></span></li><li><span><a href=\"#Build-Test-Pipelines\" data-toc-modified-id=\"Build-Test-Pipelines-1.3.14\">Build Test Pipelines</a></span></li></ul></li><li><span><a href=\"#Save-The-Model\" data-toc-modified-id=\"Save-The-Model-1.4\">Save The Model</a></span></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-1.5\">Conclusion</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c9969",
   "metadata": {},
   "source": [
    "## File Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da2aed8",
   "metadata": {},
   "source": [
    "In this file, several models will be built using the vectorized text data and additional numerical columns. The performance of these models will be evaluated and the hyperparameters optimized to find the best model of these simple models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd7b1b3",
   "metadata": {},
   "source": [
    "## Initial Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c938c97",
   "metadata": {},
   "source": [
    "First the the remainder and test data must be loaded into the file. Then in order to prevent any data leakage, the remainder set must be split into train and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6c13ce92-dac4-4b44-82ca-bc8d0acdfbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data manipulation libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Import regex library\n",
    "import re\n",
    "\n",
    "# Import math library\n",
    "import math\n",
    "\n",
    "# Import plotting libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Import natural language processing libraries\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Import model selection libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Import processing libraries\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Import modeling libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Import dimensionality reduction library\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Import model Evaluation Libraries\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Import pipeline library\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import temporary file creation library\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "# Import Pickling library\n",
    "import pickle\n",
    "\n",
    "# Import custom tokenizer\n",
    "from Tokenizer import custom_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "662ea6d8-d0cc-4314-a983-bf5b55bf731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import warnings and supress them\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f662b984-ec98-4a98-bdd6-dd886975e9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Pandas to show all columns / rows\n",
    "pd.options.display.max_columns = 2000\n",
    "pd.options.display.max_rows = 2000\n",
    "# Set column max width larger\n",
    "pd.set_option('display.max_colwidth', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c4274933-00e2-424d-aead-5e64d0f98290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib to use nice styles\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "675e2d2e-46f3-4835-b2d9-8182327d39a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load X remainder\n",
    "X_remainder = pd.read_csv('./data/X_remainder.csv')\n",
    "# Load X test\n",
    "X_test = pd.read_csv('./data/X_test.csv')\n",
    "# Load y remainder\n",
    "y_remainder = pd.read_csv('./data/y_remainder.csv')\n",
    "# Load y test\n",
    "y_test = pd.read_csv('./data/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "afd79b0f-5f9e-4e67-b00e-0ce65ecd7a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data frames into train and validation data\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_remainder,\n",
    "    y_remainder,\n",
    "    stratify=y_remainder,\n",
    "    random_state=1337,\n",
    "    test_size=0.2,\n",
    ")\n",
    "# Reset the indexes of the resulting data frames so the counts return to 1 to n\n",
    "X_train.reset_index(drop=True, inplace=True)\n",
    "X_validation.reset_index(drop=True, inplace=True)\n",
    "y_train.reset_index(drop=True, inplace=True)\n",
    "y_validation.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4191eae6",
   "metadata": {},
   "source": [
    "Now that the data has been split into train, validation and test data, the count vectorizer can be fit on the train data and used to transform the other data sets. The vectorizer will be set to use a custom tokenizer which will remove stop words and stem each word. This vectorizer will also require a minimum frequency of 5% for any word to be used in the vectorizer. This will reduce any over-fitting for any models trained on the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ff86c490-ae3a-4f95-8802-65fbb7c825f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a column transformer to be used to vectorize the text content and pass through the other columns\n",
    "cv_transf = ColumnTransformer([\n",
    "        (\n",
    "            # Set the name of the transformer\n",
    "            'count_vectorizer',\n",
    "            # Intantiate the count vectorizer\n",
    "            CountVectorizer(\n",
    "                # Set the tokenizer for the vectorizer to the custom tokenizer\n",
    "                tokenizer=custom_tokenizer,\n",
    "                # Set a minimum requirement of 5% frequency for words to be used for vectorizer\n",
    "                min_df=0.05\n",
    "            ),\n",
    "            # Set the target column of the count vectorizer\n",
    "            'content',\n",
    "        )\n",
    "    ],\n",
    "    # Specify that all other columns for the data frame should be left as-is\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a2b808f8-ba77-4397-bc55-c7aa61e07333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the data for the training data set\n",
    "X_train_vec = cv_transf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "93c5efad-a40e-4d6c-bff9-8a7000c5f7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_vectorizer__abl</th>\n",
       "      <th>count_vectorizer__accept</th>\n",
       "      <th>count_vectorizer__access</th>\n",
       "      <th>count_vectorizer__accord</th>\n",
       "      <th>count_vectorizer__account</th>\n",
       "      <th>count_vectorizer__actual</th>\n",
       "      <th>count_vectorizer__address</th>\n",
       "      <th>count_vectorizer__agre</th>\n",
       "      <th>count_vectorizer__agreement</th>\n",
       "      <th>count_vectorizer__along</th>\n",
       "      <th>count_vectorizer__also</th>\n",
       "      <th>count_vectorizer__amount</th>\n",
       "      <th>count_vectorizer__anoth</th>\n",
       "      <th>count_vectorizer__arrang</th>\n",
       "      <th>count_vectorizer__ask</th>\n",
       "      <th>count_vectorizer__assist</th>\n",
       "      <th>count_vectorizer__assur</th>\n",
       "      <th>count_vectorizer__attent</th>\n",
       "      <th>count_vectorizer__back</th>\n",
       "      <th>count_vectorizer__bank</th>\n",
       "      <th>count_vectorizer__base</th>\n",
       "      <th>count_vectorizer__behalf</th>\n",
       "      <th>count_vectorizer__believ</th>\n",
       "      <th>count_vectorizer__beneficiari</th>\n",
       "      <th>count_vectorizer__best</th>\n",
       "      <th>count_vectorizer__bless</th>\n",
       "      <th>count_vectorizer__busi</th>\n",
       "      <th>count_vectorizer__call</th>\n",
       "      <th>count_vectorizer__care</th>\n",
       "      <th>count_vectorizer__case</th>\n",
       "      <th>count_vectorizer__chang</th>\n",
       "      <th>count_vectorizer__choos</th>\n",
       "      <th>count_vectorizer__claim</th>\n",
       "      <th>count_vectorizer__click</th>\n",
       "      <th>count_vectorizer__client</th>\n",
       "      <th>count_vectorizer__close</th>\n",
       "      <th>count_vectorizer__come</th>\n",
       "      <th>count_vectorizer__commun</th>\n",
       "      <th>count_vectorizer__compani</th>\n",
       "      <th>count_vectorizer__complet</th>\n",
       "      <th>count_vectorizer__concern</th>\n",
       "      <th>count_vectorizer__confid</th>\n",
       "      <th>count_vectorizer__confidenti</th>\n",
       "      <th>count_vectorizer__confirm</th>\n",
       "      <th>count_vectorizer__contact</th>\n",
       "      <th>count_vectorizer__corpor</th>\n",
       "      <th>count_vectorizer__could</th>\n",
       "      <th>count_vectorizer__countri</th>\n",
       "      <th>count_vectorizer__cours</th>\n",
       "      <th>count_vectorizer__current</th>\n",
       "      <th>count_vectorizer__custom</th>\n",
       "      <th>count_vectorizer__day</th>\n",
       "      <th>count_vectorizer__deal</th>\n",
       "      <th>count_vectorizer__dear</th>\n",
       "      <th>count_vectorizer__death</th>\n",
       "      <th>count_vectorizer__deceas</th>\n",
       "      <th>count_vectorizer__decid</th>\n",
       "      <th>count_vectorizer__depart</th>\n",
       "      <th>count_vectorizer__deposit</th>\n",
       "      <th>count_vectorizer__develop</th>\n",
       "      <th>count_vectorizer__direct</th>\n",
       "      <th>count_vectorizer__discov</th>\n",
       "      <th>count_vectorizer__discuss</th>\n",
       "      <th>count_vectorizer__done</th>\n",
       "      <th>count_vectorizer__due</th>\n",
       "      <th>count_vectorizer__easi</th>\n",
       "      <th>count_vectorizer__enabl</th>\n",
       "      <th>count_vectorizer__end</th>\n",
       "      <th>count_vectorizer__even</th>\n",
       "      <th>count_vectorizer__everi</th>\n",
       "      <th>count_vectorizer__execut</th>\n",
       "      <th>count_vectorizer__fact</th>\n",
       "      <th>count_vectorizer__faith</th>\n",
       "      <th>count_vectorizer__famili</th>\n",
       "      <th>count_vectorizer__father</th>\n",
       "      <th>count_vectorizer__file</th>\n",
       "      <th>count_vectorizer__final</th>\n",
       "      <th>count_vectorizer__financi</th>\n",
       "      <th>count_vectorizer__find</th>\n",
       "      <th>count_vectorizer__first</th>\n",
       "      <th>count_vectorizer__five</th>\n",
       "      <th>count_vectorizer__follow</th>\n",
       "      <th>count_vectorizer__foreign</th>\n",
       "      <th>count_vectorizer__form</th>\n",
       "      <th>count_vectorizer__former</th>\n",
       "      <th>count_vectorizer__forward</th>\n",
       "      <th>count_vectorizer__free</th>\n",
       "      <th>count_vectorizer__friend</th>\n",
       "      <th>count_vectorizer__full</th>\n",
       "      <th>count_vectorizer__fund</th>\n",
       "      <th>count_vectorizer__futur</th>\n",
       "      <th>count_vectorizer__gener</th>\n",
       "      <th>count_vectorizer__get</th>\n",
       "      <th>count_vectorizer__give</th>\n",
       "      <th>count_vectorizer__given</th>\n",
       "      <th>count_vectorizer__go</th>\n",
       "      <th>count_vectorizer__god</th>\n",
       "      <th>count_vectorizer__good</th>\n",
       "      <th>count_vectorizer__got</th>\n",
       "      <th>count_vectorizer__govern</th>\n",
       "      <th>count_vectorizer__great</th>\n",
       "      <th>count_vectorizer__group</th>\n",
       "      <th>count_vectorizer__hear</th>\n",
       "      <th>count_vectorizer__help</th>\n",
       "      <th>count_vectorizer__henc</th>\n",
       "      <th>count_vectorizer__home</th>\n",
       "      <th>count_vectorizer__hope</th>\n",
       "      <th>count_vectorizer__hous</th>\n",
       "      <th>count_vectorizer__howev</th>\n",
       "      <th>count_vectorizer__hundr</th>\n",
       "      <th>count_vectorizer__id</th>\n",
       "      <th>count_vectorizer__immedi</th>\n",
       "      <th>count_vectorizer__import</th>\n",
       "      <th>count_vectorizer__includ</th>\n",
       "      <th>count_vectorizer__inform</th>\n",
       "      <th>count_vectorizer__interest</th>\n",
       "      <th>count_vectorizer__intern</th>\n",
       "      <th>count_vectorizer__invest</th>\n",
       "      <th>count_vectorizer__involv</th>\n",
       "      <th>count_vectorizer__issu</th>\n",
       "      <th>count_vectorizer__keep</th>\n",
       "      <th>count_vectorizer__kin</th>\n",
       "      <th>count_vectorizer__know</th>\n",
       "      <th>count_vectorizer__last</th>\n",
       "      <th>count_vectorizer__late</th>\n",
       "      <th>count_vectorizer__law</th>\n",
       "      <th>count_vectorizer__leav</th>\n",
       "      <th>count_vectorizer__left</th>\n",
       "      <th>count_vectorizer__legal</th>\n",
       "      <th>count_vectorizer__let</th>\n",
       "      <th>count_vectorizer__letter</th>\n",
       "      <th>count_vectorizer__life</th>\n",
       "      <th>count_vectorizer__like</th>\n",
       "      <th>count_vectorizer__link</th>\n",
       "      <th>count_vectorizer__list</th>\n",
       "      <th>count_vectorizer__live</th>\n",
       "      <th>count_vectorizer__long</th>\n",
       "      <th>count_vectorizer__look</th>\n",
       "      <th>count_vectorizer__made</th>\n",
       "      <th>count_vectorizer__mail</th>\n",
       "      <th>count_vectorizer__mailman</th>\n",
       "      <th>count_vectorizer__make</th>\n",
       "      <th>count_vectorizer__manag</th>\n",
       "      <th>count_vectorizer__mani</th>\n",
       "      <th>count_vectorizer__matter</th>\n",
       "      <th>count_vectorizer__may</th>\n",
       "      <th>count_vectorizer__meet</th>\n",
       "      <th>count_vectorizer__member</th>\n",
       "      <th>count_vectorizer__messag</th>\n",
       "      <th>count_vectorizer__might</th>\n",
       "      <th>count_vectorizer__million</th>\n",
       "      <th>count_vectorizer__money</th>\n",
       "      <th>count_vectorizer__move</th>\n",
       "      <th>count_vectorizer__much</th>\n",
       "      <th>count_vectorizer__must</th>\n",
       "      <th>count_vectorizer__name</th>\n",
       "      <th>count_vectorizer__nation</th>\n",
       "      <th>count_vectorizer__necessari</th>\n",
       "      <th>count_vectorizer__need</th>\n",
       "      <th>count_vectorizer__net</th>\n",
       "      <th>count_vectorizer__never</th>\n",
       "      <th>count_vectorizer__new</th>\n",
       "      <th>count_vectorizer__next</th>\n",
       "      <th>count_vectorizer__note</th>\n",
       "      <th>count_vectorizer__number</th>\n",
       "      <th>count_vectorizer__offer</th>\n",
       "      <th>count_vectorizer__offic</th>\n",
       "      <th>count_vectorizer__offici</th>\n",
       "      <th>count_vectorizer__old</th>\n",
       "      <th>count_vectorizer__one</th>\n",
       "      <th>count_vectorizer__open</th>\n",
       "      <th>count_vectorizer__oper</th>\n",
       "      <th>count_vectorizer__order</th>\n",
       "      <th>count_vectorizer__part</th>\n",
       "      <th>count_vectorizer__partner</th>\n",
       "      <th>count_vectorizer__peopl</th>\n",
       "      <th>count_vectorizer__person</th>\n",
       "      <th>count_vectorizer__phone</th>\n",
       "      <th>count_vectorizer__place</th>\n",
       "      <th>count_vectorizer__pleas</th>\n",
       "      <th>count_vectorizer__polici</th>\n",
       "      <th>count_vectorizer__polit</th>\n",
       "      <th>count_vectorizer__posit</th>\n",
       "      <th>count_vectorizer__possibl</th>\n",
       "      <th>count_vectorizer__present</th>\n",
       "      <th>count_vectorizer__presid</th>\n",
       "      <th>count_vectorizer__privat</th>\n",
       "      <th>count_vectorizer__problem</th>\n",
       "      <th>count_vectorizer__process</th>\n",
       "      <th>count_vectorizer__propos</th>\n",
       "      <th>count_vectorizer__protect</th>\n",
       "      <th>count_vectorizer__provid</th>\n",
       "      <th>count_vectorizer__put</th>\n",
       "      <th>count_vectorizer__read</th>\n",
       "      <th>count_vectorizer__real</th>\n",
       "      <th>count_vectorizer__reason</th>\n",
       "      <th>count_vectorizer__receiv</th>\n",
       "      <th>count_vectorizer__recent</th>\n",
       "      <th>count_vectorizer__releas</th>\n",
       "      <th>count_vectorizer__reliabl</th>\n",
       "      <th>count_vectorizer__repli</th>\n",
       "      <th>count_vectorizer__request</th>\n",
       "      <th>count_vectorizer__reserv</th>\n",
       "      <th>count_vectorizer__respect</th>\n",
       "      <th>count_vectorizer__respons</th>\n",
       "      <th>count_vectorizer__result</th>\n",
       "      <th>count_vectorizer__right</th>\n",
       "      <th>count_vectorizer__risk</th>\n",
       "      <th>count_vectorizer__run</th>\n",
       "      <th>count_vectorizer__safe</th>\n",
       "      <th>count_vectorizer__said</th>\n",
       "      <th>count_vectorizer__say</th>\n",
       "      <th>count_vectorizer__search</th>\n",
       "      <th>count_vectorizer__secur</th>\n",
       "      <th>count_vectorizer__see</th>\n",
       "      <th>count_vectorizer__seek</th>\n",
       "      <th>count_vectorizer__send</th>\n",
       "      <th>count_vectorizer__sent</th>\n",
       "      <th>count_vectorizer__servic</th>\n",
       "      <th>count_vectorizer__set</th>\n",
       "      <th>count_vectorizer__shall</th>\n",
       "      <th>count_vectorizer__share</th>\n",
       "      <th>count_vectorizer__sinc</th>\n",
       "      <th>count_vectorizer__sincer</th>\n",
       "      <th>count_vectorizer__sir</th>\n",
       "      <th>count_vectorizer__site</th>\n",
       "      <th>count_vectorizer__son</th>\n",
       "      <th>count_vectorizer__soon</th>\n",
       "      <th>count_vectorizer__stand</th>\n",
       "      <th>count_vectorizer__start</th>\n",
       "      <th>count_vectorizer__state</th>\n",
       "      <th>count_vectorizer__still</th>\n",
       "      <th>count_vectorizer__success</th>\n",
       "      <th>count_vectorizer__sum</th>\n",
       "      <th>count_vectorizer__support</th>\n",
       "      <th>count_vectorizer__sure</th>\n",
       "      <th>count_vectorizer__system</th>\n",
       "      <th>count_vectorizer__take</th>\n",
       "      <th>count_vectorizer__telephon</th>\n",
       "      <th>count_vectorizer__th</th>\n",
       "      <th>count_vectorizer__thank</th>\n",
       "      <th>count_vectorizer__therefor</th>\n",
       "      <th>count_vectorizer__think</th>\n",
       "      <th>count_vectorizer__though</th>\n",
       "      <th>count_vectorizer__thousand</th>\n",
       "      <th>count_vectorizer__time</th>\n",
       "      <th>count_vectorizer__today</th>\n",
       "      <th>count_vectorizer__told</th>\n",
       "      <th>count_vectorizer__top</th>\n",
       "      <th>count_vectorizer__total</th>\n",
       "      <th>count_vectorizer__transact</th>\n",
       "      <th>count_vectorizer__transfer</th>\n",
       "      <th>count_vectorizer__tri</th>\n",
       "      <th>count_vectorizer__trust</th>\n",
       "      <th>count_vectorizer__two</th>\n",
       "      <th>count_vectorizer__understand</th>\n",
       "      <th>count_vectorizer__unit</th>\n",
       "      <th>count_vectorizer__updat</th>\n",
       "      <th>count_vectorizer__upon</th>\n",
       "      <th>count_vectorizer__urgent</th>\n",
       "      <th>count_vectorizer__us</th>\n",
       "      <th>count_vectorizer__use</th>\n",
       "      <th>count_vectorizer__user</th>\n",
       "      <th>count_vectorizer__valu</th>\n",
       "      <th>count_vectorizer__via</th>\n",
       "      <th>count_vectorizer__visit</th>\n",
       "      <th>count_vectorizer__want</th>\n",
       "      <th>count_vectorizer__way</th>\n",
       "      <th>count_vectorizer__well</th>\n",
       "      <th>count_vectorizer__wish</th>\n",
       "      <th>count_vectorizer__within</th>\n",
       "      <th>count_vectorizer__without</th>\n",
       "      <th>count_vectorizer__work</th>\n",
       "      <th>count_vectorizer__world</th>\n",
       "      <th>count_vectorizer__would</th>\n",
       "      <th>count_vectorizer__write</th>\n",
       "      <th>count_vectorizer__wrote</th>\n",
       "      <th>count_vectorizer__yahoo</th>\n",
       "      <th>count_vectorizer__year</th>\n",
       "      <th>remainder__unsecure_link_count</th>\n",
       "      <th>remainder__secure_link_count</th>\n",
       "      <th>remainder__numbers_count</th>\n",
       "      <th>remainder__word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_vectorizer__abl  count_vectorizer__accept  count_vectorizer__access  \\\n",
       "0                      0                         0                         0   \n",
       "1                      0                         0                         0   \n",
       "2                      0                         0                         0   \n",
       "3                      1                         1                         0   \n",
       "4                      0                         0                         4   \n",
       "5                      0                         0                         0   \n",
       "6                      0                         0                         0   \n",
       "7                      0                         1                         0   \n",
       "8                      0                         0                         0   \n",
       "9                      0                         0                         0   \n",
       "\n",
       "   count_vectorizer__accord  count_vectorizer__account  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         1                          2   \n",
       "4                         1                         10   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                         10   \n",
       "8                         0                          2   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__actual  count_vectorizer__address  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          3   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         1                          1   \n",
       "8                         0                          1   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__agre  count_vectorizer__agreement  \\\n",
       "0                       0                            0   \n",
       "1                       0                            0   \n",
       "2                       0                            1   \n",
       "3                       1                            0   \n",
       "4                       0                            1   \n",
       "5                       0                            0   \n",
       "6                       0                            0   \n",
       "7                       0                            1   \n",
       "8                       0                            1   \n",
       "9                       0                            0   \n",
       "\n",
       "   count_vectorizer__along  count_vectorizer__also  count_vectorizer__amount  \\\n",
       "0                        0                       0                         0   \n",
       "1                        0                       0                         0   \n",
       "2                        0                       0                         0   \n",
       "3                        0                       2                         0   \n",
       "4                        0                       0                         0   \n",
       "5                        0                       0                         0   \n",
       "6                        0                       0                         0   \n",
       "7                        0                       0                         0   \n",
       "8                        0                       0                         1   \n",
       "9                        0                       0                         0   \n",
       "\n",
       "   count_vectorizer__anoth  count_vectorizer__arrang  count_vectorizer__ask  \\\n",
       "0                        0                         0                      0   \n",
       "1                        0                         0                      0   \n",
       "2                        0                         0                      0   \n",
       "3                        0                         0                      3   \n",
       "4                        0                         0                      0   \n",
       "5                        0                         0                      0   \n",
       "6                        0                         0                      0   \n",
       "7                        0                         0                      0   \n",
       "8                        0                         0                      0   \n",
       "9                        0                         0                      0   \n",
       "\n",
       "   count_vectorizer__assist  count_vectorizer__assur  \\\n",
       "0                         0                        0   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         1                        0   \n",
       "5                         0                        0   \n",
       "6                         0                        0   \n",
       "7                         0                        0   \n",
       "8                         1                        1   \n",
       "9                         0                        0   \n",
       "\n",
       "   count_vectorizer__attent  count_vectorizer__back  count_vectorizer__bank  \\\n",
       "0                         0                       0                       0   \n",
       "1                         0                       0                       0   \n",
       "2                         0                       0                       0   \n",
       "3                         0                       0                       5   \n",
       "4                         0                       0                       0   \n",
       "5                         0                       0                       0   \n",
       "6                         0                       0                       0   \n",
       "7                         0                       1                       5   \n",
       "8                         0                       0                       0   \n",
       "9                         0                       0                       0   \n",
       "\n",
       "   count_vectorizer__base  count_vectorizer__behalf  count_vectorizer__believ  \\\n",
       "0                       0                         0                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       0                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       0                         0                         0   \n",
       "5                       0                         0                         0   \n",
       "6                       0                         0                         0   \n",
       "7                       0                         0                         0   \n",
       "8                       1                         0                         0   \n",
       "9                       0                         0                         0   \n",
       "\n",
       "   count_vectorizer__beneficiari  count_vectorizer__best  \\\n",
       "0                              0                       0   \n",
       "1                              0                       0   \n",
       "2                              0                       0   \n",
       "3                              1                       0   \n",
       "4                              0                       0   \n",
       "5                              0                       0   \n",
       "6                              0                       0   \n",
       "7                              1                       0   \n",
       "8                              0                       1   \n",
       "9                              0                       0   \n",
       "\n",
       "   count_vectorizer__bless  count_vectorizer__busi  count_vectorizer__call  \\\n",
       "0                        0                       0                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       0                       0   \n",
       "3                        2                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "5                        0                       0                       1   \n",
       "6                        0                       0                       0   \n",
       "7                        0                       1                       0   \n",
       "8                        0                       2                       0   \n",
       "9                        0                       0                       0   \n",
       "\n",
       "   count_vectorizer__care  count_vectorizer__case  count_vectorizer__chang  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       1                       0                        0   \n",
       "4                       0                       0                        0   \n",
       "5                       0                       0                        0   \n",
       "6                       0                       0                        0   \n",
       "7                       0                       0                        0   \n",
       "8                       0                       0                        0   \n",
       "9                       0                       0                        0   \n",
       "\n",
       "   count_vectorizer__choos  count_vectorizer__claim  count_vectorizer__click  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        1                        0                        2   \n",
       "5                        0                        0                        0   \n",
       "6                        0                        0                        0   \n",
       "7                        0                        0                        0   \n",
       "8                        0                        4                        0   \n",
       "9                        0                        0                        0   \n",
       "\n",
       "   count_vectorizer__client  count_vectorizer__close  count_vectorizer__come  \\\n",
       "0                         0                        0                       0   \n",
       "1                         0                        0                       0   \n",
       "2                         0                        0                       0   \n",
       "3                         2                        0                       2   \n",
       "4                         0                        0                       0   \n",
       "5                         0                        0                       0   \n",
       "6                         0                        0                       0   \n",
       "7                         0                        0                       0   \n",
       "8                         0                        0                       2   \n",
       "9                         0                        0                       0   \n",
       "\n",
       "   count_vectorizer__commun  count_vectorizer__compani  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          3   \n",
       "8                         1                          2   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__complet  count_vectorizer__concern  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          1                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__confid  count_vectorizer__confidenti  \\\n",
       "0                         0                             0   \n",
       "1                         0                             0   \n",
       "2                         0                             0   \n",
       "3                         2                             0   \n",
       "4                         0                             0   \n",
       "5                         0                             0   \n",
       "6                         0                             0   \n",
       "7                         0                             2   \n",
       "8                         1                             2   \n",
       "9                         0                             0   \n",
       "\n",
       "   count_vectorizer__confirm  count_vectorizer__contact  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          2   \n",
       "4                          1                          0   \n",
       "5                          1                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          1   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__corpor  count_vectorizer__could  \\\n",
       "0                         0                        0   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "5                         0                        0   \n",
       "6                         0                        0   \n",
       "7                         0                        0   \n",
       "8                         0                        0   \n",
       "9                         0                        0   \n",
       "\n",
       "   count_vectorizer__countri  count_vectorizer__cours  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          1                        0   \n",
       "5                          0                        0   \n",
       "6                          0                        0   \n",
       "7                          2                        0   \n",
       "8                          1                        0   \n",
       "9                          0                        0   \n",
       "\n",
       "   count_vectorizer__current  count_vectorizer__custom  count_vectorizer__day  \\\n",
       "0                          0                         0                      1   \n",
       "1                          0                         0                      0   \n",
       "2                          0                         0                      1   \n",
       "3                          0                         1                      0   \n",
       "4                          0                         0                      0   \n",
       "5                          0                         0                      0   \n",
       "6                          0                         0                      0   \n",
       "7                          1                         0                      1   \n",
       "8                          0                         0                      1   \n",
       "9                          0                         0                      0   \n",
       "\n",
       "   count_vectorizer__deal  count_vectorizer__dear  count_vectorizer__death  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       1                       0                        0   \n",
       "4                       0                       0                        0   \n",
       "5                       0                       0                        0   \n",
       "6                       0                       0                        0   \n",
       "7                       0                       0                        0   \n",
       "8                       1                       0                        0   \n",
       "9                       0                       0                        0   \n",
       "\n",
       "   count_vectorizer__deceas  count_vectorizer__decid  \\\n",
       "0                         0                        0   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         2                        0   \n",
       "4                         0                        0   \n",
       "5                         0                        0   \n",
       "6                         0                        0   \n",
       "7                         0                        0   \n",
       "8                         0                        1   \n",
       "9                         0                        0   \n",
       "\n",
       "   count_vectorizer__depart  count_vectorizer__deposit  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         1                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__develop  count_vectorizer__direct  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         1   \n",
       "4                          0                         0   \n",
       "5                          0                         0   \n",
       "6                          0                         0   \n",
       "7                          3                         0   \n",
       "8                          0                         0   \n",
       "9                          0                         0   \n",
       "\n",
       "   count_vectorizer__discov  count_vectorizer__discuss  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__done  count_vectorizer__due  count_vectorizer__easi  \\\n",
       "0                       0                      0                       0   \n",
       "1                       0                      0                       0   \n",
       "2                       0                      0                       0   \n",
       "3                       0                      0                       1   \n",
       "4                       0                      0                       0   \n",
       "5                       0                      0                       0   \n",
       "6                       0                      0                       0   \n",
       "7                       0                      0                       0   \n",
       "8                       2                      1                       0   \n",
       "9                       0                      0                       0   \n",
       "\n",
       "   count_vectorizer__enabl  count_vectorizer__end  count_vectorizer__even  \\\n",
       "0                        0                      0                       0   \n",
       "1                        0                      0                       0   \n",
       "2                        0                      0                       0   \n",
       "3                        0                      1                       0   \n",
       "4                        0                      0                       0   \n",
       "5                        0                      0                       0   \n",
       "6                        0                      0                       0   \n",
       "7                        0                      0                       0   \n",
       "8                        0                      0                       0   \n",
       "9                        0                      0                       0   \n",
       "\n",
       "   count_vectorizer__everi  count_vectorizer__execut  count_vectorizer__fact  \\\n",
       "0                        0                         0                       0   \n",
       "1                        0                         0                       0   \n",
       "2                        1                         0                       0   \n",
       "3                        0                         0                       1   \n",
       "4                        0                         0                       0   \n",
       "5                        0                         0                       0   \n",
       "6                        0                         0                       0   \n",
       "7                        0                         3                       0   \n",
       "8                        0                         1                       0   \n",
       "9                        0                         0                       0   \n",
       "\n",
       "   count_vectorizer__faith  count_vectorizer__famili  \\\n",
       "0                        0                         0   \n",
       "1                        0                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         3   \n",
       "4                        0                         0   \n",
       "5                        0                         0   \n",
       "6                        0                         0   \n",
       "7                        0                         0   \n",
       "8                        0                         0   \n",
       "9                        0                         0   \n",
       "\n",
       "   count_vectorizer__father  count_vectorizer__file  count_vectorizer__final  \\\n",
       "0                         0                       0                        0   \n",
       "1                         0                       0                        0   \n",
       "2                         0                       0                        0   \n",
       "3                         0                       0                        0   \n",
       "4                         0                       0                        0   \n",
       "5                         0                       0                        0   \n",
       "6                         0                       0                        0   \n",
       "7                         0                       0                        1   \n",
       "8                         0                       0                        1   \n",
       "9                         0                       0                        0   \n",
       "\n",
       "   count_vectorizer__financi  count_vectorizer__find  count_vectorizer__first  \\\n",
       "0                          0                       0                        0   \n",
       "1                          0                       0                        0   \n",
       "2                          0                       0                        1   \n",
       "3                          0                       3                        0   \n",
       "4                          0                       0                        0   \n",
       "5                          0                       0                        0   \n",
       "6                          0                       0                        0   \n",
       "7                          0                       0                        0   \n",
       "8                          0                       0                        0   \n",
       "9                          0                       0                        0   \n",
       "\n",
       "   count_vectorizer__five  count_vectorizer__follow  \\\n",
       "0                       0                         0   \n",
       "1                       0                         0   \n",
       "2                       0                         0   \n",
       "3                       0                         0   \n",
       "4                       0                         0   \n",
       "5                       0                         0   \n",
       "6                       0                         0   \n",
       "7                       1                         0   \n",
       "8                       0                         0   \n",
       "9                       0                         0   \n",
       "\n",
       "   count_vectorizer__foreign  count_vectorizer__form  \\\n",
       "0                          0                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       0   \n",
       "3                          1                       0   \n",
       "4                          1                       0   \n",
       "5                          0                       0   \n",
       "6                          0                       0   \n",
       "7                          3                       0   \n",
       "8                          4                       0   \n",
       "9                          0                       0   \n",
       "\n",
       "   count_vectorizer__former  count_vectorizer__forward  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          1   \n",
       "8                         0                          4   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__free  count_vectorizer__friend  count_vectorizer__full  \\\n",
       "0                       0                         0                       0   \n",
       "1                       0                         0                       0   \n",
       "2                       0                         0                       0   \n",
       "3                       0                         0                       0   \n",
       "4                       0                         0                       1   \n",
       "5                       0                         0                       0   \n",
       "6                       0                         0                       0   \n",
       "7                       1                         0                       0   \n",
       "8                       0                         0                       1   \n",
       "9                       0                         0                       0   \n",
       "\n",
       "   count_vectorizer__fund  count_vectorizer__futur  count_vectorizer__gener  \\\n",
       "0                       0                        0                        0   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        0   \n",
       "3                       1                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "5                       0                        0                        0   \n",
       "6                       0                        0                        0   \n",
       "7                       4                        1                        0   \n",
       "8                       5                        0                        2   \n",
       "9                       0                        0                        0   \n",
       "\n",
       "   count_vectorizer__get  count_vectorizer__give  count_vectorizer__given  \\\n",
       "0                      0                       0                        0   \n",
       "1                      0                       0                        0   \n",
       "2                      0                       0                        0   \n",
       "3                      0                       3                        0   \n",
       "4                      0                       0                        0   \n",
       "5                      0                       0                        0   \n",
       "6                      0                       0                        0   \n",
       "7                      0                       0                        0   \n",
       "8                      2                       1                        1   \n",
       "9                      0                       0                        0   \n",
       "\n",
       "   count_vectorizer__go  count_vectorizer__god  count_vectorizer__good  \\\n",
       "0                     0                      0                       0   \n",
       "1                     0                      0                       0   \n",
       "2                     0                      0                       0   \n",
       "3                     0                      0                       2   \n",
       "4                     1                      0                       0   \n",
       "5                     0                      0                       0   \n",
       "6                     0                      0                       0   \n",
       "7                     0                      0                       0   \n",
       "8                     0                      0                       1   \n",
       "9                     0                      0                       0   \n",
       "\n",
       "   count_vectorizer__got  count_vectorizer__govern  count_vectorizer__great  \\\n",
       "0                      0                         0                        1   \n",
       "1                      0                         0                        0   \n",
       "2                      0                         0                        0   \n",
       "3                      0                         0                        0   \n",
       "4                      0                         0                        0   \n",
       "5                      0                         0                        0   \n",
       "6                      0                         0                        0   \n",
       "7                      0                         3                        0   \n",
       "8                      0                         2                        0   \n",
       "9                      0                         0                        0   \n",
       "\n",
       "   count_vectorizer__group  count_vectorizer__hear  count_vectorizer__help  \\\n",
       "0                        0                       0                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       0                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       1   \n",
       "5                        0                       0                       0   \n",
       "6                        0                       0                       0   \n",
       "7                        0                       0                       0   \n",
       "8                        0                       1                       1   \n",
       "9                        0                       0                       0   \n",
       "\n",
       "   count_vectorizer__henc  count_vectorizer__home  count_vectorizer__hope  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "5                       0                       0                       0   \n",
       "6                       0                       0                       0   \n",
       "7                       0                       0                       0   \n",
       "8                       2                       0                       0   \n",
       "9                       0                       0                       0   \n",
       "\n",
       "   count_vectorizer__hous  count_vectorizer__howev  count_vectorizer__hundr  \\\n",
       "0                       0                        0                        0   \n",
       "1                       0                        0                        0   \n",
       "2                       1                        0                        0   \n",
       "3                       0                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "5                       0                        0                        0   \n",
       "6                       0                        0                        0   \n",
       "7                       0                        1                        1   \n",
       "8                       0                        0                        0   \n",
       "9                       0                        0                        0   \n",
       "\n",
       "   count_vectorizer__id  count_vectorizer__immedi  count_vectorizer__import  \\\n",
       "0                     0                         0                         0   \n",
       "1                     0                         0                         0   \n",
       "2                     0                         0                         0   \n",
       "3                     0                         0                         0   \n",
       "4                     0                         0                         0   \n",
       "5                     0                         0                         0   \n",
       "6                     0                         0                         0   \n",
       "7                     0                         0                         0   \n",
       "8                     0                         1                         0   \n",
       "9                     0                         0                         0   \n",
       "\n",
       "   count_vectorizer__includ  count_vectorizer__inform  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         1   \n",
       "3                         0                         2   \n",
       "4                         0                         2   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         0   \n",
       "8                         0                         1   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__interest  count_vectorizer__intern  \\\n",
       "0                           0                         0   \n",
       "1                           0                         0   \n",
       "2                           0                         0   \n",
       "3                           2                         2   \n",
       "4                           0                         0   \n",
       "5                           0                         0   \n",
       "6                           0                         0   \n",
       "7                           0                         0   \n",
       "8                           0                         0   \n",
       "9                           0                         0   \n",
       "\n",
       "   count_vectorizer__invest  count_vectorizer__involv  count_vectorizer__issu  \\\n",
       "0                         0                         0                       0   \n",
       "1                         0                         0                       0   \n",
       "2                         0                         0                       0   \n",
       "3                         0                         1                       0   \n",
       "4                         0                         0                       1   \n",
       "5                         0                         0                       0   \n",
       "6                         0                         0                       0   \n",
       "7                         0                         0                       0   \n",
       "8                         0                         3                       0   \n",
       "9                         0                         0                       0   \n",
       "\n",
       "   count_vectorizer__keep  count_vectorizer__kin  count_vectorizer__know  \\\n",
       "0                       0                      0                       0   \n",
       "1                       0                      0                       0   \n",
       "2                       0                      0                       0   \n",
       "3                       0                      0                       4   \n",
       "4                       0                      0                       0   \n",
       "5                       0                      0                       0   \n",
       "6                       0                      0                       0   \n",
       "7                       0                      0                       0   \n",
       "8                       1                      0                       0   \n",
       "9                       0                      0                       0   \n",
       "\n",
       "   count_vectorizer__last  count_vectorizer__late  count_vectorizer__law  \\\n",
       "0                       0                       0                      0   \n",
       "1                       0                       0                      0   \n",
       "2                       0                       0                      0   \n",
       "3                       0                       0                      0   \n",
       "4                       0                       0                      0   \n",
       "5                       0                       0                      0   \n",
       "6                       0                       0                      0   \n",
       "7                       0                       0                      1   \n",
       "8                       0                       0                      0   \n",
       "9                       0                       0                      0   \n",
       "\n",
       "   count_vectorizer__leav  count_vectorizer__left  count_vectorizer__legal  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       0                       0                        0   \n",
       "4                       0                       0                        0   \n",
       "5                       0                       0                        0   \n",
       "6                       0                       0                        0   \n",
       "7                       0                       0                        1   \n",
       "8                       0                       0                        0   \n",
       "9                       0                       0                        0   \n",
       "\n",
       "   count_vectorizer__let  count_vectorizer__letter  count_vectorizer__life  \\\n",
       "0                      0                         0                       0   \n",
       "1                      0                         0                       0   \n",
       "2                      0                         0                       0   \n",
       "3                      3                         1                       2   \n",
       "4                      0                         0                       0   \n",
       "5                      0                         0                       0   \n",
       "6                      0                         0                       0   \n",
       "7                      0                         0                       0   \n",
       "8                      0                         0                       0   \n",
       "9                      0                         0                       0   \n",
       "\n",
       "   count_vectorizer__like  count_vectorizer__link  count_vectorizer__list  \\\n",
       "0                       1                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       2                       1                       0   \n",
       "4                       0                       1                       0   \n",
       "5                       0                       0                       0   \n",
       "6                       0                       0                       0   \n",
       "7                       0                       0                       0   \n",
       "8                       1                       0                       0   \n",
       "9                       0                       0                       0   \n",
       "\n",
       "   count_vectorizer__live  count_vectorizer__long  count_vectorizer__look  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "5                       0                       0                       0   \n",
       "6                       0                       0                       0   \n",
       "7                       0                       0                       2   \n",
       "8                       0                       0                       1   \n",
       "9                       0                       0                       0   \n",
       "\n",
       "   count_vectorizer__made  count_vectorizer__mail  count_vectorizer__mailman  \\\n",
       "0                       0                       0                          1   \n",
       "1                       0                       0                          0   \n",
       "2                       0                       0                          0   \n",
       "3                       1                       2                          0   \n",
       "4                       0                       2                          0   \n",
       "5                       0                       0                          0   \n",
       "6                       0                       0                          0   \n",
       "7                       1                       2                          0   \n",
       "8                       1                       0                          0   \n",
       "9                       0                       0                          0   \n",
       "\n",
       "   count_vectorizer__make  count_vectorizer__manag  count_vectorizer__mani  \\\n",
       "0                       0                        0                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       0                        0                       1   \n",
       "3                       2                        1                       0   \n",
       "4                       0                        0                       0   \n",
       "5                       0                        0                       0   \n",
       "6                       0                        0                       0   \n",
       "7                       0                        0                       0   \n",
       "8                       2                        2                       0   \n",
       "9                       0                        0                       0   \n",
       "\n",
       "   count_vectorizer__matter  count_vectorizer__may  count_vectorizer__meet  \\\n",
       "0                         0                      0                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      0                       0   \n",
       "3                         0                      2                       1   \n",
       "4                         0                      1                       0   \n",
       "5                         0                      0                       0   \n",
       "6                         0                      0                       0   \n",
       "7                         1                      0                       0   \n",
       "8                         1                      0                       1   \n",
       "9                         0                      0                       0   \n",
       "\n",
       "   count_vectorizer__member  count_vectorizer__messag  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         1   \n",
       "4                         0                         0   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         0   \n",
       "8                         0                         0   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__might  count_vectorizer__million  \\\n",
       "0                        0                          1   \n",
       "1                        0                          0   \n",
       "2                        0                          0   \n",
       "3                        0                          0   \n",
       "4                        0                          0   \n",
       "5                        0                          0   \n",
       "6                        0                          0   \n",
       "7                        0                          2   \n",
       "8                        0                          4   \n",
       "9                        0                          0   \n",
       "\n",
       "   count_vectorizer__money  count_vectorizer__move  count_vectorizer__much  \\\n",
       "0                        0                       0                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       0                       1   \n",
       "3                        0                       2                       0   \n",
       "4                        0                       0                       0   \n",
       "5                        0                       0                       0   \n",
       "6                        0                       0                       0   \n",
       "7                        1                       0                       0   \n",
       "8                        0                       0                       1   \n",
       "9                        0                       0                       0   \n",
       "\n",
       "   count_vectorizer__must  count_vectorizer__name  count_vectorizer__nation  \\\n",
       "0                       0                       0                         0   \n",
       "1                       0                       0                         0   \n",
       "2                       0                       0                         0   \n",
       "3                       0                       1                         0   \n",
       "4                       0                       0                         0   \n",
       "5                       0                       0                         0   \n",
       "6                       0                       0                         0   \n",
       "7                       1                       3                         0   \n",
       "8                       0                       0                         0   \n",
       "9                       0                       0                         0   \n",
       "\n",
       "   count_vectorizer__necessari  count_vectorizer__need  count_vectorizer__net  \\\n",
       "0                            0                       0                      0   \n",
       "1                            0                       0                      0   \n",
       "2                            0                       0                      0   \n",
       "3                            0                       2                      0   \n",
       "4                            1                       0                      0   \n",
       "5                            0                       0                      0   \n",
       "6                            0                       0                      0   \n",
       "7                            0                       1                      0   \n",
       "8                            0                       1                      0   \n",
       "9                            0                       0                      0   \n",
       "\n",
       "   count_vectorizer__never  count_vectorizer__new  count_vectorizer__next  \\\n",
       "0                        0                      0                       0   \n",
       "1                        0                      0                       0   \n",
       "2                        1                      0                       0   \n",
       "3                        1                      1                       1   \n",
       "4                        0                      0                       0   \n",
       "5                        0                      0                       0   \n",
       "6                        0                      0                       0   \n",
       "7                        0                      0                       0   \n",
       "8                        0                      0                       0   \n",
       "9                        0                      0                       0   \n",
       "\n",
       "   count_vectorizer__note  count_vectorizer__number  count_vectorizer__offer  \\\n",
       "0                       0                         0                        0   \n",
       "1                       0                         0                        0   \n",
       "2                       0                         0                        0   \n",
       "3                       1                         0                        1   \n",
       "4                       0                         0                        0   \n",
       "5                       0                         0                        0   \n",
       "6                       0                         0                        0   \n",
       "7                       1                         1                        0   \n",
       "8                       1                         1                        1   \n",
       "9                       0                         0                        0   \n",
       "\n",
       "   count_vectorizer__offic  count_vectorizer__offici  count_vectorizer__old  \\\n",
       "0                        0                         0                      0   \n",
       "1                        0                         0                      0   \n",
       "2                        0                         0                      0   \n",
       "3                        0                         4                      0   \n",
       "4                        0                         0                      0   \n",
       "5                        0                         0                      0   \n",
       "6                        0                         0                      0   \n",
       "7                        0                         0                      0   \n",
       "8                        2                         0                      0   \n",
       "9                        0                         0                      0   \n",
       "\n",
       "   count_vectorizer__one  count_vectorizer__open  count_vectorizer__oper  \\\n",
       "0                      0                       0                       0   \n",
       "1                      0                       0                       0   \n",
       "2                      0                       0                       0   \n",
       "3                      3                       0                       0   \n",
       "4                      1                       0                       0   \n",
       "5                      0                       0                       0   \n",
       "6                      0                       0                       0   \n",
       "7                      0                       0                       1   \n",
       "8                      0                       0                       2   \n",
       "9                      0                       0                       0   \n",
       "\n",
       "   count_vectorizer__order  count_vectorizer__part  count_vectorizer__partner  \\\n",
       "0                        0                       0                          0   \n",
       "1                        0                       0                          0   \n",
       "2                        0                       0                          0   \n",
       "3                        0                       0                          1   \n",
       "4                        0                       0                          0   \n",
       "5                        0                       0                          0   \n",
       "6                        0                       0                          0   \n",
       "7                        0                       0                          2   \n",
       "8                        1                       0                          1   \n",
       "9                        0                       0                          0   \n",
       "\n",
       "   count_vectorizer__peopl  count_vectorizer__person  count_vectorizer__phone  \\\n",
       "0                        0                         0                        0   \n",
       "1                        0                         0                        0   \n",
       "2                        0                         0                        0   \n",
       "3                        1                         0                        1   \n",
       "4                        0                         0                        0   \n",
       "5                        0                         0                        0   \n",
       "6                        0                         0                        0   \n",
       "7                        0                         0                        0   \n",
       "8                        0                         1                        0   \n",
       "9                        0                         0                        0   \n",
       "\n",
       "   count_vectorizer__place  count_vectorizer__pleas  count_vectorizer__polici  \\\n",
       "0                        0                        0                         0   \n",
       "1                        0                        0                         0   \n",
       "2                        0                        0                         0   \n",
       "3                        0                        2                         1   \n",
       "4                        0                        2                         0   \n",
       "5                        0                        0                         0   \n",
       "6                        0                        0                         0   \n",
       "7                        1                        1                         0   \n",
       "8                        0                        0                         0   \n",
       "9                        0                        0                         0   \n",
       "\n",
       "   count_vectorizer__polit  count_vectorizer__posit  \\\n",
       "0                        0                        0   \n",
       "1                        0                        0   \n",
       "2                        0                        0   \n",
       "3                        0                        1   \n",
       "4                        0                        0   \n",
       "5                        0                        0   \n",
       "6                        0                        0   \n",
       "7                        0                        1   \n",
       "8                        0                        2   \n",
       "9                        0                        0   \n",
       "\n",
       "   count_vectorizer__possibl  count_vectorizer__present  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          1                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          1   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__presid  count_vectorizer__privat  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         2   \n",
       "4                         0                         0   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         0   \n",
       "8                         1                         1   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__problem  count_vectorizer__process  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          1   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__propos  count_vectorizer__protect  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         2                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          0   \n",
       "8                         1                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__provid  count_vectorizer__put  count_vectorizer__read  \\\n",
       "0                         0                      0                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      0                       0   \n",
       "3                         3                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "5                         0                      0                       0   \n",
       "6                         0                      0                       0   \n",
       "7                         2                      1                       0   \n",
       "8                         0                      1                       0   \n",
       "9                         0                      0                       0   \n",
       "\n",
       "   count_vectorizer__real  count_vectorizer__reason  count_vectorizer__receiv  \\\n",
       "0                       0                         0                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       0                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       0                         0                         1   \n",
       "5                       0                         0                         0   \n",
       "6                       0                         0                         0   \n",
       "7                       0                         1                         0   \n",
       "8                       0                         0                         1   \n",
       "9                       0                         0                         0   \n",
       "\n",
       "   count_vectorizer__recent  count_vectorizer__releas  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         0   \n",
       "8                         0                         0   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__reliabl  count_vectorizer__repli  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        1   \n",
       "5                          0                        0   \n",
       "6                          0                        0   \n",
       "7                          0                        1   \n",
       "8                          2                        1   \n",
       "9                          0                        0   \n",
       "\n",
       "   count_vectorizer__request  count_vectorizer__reserv  \\\n",
       "0                          0                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "5                          0                         0   \n",
       "6                          0                         0   \n",
       "7                          0                         0   \n",
       "8                          0                         0   \n",
       "9                          0                         0   \n",
       "\n",
       "   count_vectorizer__respect  count_vectorizer__respons  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          2   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          1   \n",
       "8                          0                          2   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__result  count_vectorizer__right  count_vectorizer__risk  \\\n",
       "0                         0                        0                       0   \n",
       "1                         0                        0                       0   \n",
       "2                         0                        0                       0   \n",
       "3                         0                        0                       2   \n",
       "4                         0                        0                       0   \n",
       "5                         0                        0                       0   \n",
       "6                         0                        0                       0   \n",
       "7                         0                        0                       1   \n",
       "8                         0                        1                       1   \n",
       "9                         0                        0                       0   \n",
       "\n",
       "   count_vectorizer__run  count_vectorizer__safe  count_vectorizer__said  \\\n",
       "0                      0                       0                       0   \n",
       "1                      0                       0                       0   \n",
       "2                      0                       0                       0   \n",
       "3                      1                       0                       1   \n",
       "4                      0                       0                       0   \n",
       "5                      0                       0                       0   \n",
       "6                      0                       0                       0   \n",
       "7                      0                       0                       0   \n",
       "8                      0                       2                       0   \n",
       "9                      0                       0                       0   \n",
       "\n",
       "   count_vectorizer__say  count_vectorizer__search  count_vectorizer__secur  \\\n",
       "0                      0                         0                        0   \n",
       "1                      0                         0                        0   \n",
       "2                      0                         0                        0   \n",
       "3                      0                         0                        1   \n",
       "4                      0                         0                        3   \n",
       "5                      0                         0                        0   \n",
       "6                      0                         0                        0   \n",
       "7                      0                         0                        0   \n",
       "8                      0                         0                        0   \n",
       "9                      0                         0                        0   \n",
       "\n",
       "   count_vectorizer__see  count_vectorizer__seek  count_vectorizer__send  \\\n",
       "0                      0                       0                       0   \n",
       "1                      1                       0                       0   \n",
       "2                      0                       0                       0   \n",
       "3                      0                       0                       1   \n",
       "4                      0                       0                       0   \n",
       "5                      0                       0                       0   \n",
       "6                      0                       0                       0   \n",
       "7                      0                       0                       0   \n",
       "8                      0                       0                       0   \n",
       "9                      0                       0                       0   \n",
       "\n",
       "   count_vectorizer__sent  count_vectorizer__servic  count_vectorizer__set  \\\n",
       "0                       0                         0                      0   \n",
       "1                       0                         0                      0   \n",
       "2                       0                         0                      0   \n",
       "3                       1                         0                      1   \n",
       "4                       1                         0                      0   \n",
       "5                       0                         0                      0   \n",
       "6                       0                         0                      0   \n",
       "7                       0                         0                      0   \n",
       "8                       0                         1                      0   \n",
       "9                       0                         0                      0   \n",
       "\n",
       "   count_vectorizer__shall  count_vectorizer__share  count_vectorizer__sinc  \\\n",
       "0                        0                        0                       0   \n",
       "1                        0                        0                       0   \n",
       "2                        0                        0                       0   \n",
       "3                        0                        0                       0   \n",
       "4                        0                        0                       0   \n",
       "5                        0                        0                       0   \n",
       "6                        0                        0                       0   \n",
       "7                        2                        0                       0   \n",
       "8                        1                        0                       0   \n",
       "9                        0                        0                       0   \n",
       "\n",
       "   count_vectorizer__sincer  count_vectorizer__sir  count_vectorizer__site  \\\n",
       "0                         0                      0                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      0                       0   \n",
       "3                         0                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "5                         0                      0                       0   \n",
       "6                         0                      0                       0   \n",
       "7                         0                      0                       0   \n",
       "8                         0                      1                       0   \n",
       "9                         0                      0                       0   \n",
       "\n",
       "   count_vectorizer__son  count_vectorizer__soon  count_vectorizer__stand  \\\n",
       "0                      0                       0                        0   \n",
       "1                      0                       0                        0   \n",
       "2                      0                       0                        0   \n",
       "3                      0                       1                        1   \n",
       "4                      0                       1                        0   \n",
       "5                      0                       0                        0   \n",
       "6                      0                       0                        0   \n",
       "7                      0                       0                        0   \n",
       "8                      0                       2                        0   \n",
       "9                      0                       0                        0   \n",
       "\n",
       "   count_vectorizer__start  count_vectorizer__state  count_vectorizer__still  \\\n",
       "0                        0                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        2                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "5                        1                        0                        0   \n",
       "6                        0                        0                        0   \n",
       "7                        0                        0                        0   \n",
       "8                        0                        1                        1   \n",
       "9                        0                        0                        0   \n",
       "\n",
       "   count_vectorizer__success  count_vectorizer__sum  \\\n",
       "0                          0                      0   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          1                      0   \n",
       "4                          0                      0   \n",
       "5                          0                      0   \n",
       "6                          0                      0   \n",
       "7                          0                      1   \n",
       "8                          0                      1   \n",
       "9                          0                      0   \n",
       "\n",
       "   count_vectorizer__support  count_vectorizer__sure  \\\n",
       "0                          0                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       0   \n",
       "3                          0                       1   \n",
       "4                          0                       0   \n",
       "5                          0                       0   \n",
       "6                          0                       0   \n",
       "7                          1                       0   \n",
       "8                          3                       0   \n",
       "9                          0                       0   \n",
       "\n",
       "   count_vectorizer__system  count_vectorizer__take  \\\n",
       "0                         0                       1   \n",
       "1                         0                       0   \n",
       "2                         0                       0   \n",
       "3                         0                       0   \n",
       "4                         0                       0   \n",
       "5                         0                       0   \n",
       "6                         0                       0   \n",
       "7                         0                       0   \n",
       "8                         0                       0   \n",
       "9                         0                       0   \n",
       "\n",
       "   count_vectorizer__telephon  count_vectorizer__th  count_vectorizer__thank  \\\n",
       "0                           0                     0                        0   \n",
       "1                           0                     0                        0   \n",
       "2                           0                     0                        1   \n",
       "3                           0                     0                        0   \n",
       "4                           0                     0                        1   \n",
       "5                           0                     0                        0   \n",
       "6                           0                     0                        0   \n",
       "7                           0                     0                        0   \n",
       "8                           2                     0                        0   \n",
       "9                           0                     0                        0   \n",
       "\n",
       "   count_vectorizer__therefor  count_vectorizer__think  \\\n",
       "0                           0                        0   \n",
       "1                           0                        0   \n",
       "2                           0                        0   \n",
       "3                           0                        0   \n",
       "4                           0                        0   \n",
       "5                           0                        0   \n",
       "6                           0                        0   \n",
       "7                           0                        0   \n",
       "8                           0                        0   \n",
       "9                           0                        0   \n",
       "\n",
       "   count_vectorizer__though  count_vectorizer__thousand  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           0   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "5                         0                           0   \n",
       "6                         0                           0   \n",
       "7                         0                           0   \n",
       "8                         0                           0   \n",
       "9                         0                           0   \n",
       "\n",
       "   count_vectorizer__time  count_vectorizer__today  count_vectorizer__told  \\\n",
       "0                       0                        0                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       0                        4                       0   \n",
       "3                       1                        0                       0   \n",
       "4                       1                        0                       0   \n",
       "5                       0                        0                       0   \n",
       "6                       0                        0                       0   \n",
       "7                       0                        0                       0   \n",
       "8                       1                        0                       0   \n",
       "9                       0                        0                       0   \n",
       "\n",
       "   count_vectorizer__top  count_vectorizer__total  count_vectorizer__transact  \\\n",
       "0                      0                        0                           0   \n",
       "1                      0                        0                           0   \n",
       "2                      0                        0                           0   \n",
       "3                      0                        2                           4   \n",
       "4                      0                        0                           0   \n",
       "5                      0                        0                           0   \n",
       "6                      0                        0                           0   \n",
       "7                      1                        1                           5   \n",
       "8                      1                        2                           1   \n",
       "9                      4                        0                           0   \n",
       "\n",
       "   count_vectorizer__transfer  count_vectorizer__tri  count_vectorizer__trust  \\\n",
       "0                           0                      0                        0   \n",
       "1                           0                      0                        0   \n",
       "2                           0                      0                        0   \n",
       "3                           0                      0                        2   \n",
       "4                           0                      0                        0   \n",
       "5                           0                      0                        0   \n",
       "6                           0                      0                        0   \n",
       "7                           5                      0                        1   \n",
       "8                           1                      0                        1   \n",
       "9                           0                      0                        0   \n",
       "\n",
       "   count_vectorizer__two  count_vectorizer__understand  \\\n",
       "0                      0                             0   \n",
       "1                      0                             0   \n",
       "2                      0                             0   \n",
       "3                      1                             2   \n",
       "4                      0                             0   \n",
       "5                      0                             0   \n",
       "6                      0                             0   \n",
       "7                      0                             0   \n",
       "8                      2                             0   \n",
       "9                      0                             0   \n",
       "\n",
       "   count_vectorizer__unit  count_vectorizer__updat  count_vectorizer__upon  \\\n",
       "0                       0                        0                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       0                        0                       0   \n",
       "3                       0                        0                       0   \n",
       "4                       0                        1                       0   \n",
       "5                       0                        0                       0   \n",
       "6                       0                        0                       0   \n",
       "7                       1                        1                       1   \n",
       "8                       1                        0                       0   \n",
       "9                       0                        0                       0   \n",
       "\n",
       "   count_vectorizer__urgent  count_vectorizer__us  count_vectorizer__use  \\\n",
       "0                         0                     0                      0   \n",
       "1                         0                     0                      0   \n",
       "2                         0                     0                      0   \n",
       "3                         0                     0                      1   \n",
       "4                         0                     0                      0   \n",
       "5                         0                     0                      0   \n",
       "6                         0                     0                      0   \n",
       "7                         0                     0                      0   \n",
       "8                         0                     7                      0   \n",
       "9                         0                     0                      0   \n",
       "\n",
       "   count_vectorizer__user  count_vectorizer__valu  count_vectorizer__via  \\\n",
       "0                       0                       0                      0   \n",
       "1                       0                       0                      0   \n",
       "2                       0                       0                      0   \n",
       "3                       0                       0                      2   \n",
       "4                       1                       0                      0   \n",
       "5                       0                       0                      0   \n",
       "6                       0                       0                      0   \n",
       "7                       0                       0                      0   \n",
       "8                       0                       0                      0   \n",
       "9                       0                       0                      0   \n",
       "\n",
       "   count_vectorizer__visit  count_vectorizer__want  count_vectorizer__way  \\\n",
       "0                        0                       0                      0   \n",
       "1                        0                       0                      0   \n",
       "2                        0                       0                      0   \n",
       "3                        0                       3                      1   \n",
       "4                        0                       0                      0   \n",
       "5                        0                       0                      0   \n",
       "6                        0                       0                      0   \n",
       "7                        0                       0                      0   \n",
       "8                        0                       0                      0   \n",
       "9                        0                       0                      0   \n",
       "\n",
       "   count_vectorizer__well  count_vectorizer__wish  count_vectorizer__within  \\\n",
       "0                       0                       0                         0   \n",
       "1                       0                       0                         0   \n",
       "2                       0                       0                         0   \n",
       "3                       1                       1                         1   \n",
       "4                       0                       0                         0   \n",
       "5                       0                       0                         0   \n",
       "6                       0                       0                         0   \n",
       "7                       0                       1                         1   \n",
       "8                       0                       0                         0   \n",
       "9                       0                       0                         0   \n",
       "\n",
       "   count_vectorizer__without  count_vectorizer__work  count_vectorizer__world  \\\n",
       "0                          0                       0                        0   \n",
       "1                          0                       0                        0   \n",
       "2                          0                       0                        0   \n",
       "3                          1                       2                        0   \n",
       "4                          0                       0                        0   \n",
       "5                          0                       0                        0   \n",
       "6                          0                       0                        0   \n",
       "7                          0                       1                        0   \n",
       "8                          0                       2                        0   \n",
       "9                          0                       0                        0   \n",
       "\n",
       "   count_vectorizer__would  count_vectorizer__write  count_vectorizer__wrote  \\\n",
       "0                        0                        0                        1   \n",
       "1                        0                        0                        0   \n",
       "2                        1                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "5                        0                        0                        0   \n",
       "6                        0                        0                        0   \n",
       "7                        1                        0                        0   \n",
       "8                        0                        1                        0   \n",
       "9                        0                        0                        0   \n",
       "\n",
       "   count_vectorizer__yahoo  count_vectorizer__year  \\\n",
       "0                        0                       0   \n",
       "1                        0                       0   \n",
       "2                        0                       0   \n",
       "3                        1                       0   \n",
       "4                        0                       0   \n",
       "5                        0                       0   \n",
       "6                        0                       0   \n",
       "7                        0                       0   \n",
       "8                        0                       0   \n",
       "9                        0                       0   \n",
       "\n",
       "   remainder__unsecure_link_count  remainder__secure_link_count  \\\n",
       "0                               3                             0   \n",
       "1                               0                             0   \n",
       "2                               0                             0   \n",
       "3                               0                             0   \n",
       "4                               0                             1   \n",
       "5                               0                             0   \n",
       "6                               0                             0   \n",
       "7                               0                             0   \n",
       "8                               0                             0   \n",
       "9                               0                             0   \n",
       "\n",
       "   remainder__numbers_count  remainder__word_count  \n",
       "0                         5                     56  \n",
       "1                         0                      3  \n",
       "2                         7                     93  \n",
       "3                         1                    680  \n",
       "4                        47                    167  \n",
       "5                         0                      8  \n",
       "6                         0                      1  \n",
       "7                        63                    409  \n",
       "8                        10                    538  \n",
       "9                        24                     43  "
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a data frame from the vectorized data\n",
    "X_train_vec = pd.DataFrame(\n",
    "    data=X_train_vec.toarray(),\n",
    "    columns=cv_transf.get_feature_names_out(),\n",
    ")\n",
    "# Look at the top 10 entries in the data frame\n",
    "X_train_vec.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a4a9853d-1b67-49c7-ab3e-24239b881218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7936, 283)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the resulting shape of the data frame\n",
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c967d0b2-cd6e-46b3-ae9f-664507bb6dba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_vectorizer__abl</th>\n",
       "      <th>count_vectorizer__accept</th>\n",
       "      <th>count_vectorizer__access</th>\n",
       "      <th>count_vectorizer__accord</th>\n",
       "      <th>count_vectorizer__account</th>\n",
       "      <th>count_vectorizer__actual</th>\n",
       "      <th>count_vectorizer__address</th>\n",
       "      <th>count_vectorizer__agre</th>\n",
       "      <th>count_vectorizer__agreement</th>\n",
       "      <th>count_vectorizer__along</th>\n",
       "      <th>count_vectorizer__also</th>\n",
       "      <th>count_vectorizer__amount</th>\n",
       "      <th>count_vectorizer__anoth</th>\n",
       "      <th>count_vectorizer__arrang</th>\n",
       "      <th>count_vectorizer__ask</th>\n",
       "      <th>count_vectorizer__assist</th>\n",
       "      <th>count_vectorizer__assur</th>\n",
       "      <th>count_vectorizer__attent</th>\n",
       "      <th>count_vectorizer__back</th>\n",
       "      <th>count_vectorizer__bank</th>\n",
       "      <th>count_vectorizer__base</th>\n",
       "      <th>count_vectorizer__behalf</th>\n",
       "      <th>count_vectorizer__believ</th>\n",
       "      <th>count_vectorizer__beneficiari</th>\n",
       "      <th>count_vectorizer__best</th>\n",
       "      <th>count_vectorizer__bless</th>\n",
       "      <th>count_vectorizer__busi</th>\n",
       "      <th>count_vectorizer__call</th>\n",
       "      <th>count_vectorizer__care</th>\n",
       "      <th>count_vectorizer__case</th>\n",
       "      <th>count_vectorizer__chang</th>\n",
       "      <th>count_vectorizer__choos</th>\n",
       "      <th>count_vectorizer__claim</th>\n",
       "      <th>count_vectorizer__click</th>\n",
       "      <th>count_vectorizer__client</th>\n",
       "      <th>count_vectorizer__close</th>\n",
       "      <th>count_vectorizer__come</th>\n",
       "      <th>count_vectorizer__commun</th>\n",
       "      <th>count_vectorizer__compani</th>\n",
       "      <th>count_vectorizer__complet</th>\n",
       "      <th>count_vectorizer__concern</th>\n",
       "      <th>count_vectorizer__confid</th>\n",
       "      <th>count_vectorizer__confidenti</th>\n",
       "      <th>count_vectorizer__confirm</th>\n",
       "      <th>count_vectorizer__contact</th>\n",
       "      <th>count_vectorizer__corpor</th>\n",
       "      <th>count_vectorizer__could</th>\n",
       "      <th>count_vectorizer__countri</th>\n",
       "      <th>count_vectorizer__cours</th>\n",
       "      <th>count_vectorizer__current</th>\n",
       "      <th>count_vectorizer__custom</th>\n",
       "      <th>count_vectorizer__day</th>\n",
       "      <th>count_vectorizer__deal</th>\n",
       "      <th>count_vectorizer__dear</th>\n",
       "      <th>count_vectorizer__death</th>\n",
       "      <th>count_vectorizer__deceas</th>\n",
       "      <th>count_vectorizer__decid</th>\n",
       "      <th>count_vectorizer__depart</th>\n",
       "      <th>count_vectorizer__deposit</th>\n",
       "      <th>count_vectorizer__develop</th>\n",
       "      <th>count_vectorizer__direct</th>\n",
       "      <th>count_vectorizer__discov</th>\n",
       "      <th>count_vectorizer__discuss</th>\n",
       "      <th>count_vectorizer__done</th>\n",
       "      <th>count_vectorizer__due</th>\n",
       "      <th>count_vectorizer__easi</th>\n",
       "      <th>count_vectorizer__enabl</th>\n",
       "      <th>count_vectorizer__end</th>\n",
       "      <th>count_vectorizer__even</th>\n",
       "      <th>count_vectorizer__everi</th>\n",
       "      <th>count_vectorizer__execut</th>\n",
       "      <th>count_vectorizer__fact</th>\n",
       "      <th>count_vectorizer__faith</th>\n",
       "      <th>count_vectorizer__famili</th>\n",
       "      <th>count_vectorizer__father</th>\n",
       "      <th>count_vectorizer__file</th>\n",
       "      <th>count_vectorizer__final</th>\n",
       "      <th>count_vectorizer__financi</th>\n",
       "      <th>count_vectorizer__find</th>\n",
       "      <th>count_vectorizer__first</th>\n",
       "      <th>count_vectorizer__five</th>\n",
       "      <th>count_vectorizer__follow</th>\n",
       "      <th>count_vectorizer__foreign</th>\n",
       "      <th>count_vectorizer__form</th>\n",
       "      <th>count_vectorizer__former</th>\n",
       "      <th>count_vectorizer__forward</th>\n",
       "      <th>count_vectorizer__free</th>\n",
       "      <th>count_vectorizer__friend</th>\n",
       "      <th>count_vectorizer__full</th>\n",
       "      <th>count_vectorizer__fund</th>\n",
       "      <th>count_vectorizer__futur</th>\n",
       "      <th>count_vectorizer__gener</th>\n",
       "      <th>count_vectorizer__get</th>\n",
       "      <th>count_vectorizer__give</th>\n",
       "      <th>count_vectorizer__given</th>\n",
       "      <th>count_vectorizer__go</th>\n",
       "      <th>count_vectorizer__god</th>\n",
       "      <th>count_vectorizer__good</th>\n",
       "      <th>count_vectorizer__got</th>\n",
       "      <th>count_vectorizer__govern</th>\n",
       "      <th>count_vectorizer__great</th>\n",
       "      <th>count_vectorizer__group</th>\n",
       "      <th>count_vectorizer__hear</th>\n",
       "      <th>count_vectorizer__help</th>\n",
       "      <th>count_vectorizer__henc</th>\n",
       "      <th>count_vectorizer__home</th>\n",
       "      <th>count_vectorizer__hope</th>\n",
       "      <th>count_vectorizer__hous</th>\n",
       "      <th>count_vectorizer__howev</th>\n",
       "      <th>count_vectorizer__hundr</th>\n",
       "      <th>count_vectorizer__id</th>\n",
       "      <th>count_vectorizer__immedi</th>\n",
       "      <th>count_vectorizer__import</th>\n",
       "      <th>count_vectorizer__includ</th>\n",
       "      <th>count_vectorizer__inform</th>\n",
       "      <th>count_vectorizer__interest</th>\n",
       "      <th>count_vectorizer__intern</th>\n",
       "      <th>count_vectorizer__invest</th>\n",
       "      <th>count_vectorizer__involv</th>\n",
       "      <th>count_vectorizer__issu</th>\n",
       "      <th>count_vectorizer__keep</th>\n",
       "      <th>count_vectorizer__kin</th>\n",
       "      <th>count_vectorizer__know</th>\n",
       "      <th>count_vectorizer__last</th>\n",
       "      <th>count_vectorizer__late</th>\n",
       "      <th>count_vectorizer__law</th>\n",
       "      <th>count_vectorizer__leav</th>\n",
       "      <th>count_vectorizer__left</th>\n",
       "      <th>count_vectorizer__legal</th>\n",
       "      <th>count_vectorizer__let</th>\n",
       "      <th>count_vectorizer__letter</th>\n",
       "      <th>count_vectorizer__life</th>\n",
       "      <th>count_vectorizer__like</th>\n",
       "      <th>count_vectorizer__link</th>\n",
       "      <th>count_vectorizer__list</th>\n",
       "      <th>count_vectorizer__live</th>\n",
       "      <th>count_vectorizer__long</th>\n",
       "      <th>count_vectorizer__look</th>\n",
       "      <th>count_vectorizer__made</th>\n",
       "      <th>count_vectorizer__mail</th>\n",
       "      <th>count_vectorizer__mailman</th>\n",
       "      <th>count_vectorizer__make</th>\n",
       "      <th>count_vectorizer__manag</th>\n",
       "      <th>count_vectorizer__mani</th>\n",
       "      <th>count_vectorizer__matter</th>\n",
       "      <th>count_vectorizer__may</th>\n",
       "      <th>count_vectorizer__meet</th>\n",
       "      <th>count_vectorizer__member</th>\n",
       "      <th>count_vectorizer__messag</th>\n",
       "      <th>count_vectorizer__might</th>\n",
       "      <th>count_vectorizer__million</th>\n",
       "      <th>count_vectorizer__money</th>\n",
       "      <th>count_vectorizer__move</th>\n",
       "      <th>count_vectorizer__much</th>\n",
       "      <th>count_vectorizer__must</th>\n",
       "      <th>count_vectorizer__name</th>\n",
       "      <th>count_vectorizer__nation</th>\n",
       "      <th>count_vectorizer__necessari</th>\n",
       "      <th>count_vectorizer__need</th>\n",
       "      <th>count_vectorizer__net</th>\n",
       "      <th>count_vectorizer__never</th>\n",
       "      <th>count_vectorizer__new</th>\n",
       "      <th>count_vectorizer__next</th>\n",
       "      <th>count_vectorizer__note</th>\n",
       "      <th>count_vectorizer__number</th>\n",
       "      <th>count_vectorizer__offer</th>\n",
       "      <th>count_vectorizer__offic</th>\n",
       "      <th>count_vectorizer__offici</th>\n",
       "      <th>count_vectorizer__old</th>\n",
       "      <th>count_vectorizer__one</th>\n",
       "      <th>count_vectorizer__open</th>\n",
       "      <th>count_vectorizer__oper</th>\n",
       "      <th>count_vectorizer__order</th>\n",
       "      <th>count_vectorizer__part</th>\n",
       "      <th>count_vectorizer__partner</th>\n",
       "      <th>count_vectorizer__peopl</th>\n",
       "      <th>count_vectorizer__person</th>\n",
       "      <th>count_vectorizer__phone</th>\n",
       "      <th>count_vectorizer__place</th>\n",
       "      <th>count_vectorizer__pleas</th>\n",
       "      <th>count_vectorizer__polici</th>\n",
       "      <th>count_vectorizer__polit</th>\n",
       "      <th>count_vectorizer__posit</th>\n",
       "      <th>count_vectorizer__possibl</th>\n",
       "      <th>count_vectorizer__present</th>\n",
       "      <th>count_vectorizer__presid</th>\n",
       "      <th>count_vectorizer__privat</th>\n",
       "      <th>count_vectorizer__problem</th>\n",
       "      <th>count_vectorizer__process</th>\n",
       "      <th>count_vectorizer__propos</th>\n",
       "      <th>count_vectorizer__protect</th>\n",
       "      <th>count_vectorizer__provid</th>\n",
       "      <th>count_vectorizer__put</th>\n",
       "      <th>count_vectorizer__read</th>\n",
       "      <th>count_vectorizer__real</th>\n",
       "      <th>count_vectorizer__reason</th>\n",
       "      <th>count_vectorizer__receiv</th>\n",
       "      <th>count_vectorizer__recent</th>\n",
       "      <th>count_vectorizer__releas</th>\n",
       "      <th>count_vectorizer__reliabl</th>\n",
       "      <th>count_vectorizer__repli</th>\n",
       "      <th>count_vectorizer__request</th>\n",
       "      <th>count_vectorizer__reserv</th>\n",
       "      <th>count_vectorizer__respect</th>\n",
       "      <th>count_vectorizer__respons</th>\n",
       "      <th>count_vectorizer__result</th>\n",
       "      <th>count_vectorizer__right</th>\n",
       "      <th>count_vectorizer__risk</th>\n",
       "      <th>count_vectorizer__run</th>\n",
       "      <th>count_vectorizer__safe</th>\n",
       "      <th>count_vectorizer__said</th>\n",
       "      <th>count_vectorizer__say</th>\n",
       "      <th>count_vectorizer__search</th>\n",
       "      <th>count_vectorizer__secur</th>\n",
       "      <th>count_vectorizer__see</th>\n",
       "      <th>count_vectorizer__seek</th>\n",
       "      <th>count_vectorizer__send</th>\n",
       "      <th>count_vectorizer__sent</th>\n",
       "      <th>count_vectorizer__servic</th>\n",
       "      <th>count_vectorizer__set</th>\n",
       "      <th>count_vectorizer__shall</th>\n",
       "      <th>count_vectorizer__share</th>\n",
       "      <th>count_vectorizer__sinc</th>\n",
       "      <th>count_vectorizer__sincer</th>\n",
       "      <th>count_vectorizer__sir</th>\n",
       "      <th>count_vectorizer__site</th>\n",
       "      <th>count_vectorizer__son</th>\n",
       "      <th>count_vectorizer__soon</th>\n",
       "      <th>count_vectorizer__stand</th>\n",
       "      <th>count_vectorizer__start</th>\n",
       "      <th>count_vectorizer__state</th>\n",
       "      <th>count_vectorizer__still</th>\n",
       "      <th>count_vectorizer__success</th>\n",
       "      <th>count_vectorizer__sum</th>\n",
       "      <th>count_vectorizer__support</th>\n",
       "      <th>count_vectorizer__sure</th>\n",
       "      <th>count_vectorizer__system</th>\n",
       "      <th>count_vectorizer__take</th>\n",
       "      <th>count_vectorizer__telephon</th>\n",
       "      <th>count_vectorizer__th</th>\n",
       "      <th>count_vectorizer__thank</th>\n",
       "      <th>count_vectorizer__therefor</th>\n",
       "      <th>count_vectorizer__think</th>\n",
       "      <th>count_vectorizer__though</th>\n",
       "      <th>count_vectorizer__thousand</th>\n",
       "      <th>count_vectorizer__time</th>\n",
       "      <th>count_vectorizer__today</th>\n",
       "      <th>count_vectorizer__told</th>\n",
       "      <th>count_vectorizer__top</th>\n",
       "      <th>count_vectorizer__total</th>\n",
       "      <th>count_vectorizer__transact</th>\n",
       "      <th>count_vectorizer__transfer</th>\n",
       "      <th>count_vectorizer__tri</th>\n",
       "      <th>count_vectorizer__trust</th>\n",
       "      <th>count_vectorizer__two</th>\n",
       "      <th>count_vectorizer__understand</th>\n",
       "      <th>count_vectorizer__unit</th>\n",
       "      <th>count_vectorizer__updat</th>\n",
       "      <th>count_vectorizer__upon</th>\n",
       "      <th>count_vectorizer__urgent</th>\n",
       "      <th>count_vectorizer__us</th>\n",
       "      <th>count_vectorizer__use</th>\n",
       "      <th>count_vectorizer__user</th>\n",
       "      <th>count_vectorizer__valu</th>\n",
       "      <th>count_vectorizer__via</th>\n",
       "      <th>count_vectorizer__visit</th>\n",
       "      <th>count_vectorizer__want</th>\n",
       "      <th>count_vectorizer__way</th>\n",
       "      <th>count_vectorizer__well</th>\n",
       "      <th>count_vectorizer__wish</th>\n",
       "      <th>count_vectorizer__within</th>\n",
       "      <th>count_vectorizer__without</th>\n",
       "      <th>count_vectorizer__work</th>\n",
       "      <th>count_vectorizer__world</th>\n",
       "      <th>count_vectorizer__would</th>\n",
       "      <th>count_vectorizer__write</th>\n",
       "      <th>count_vectorizer__wrote</th>\n",
       "      <th>count_vectorizer__yahoo</th>\n",
       "      <th>count_vectorizer__year</th>\n",
       "      <th>remainder__unsecure_link_count</th>\n",
       "      <th>remainder__secure_link_count</th>\n",
       "      <th>remainder__numbers_count</th>\n",
       "      <th>remainder__word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_vectorizer__abl  count_vectorizer__accept  count_vectorizer__access  \\\n",
       "0                      0                         0                         0   \n",
       "1                      0                         0                         0   \n",
       "2                      0                         0                         0   \n",
       "3                      0                         0                         0   \n",
       "4                      0                         0                         0   \n",
       "5                      0                         0                         0   \n",
       "6                      0                         0                         0   \n",
       "7                      0                         1                         0   \n",
       "8                      0                         0                         0   \n",
       "9                      0                         0                         0   \n",
       "\n",
       "   count_vectorizer__accord  count_vectorizer__account  \\\n",
       "0                         1                          7   \n",
       "1                         0                          0   \n",
       "2                         0                          3   \n",
       "3                         0                          2   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          2   \n",
       "8                         0                          1   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__actual  count_vectorizer__address  \\\n",
       "0                         1                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          1   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          0   \n",
       "8                         0                          1   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__agre  count_vectorizer__agreement  \\\n",
       "0                       0                            0   \n",
       "1                       0                            0   \n",
       "2                       1                            0   \n",
       "3                       0                            0   \n",
       "4                       0                            0   \n",
       "5                       0                            0   \n",
       "6                       0                            0   \n",
       "7                       0                            0   \n",
       "8                       0                            0   \n",
       "9                       0                            0   \n",
       "\n",
       "   count_vectorizer__along  count_vectorizer__also  count_vectorizer__amount  \\\n",
       "0                        0                       2                         1   \n",
       "1                        0                       0                         0   \n",
       "2                        0                       1                         0   \n",
       "3                        0                       2                         0   \n",
       "4                        0                       0                         0   \n",
       "5                        0                       0                         0   \n",
       "6                        0                       0                         0   \n",
       "7                        1                       0                         0   \n",
       "8                        0                       0                         0   \n",
       "9                        0                       0                         0   \n",
       "\n",
       "   count_vectorizer__anoth  count_vectorizer__arrang  count_vectorizer__ask  \\\n",
       "0                        0                         1                      1   \n",
       "1                        0                         0                      0   \n",
       "2                        0                         0                      0   \n",
       "3                        0                         0                      0   \n",
       "4                        0                         0                      0   \n",
       "5                        0                         0                      0   \n",
       "6                        0                         0                      0   \n",
       "7                        0                         0                      0   \n",
       "8                        1                         0                      0   \n",
       "9                        0                         0                      0   \n",
       "\n",
       "   count_vectorizer__assist  count_vectorizer__assur  \\\n",
       "0                         1                        0   \n",
       "1                         0                        0   \n",
       "2                         1                        0   \n",
       "3                         1                        0   \n",
       "4                         0                        0   \n",
       "5                         0                        0   \n",
       "6                         0                        0   \n",
       "7                         0                        0   \n",
       "8                         2                        0   \n",
       "9                         0                        0   \n",
       "\n",
       "   count_vectorizer__attent  count_vectorizer__back  count_vectorizer__bank  \\\n",
       "0                         0                       0                       9   \n",
       "1                         0                       0                       1   \n",
       "2                         0                       0                       1   \n",
       "3                         0                       2                       3   \n",
       "4                         0                       0                       4   \n",
       "5                         0                       0                       0   \n",
       "6                         0                       0                       0   \n",
       "7                         0                       1                       6   \n",
       "8                         0                       0                       3   \n",
       "9                         0                       0                       0   \n",
       "\n",
       "   count_vectorizer__base  count_vectorizer__behalf  count_vectorizer__believ  \\\n",
       "0                       0                         0                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       1                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       0                         0                         0   \n",
       "5                       0                         0                         0   \n",
       "6                       0                         0                         0   \n",
       "7                       0                         0                         0   \n",
       "8                       0                         0                         0   \n",
       "9                       0                         0                         0   \n",
       "\n",
       "   count_vectorizer__beneficiari  count_vectorizer__best  \\\n",
       "0                              0                       0   \n",
       "1                              0                       0   \n",
       "2                              0                       0   \n",
       "3                              0                       0   \n",
       "4                              0                       0   \n",
       "5                              0                       0   \n",
       "6                              0                       0   \n",
       "7                              0                       0   \n",
       "8                              3                       1   \n",
       "9                              0                       0   \n",
       "\n",
       "   count_vectorizer__bless  count_vectorizer__busi  count_vectorizer__call  \\\n",
       "0                        0                       2                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       1                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "5                        0                       0                       0   \n",
       "6                        0                       0                       0   \n",
       "7                        0                       1                       0   \n",
       "8                        0                       1                       0   \n",
       "9                        0                       0                       0   \n",
       "\n",
       "   count_vectorizer__care  count_vectorizer__case  count_vectorizer__chang  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       0                       0                        0   \n",
       "4                       0                       0                        0   \n",
       "5                       0                       0                        0   \n",
       "6                       0                       0                        0   \n",
       "7                       0                       0                        0   \n",
       "8                       0                       0                        0   \n",
       "9                       0                       0                        0   \n",
       "\n",
       "   count_vectorizer__choos  count_vectorizer__claim  count_vectorizer__click  \\\n",
       "0                        0                        2                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "5                        0                        0                        0   \n",
       "6                        0                        0                        0   \n",
       "7                        0                        2                        0   \n",
       "8                        0                        0                        0   \n",
       "9                        0                        0                        0   \n",
       "\n",
       "   count_vectorizer__client  count_vectorizer__close  count_vectorizer__come  \\\n",
       "0                         0                        0                       1   \n",
       "1                         0                        0                       0   \n",
       "2                         0                        0                       0   \n",
       "3                         0                        0                       1   \n",
       "4                         0                        0                       0   \n",
       "5                         0                        0                       0   \n",
       "6                         0                        0                       0   \n",
       "7                         0                        0                       1   \n",
       "8                         0                        0                       0   \n",
       "9                         0                        0                       0   \n",
       "\n",
       "   count_vectorizer__commun  count_vectorizer__compani  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         1                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__complet  count_vectorizer__concern  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__confid  count_vectorizer__confidenti  \\\n",
       "0                         0                             0   \n",
       "1                         0                             0   \n",
       "2                         0                             1   \n",
       "3                         0                             2   \n",
       "4                         0                             0   \n",
       "5                         0                             0   \n",
       "6                         0                             0   \n",
       "7                         0                             0   \n",
       "8                         0                             0   \n",
       "9                         0                             0   \n",
       "\n",
       "   count_vectorizer__confirm  count_vectorizer__contact  \\\n",
       "0                          1                          2   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          6                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__corpor  count_vectorizer__could  \\\n",
       "0                         0                        1   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "5                         0                        0   \n",
       "6                         0                        0   \n",
       "7                         0                        0   \n",
       "8                         0                        0   \n",
       "9                         0                        0   \n",
       "\n",
       "   count_vectorizer__countri  count_vectorizer__cours  \\\n",
       "0                          3                        0   \n",
       "1                          0                        0   \n",
       "2                          1                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "5                          0                        0   \n",
       "6                          0                        0   \n",
       "7                          0                        0   \n",
       "8                          5                        0   \n",
       "9                          0                        0   \n",
       "\n",
       "   count_vectorizer__current  count_vectorizer__custom  count_vectorizer__day  \\\n",
       "0                          0                         0                      0   \n",
       "1                          0                         0                      0   \n",
       "2                          0                         0                      0   \n",
       "3                          0                         0                      0   \n",
       "4                          0                         2                      0   \n",
       "5                          0                         0                      0   \n",
       "6                          0                         0                      0   \n",
       "7                          0                         2                      0   \n",
       "8                          0                         0                      0   \n",
       "9                          0                         0                      0   \n",
       "\n",
       "   count_vectorizer__deal  count_vectorizer__dear  count_vectorizer__death  \\\n",
       "0                       2                       1                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       0                       1                        0   \n",
       "4                       0                       2                        0   \n",
       "5                       0                       0                        0   \n",
       "6                       0                       0                        0   \n",
       "7                       2                       1                        1   \n",
       "8                       0                       0                        3   \n",
       "9                       0                       0                        0   \n",
       "\n",
       "   count_vectorizer__deceas  count_vectorizer__decid  \\\n",
       "0                         2                        1   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "5                         0                        0   \n",
       "6                         0                        0   \n",
       "7                         1                        0   \n",
       "8                         0                        0   \n",
       "9                         0                        0   \n",
       "\n",
       "   count_vectorizer__depart  count_vectorizer__deposit  \\\n",
       "0                         2                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          1   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         2                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__develop  count_vectorizer__direct  \\\n",
       "0                          4                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "5                          0                         0   \n",
       "6                          0                         0   \n",
       "7                          1                         0   \n",
       "8                          0                         0   \n",
       "9                          0                         0   \n",
       "\n",
       "   count_vectorizer__discov  count_vectorizer__discuss  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         1                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__done  count_vectorizer__due  count_vectorizer__easi  \\\n",
       "0                       1                      2                       0   \n",
       "1                       0                      0                       0   \n",
       "2                       0                      0                       1   \n",
       "3                       0                      0                       0   \n",
       "4                       0                      0                       0   \n",
       "5                       0                      0                       0   \n",
       "6                       0                      0                       0   \n",
       "7                       0                      0                       1   \n",
       "8                       0                      2                       0   \n",
       "9                       0                      0                       0   \n",
       "\n",
       "   count_vectorizer__enabl  count_vectorizer__end  count_vectorizer__even  \\\n",
       "0                        0                      1                       0   \n",
       "1                        0                      0                       0   \n",
       "2                        0                      0                       0   \n",
       "3                        0                      0                       0   \n",
       "4                        0                      0                       0   \n",
       "5                        0                      0                       0   \n",
       "6                        0                      0                       0   \n",
       "7                        0                      1                       0   \n",
       "8                        0                      0                       0   \n",
       "9                        0                      0                       0   \n",
       "\n",
       "   count_vectorizer__everi  count_vectorizer__execut  count_vectorizer__fact  \\\n",
       "0                        0                         0                       1   \n",
       "1                        0                         0                       0   \n",
       "2                        0                         0                       0   \n",
       "3                        0                         0                       0   \n",
       "4                        0                         0                       0   \n",
       "5                        0                         0                       0   \n",
       "6                        0                         0                       0   \n",
       "7                        0                         0                       1   \n",
       "8                        0                         0                       0   \n",
       "9                        0                         0                       0   \n",
       "\n",
       "   count_vectorizer__faith  count_vectorizer__famili  \\\n",
       "0                        1                         1   \n",
       "1                        0                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "5                        0                         0   \n",
       "6                        0                         0   \n",
       "7                        0                         1   \n",
       "8                        0                         0   \n",
       "9                        0                         0   \n",
       "\n",
       "   count_vectorizer__father  count_vectorizer__file  count_vectorizer__final  \\\n",
       "0                         0                       0                        0   \n",
       "1                         0                       0                        0   \n",
       "2                         0                       0                        0   \n",
       "3                         0                       0                        1   \n",
       "4                         0                       0                        0   \n",
       "5                         0                       0                        0   \n",
       "6                         0                       0                        0   \n",
       "7                         0                       0                        0   \n",
       "8                         4                       0                        0   \n",
       "9                         0                       0                        0   \n",
       "\n",
       "   count_vectorizer__financi  count_vectorizer__find  count_vectorizer__first  \\\n",
       "0                          0                       0                        0   \n",
       "1                          0                       0                        0   \n",
       "2                          0                       0                        0   \n",
       "3                          0                       0                        1   \n",
       "4                          0                       0                        0   \n",
       "5                          0                       0                        1   \n",
       "6                          0                       0                        0   \n",
       "7                          0                       0                        0   \n",
       "8                          0                       0                        0   \n",
       "9                          0                       0                        0   \n",
       "\n",
       "   count_vectorizer__five  count_vectorizer__follow  \\\n",
       "0                       0                         0   \n",
       "1                       0                         0   \n",
       "2                       0                         2   \n",
       "3                       0                         0   \n",
       "4                       0                         2   \n",
       "5                       0                         0   \n",
       "6                       0                         0   \n",
       "7                       1                         0   \n",
       "8                       0                         1   \n",
       "9                       0                         0   \n",
       "\n",
       "   count_vectorizer__foreign  count_vectorizer__form  \\\n",
       "0                          3                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       0   \n",
       "3                          0                       0   \n",
       "4                          0                       0   \n",
       "5                          0                       0   \n",
       "6                          0                       0   \n",
       "7                          4                       0   \n",
       "8                          2                       0   \n",
       "9                          0                       0   \n",
       "\n",
       "   count_vectorizer__former  count_vectorizer__forward  \\\n",
       "0                         0                          1   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__free  count_vectorizer__friend  count_vectorizer__full  \\\n",
       "0                       1                         0                       0   \n",
       "1                       0                         0                       0   \n",
       "2                       0                         1                       1   \n",
       "3                       0                         1                       0   \n",
       "4                       0                         0                       0   \n",
       "5                       0                         0                       0   \n",
       "6                       0                         0                       0   \n",
       "7                       0                         1                       0   \n",
       "8                       0                         0                       0   \n",
       "9                       0                         0                       0   \n",
       "\n",
       "   count_vectorizer__fund  count_vectorizer__futur  count_vectorizer__gener  \\\n",
       "0                       4                        0                        0   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        0   \n",
       "3                       2                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "5                       0                        0                        0   \n",
       "6                       0                        0                        0   \n",
       "7                       3                        0                        0   \n",
       "8                       2                        0                        0   \n",
       "9                       0                        0                        0   \n",
       "\n",
       "   count_vectorizer__get  count_vectorizer__give  count_vectorizer__given  \\\n",
       "0                      1                       0                        0   \n",
       "1                      0                       0                        0   \n",
       "2                      1                       2                        0   \n",
       "3                      0                       1                        0   \n",
       "4                      0                       0                        0   \n",
       "5                      0                       0                        0   \n",
       "6                      0                       0                        0   \n",
       "7                      1                       1                        0   \n",
       "8                      1                       0                        0   \n",
       "9                      0                       0                        0   \n",
       "\n",
       "   count_vectorizer__go  count_vectorizer__god  count_vectorizer__good  \\\n",
       "0                     0                      0                       0   \n",
       "1                     0                      0                       0   \n",
       "2                     0                      0                       0   \n",
       "3                     0                      0                       0   \n",
       "4                     0                      0                       0   \n",
       "5                     0                      0                       0   \n",
       "6                     0                      0                       1   \n",
       "7                     0                      0                       0   \n",
       "8                     0                      0                       0   \n",
       "9                     0                      0                       0   \n",
       "\n",
       "   count_vectorizer__got  count_vectorizer__govern  count_vectorizer__great  \\\n",
       "0                      1                         0                        1   \n",
       "1                      0                         0                        0   \n",
       "2                      0                         0                        0   \n",
       "3                      0                         0                        0   \n",
       "4                      0                         0                        0   \n",
       "5                      0                         0                        0   \n",
       "6                      0                         0                        0   \n",
       "7                      1                         0                        0   \n",
       "8                      0                         0                        0   \n",
       "9                      0                         0                        0   \n",
       "\n",
       "   count_vectorizer__group  count_vectorizer__hear  count_vectorizer__help  \\\n",
       "0                        0                       2                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       0                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "5                        0                       0                       0   \n",
       "6                        0                       0                       0   \n",
       "7                        0                       0                       0   \n",
       "8                        0                       0                       1   \n",
       "9                        0                       0                       0   \n",
       "\n",
       "   count_vectorizer__henc  count_vectorizer__home  count_vectorizer__hope  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "5                       0                       0                       0   \n",
       "6                       0                       0                       0   \n",
       "7                       0                       0                       0   \n",
       "8                       0                       0                       0   \n",
       "9                       0                       0                       0   \n",
       "\n",
       "   count_vectorizer__hous  count_vectorizer__howev  count_vectorizer__hundr  \\\n",
       "0                       0                        0                        1   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        1   \n",
       "3                       0                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "5                       0                        0                        0   \n",
       "6                       0                        0                        0   \n",
       "7                       0                        0                        1   \n",
       "8                       1                        0                        0   \n",
       "9                       0                        0                        0   \n",
       "\n",
       "   count_vectorizer__id  count_vectorizer__immedi  count_vectorizer__import  \\\n",
       "0                     0                         0                         0   \n",
       "1                     0                         0                         0   \n",
       "2                     0                         0                         2   \n",
       "3                     0                         0                         0   \n",
       "4                     0                         0                         0   \n",
       "5                     0                         0                         0   \n",
       "6                     0                         0                         0   \n",
       "7                     0                         0                         0   \n",
       "8                     0                         0                         2   \n",
       "9                     0                         0                         0   \n",
       "\n",
       "   count_vectorizer__includ  count_vectorizer__inform  \\\n",
       "0                         0                         4   \n",
       "1                         0                         0   \n",
       "2                         0                         1   \n",
       "3                         0                         1   \n",
       "4                         0                         0   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         1   \n",
       "8                         0                         1   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__interest  count_vectorizer__intern  \\\n",
       "0                           2                         1   \n",
       "1                           0                         0   \n",
       "2                           1                         0   \n",
       "3                           1                         0   \n",
       "4                           0                         0   \n",
       "5                           0                         0   \n",
       "6                           0                         0   \n",
       "7                           0                         1   \n",
       "8                           1                         0   \n",
       "9                           0                         0   \n",
       "\n",
       "   count_vectorizer__invest  count_vectorizer__involv  count_vectorizer__issu  \\\n",
       "0                         2                         0                       0   \n",
       "1                         0                         0                       0   \n",
       "2                         0                         0                       0   \n",
       "3                         0                         0                       0   \n",
       "4                         0                         0                       0   \n",
       "5                         0                         0                       0   \n",
       "6                         0                         0                       0   \n",
       "7                         0                         0                       0   \n",
       "8                         3                         0                       0   \n",
       "9                         0                         0                       0   \n",
       "\n",
       "   count_vectorizer__keep  count_vectorizer__kin  count_vectorizer__know  \\\n",
       "0                       1                      2                       1   \n",
       "1                       0                      0                       0   \n",
       "2                       0                      1                       0   \n",
       "3                       1                      0                       0   \n",
       "4                       0                      0                       0   \n",
       "5                       0                      0                       0   \n",
       "6                       0                      0                       0   \n",
       "7                       0                      5                       0   \n",
       "8                       0                      0                       0   \n",
       "9                       0                      0                       0   \n",
       "\n",
       "   count_vectorizer__last  count_vectorizer__late  count_vectorizer__law  \\\n",
       "0                       0                       0                      0   \n",
       "1                       0                       0                      0   \n",
       "2                       1                       1                      0   \n",
       "3                       1                       1                      0   \n",
       "4                       0                       0                      0   \n",
       "5                       0                       0                      0   \n",
       "6                       0                       0                      0   \n",
       "7                       0                       0                      1   \n",
       "8                       2                       2                      0   \n",
       "9                       0                       0                      0   \n",
       "\n",
       "   count_vectorizer__leav  count_vectorizer__left  count_vectorizer__legal  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       1                        0   \n",
       "3                       0                       0                        0   \n",
       "4                       0                       0                        0   \n",
       "5                       0                       0                        0   \n",
       "6                       0                       0                        0   \n",
       "7                       1                       0                        0   \n",
       "8                       0                       0                        0   \n",
       "9                       0                       0                        0   \n",
       "\n",
       "   count_vectorizer__let  count_vectorizer__letter  count_vectorizer__life  \\\n",
       "0                      0                         0                       0   \n",
       "1                      0                         0                       0   \n",
       "2                      0                         1                       0   \n",
       "3                      0                         0                       0   \n",
       "4                      0                         0                       0   \n",
       "5                      0                         0                       0   \n",
       "6                      0                         0                       0   \n",
       "7                      0                         0                       0   \n",
       "8                      1                         3                       1   \n",
       "9                      0                         0                       0   \n",
       "\n",
       "   count_vectorizer__like  count_vectorizer__link  count_vectorizer__list  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       2                       0   \n",
       "5                       1                       0                       0   \n",
       "6                       0                       0                       0   \n",
       "7                       0                       0                       0   \n",
       "8                       1                       0                       0   \n",
       "9                       0                       0                       0   \n",
       "\n",
       "   count_vectorizer__live  count_vectorizer__long  count_vectorizer__look  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       1                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "5                       0                       0                       0   \n",
       "6                       0                       0                       0   \n",
       "7                       0                       0                       0   \n",
       "8                       0                       0                       0   \n",
       "9                       0                       0                       0   \n",
       "\n",
       "   count_vectorizer__made  count_vectorizer__mail  count_vectorizer__mailman  \\\n",
       "0                       0                       0                          0   \n",
       "1                       0                       0                          1   \n",
       "2                       0                       1                          0   \n",
       "3                       1                       0                          0   \n",
       "4                       0                       2                          0   \n",
       "5                       0                       0                          0   \n",
       "6                       0                       0                          0   \n",
       "7                       0                       0                          0   \n",
       "8                       0                       0                          0   \n",
       "9                       0                       0                          0   \n",
       "\n",
       "   count_vectorizer__make  count_vectorizer__manag  count_vectorizer__mani  \\\n",
       "0                       0                        2                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       0                        2                       0   \n",
       "3                       0                        2                       0   \n",
       "4                       0                        6                       0   \n",
       "5                       0                        0                       0   \n",
       "6                       0                        0                       0   \n",
       "7                       0                        1                       0   \n",
       "8                       0                        0                       0   \n",
       "9                       0                        0                       0   \n",
       "\n",
       "   count_vectorizer__matter  count_vectorizer__may  count_vectorizer__meet  \\\n",
       "0                         0                      2                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      1                       0   \n",
       "3                         0                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "5                         0                      0                       0   \n",
       "6                         0                      0                       0   \n",
       "7                         0                      0                       0   \n",
       "8                         0                      0                       0   \n",
       "9                         0                      0                       0   \n",
       "\n",
       "   count_vectorizer__member  count_vectorizer__messag  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         2   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         0   \n",
       "8                         0                         0   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__might  count_vectorizer__million  \\\n",
       "0                        0                          1   \n",
       "1                        0                          0   \n",
       "2                        0                          2   \n",
       "3                        0                          1   \n",
       "4                        0                          0   \n",
       "5                        0                          0   \n",
       "6                        0                          0   \n",
       "7                        1                          1   \n",
       "8                        0                          1   \n",
       "9                        0                          0   \n",
       "\n",
       "   count_vectorizer__money  count_vectorizer__move  count_vectorizer__much  \\\n",
       "0                        5                       0                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        1                       0                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "5                        0                       0                       0   \n",
       "6                        0                       0                       0   \n",
       "7                        4                       0                       0   \n",
       "8                        6                       0                       0   \n",
       "9                        0                       0                       0   \n",
       "\n",
       "   count_vectorizer__must  count_vectorizer__name  count_vectorizer__nation  \\\n",
       "0                       0                       0                         0   \n",
       "1                       0                       0                         0   \n",
       "2                       0                       0                         0   \n",
       "3                       1                       0                         0   \n",
       "4                       0                       0                         0   \n",
       "5                       0                       0                         0   \n",
       "6                       0                       0                         0   \n",
       "7                       0                       0                         0   \n",
       "8                       0                       4                         0   \n",
       "9                       0                       0                         0   \n",
       "\n",
       "   count_vectorizer__necessari  count_vectorizer__need  count_vectorizer__net  \\\n",
       "0                            1                       1                      0   \n",
       "1                            0                       0                      0   \n",
       "2                            0                       0                      0   \n",
       "3                            0                       0                      0   \n",
       "4                            0                       0                      0   \n",
       "5                            0                       0                      0   \n",
       "6                            0                       0                      0   \n",
       "7                            0                       0                      0   \n",
       "8                            0                       1                      0   \n",
       "9                            0                       0                      0   \n",
       "\n",
       "   count_vectorizer__never  count_vectorizer__new  count_vectorizer__next  \\\n",
       "0                        0                      0                       2   \n",
       "1                        0                      0                       0   \n",
       "2                        0                      0                       1   \n",
       "3                        0                      0                       0   \n",
       "4                        0                      0                       0   \n",
       "5                        0                      0                       0   \n",
       "6                        0                      0                       0   \n",
       "7                        0                      0                       5   \n",
       "8                        0                      0                       0   \n",
       "9                        0                      0                       0   \n",
       "\n",
       "   count_vectorizer__note  count_vectorizer__number  count_vectorizer__offer  \\\n",
       "0                       0                         1                        0   \n",
       "1                       0                         0                        0   \n",
       "2                       1                         1                        0   \n",
       "3                       1                         2                        0   \n",
       "4                       0                         0                        0   \n",
       "5                       0                         1                        0   \n",
       "6                       0                         0                        0   \n",
       "7                       0                         0                        0   \n",
       "8                       0                         0                        0   \n",
       "9                       0                         0                        0   \n",
       "\n",
       "   count_vectorizer__offic  count_vectorizer__offici  count_vectorizer__old  \\\n",
       "0                        0                         0                      0   \n",
       "1                        0                         0                      0   \n",
       "2                        0                         0                      1   \n",
       "3                        1                         0                      0   \n",
       "4                        0                         0                      0   \n",
       "5                        0                         0                      0   \n",
       "6                        0                         0                      0   \n",
       "7                        0                         0                      0   \n",
       "8                        0                         0                      1   \n",
       "9                        0                         0                      0   \n",
       "\n",
       "   count_vectorizer__one  count_vectorizer__open  count_vectorizer__oper  \\\n",
       "0                      1                       0                       1   \n",
       "1                      0                       0                       0   \n",
       "2                      1                       0                       2   \n",
       "3                      0                       0                       0   \n",
       "4                      0                       2                       0   \n",
       "5                      0                       0                       0   \n",
       "6                      0                       0                       0   \n",
       "7                      1                       0                       0   \n",
       "8                      1                       0                       0   \n",
       "9                      0                       0                       0   \n",
       "\n",
       "   count_vectorizer__order  count_vectorizer__part  count_vectorizer__partner  \\\n",
       "0                        0                       0                          1   \n",
       "1                        0                       0                          0   \n",
       "2                        0                       0                          0   \n",
       "3                        0                       0                          1   \n",
       "4                        0                       0                          0   \n",
       "5                        0                       0                          0   \n",
       "6                        0                       0                          0   \n",
       "7                        0                       0                          1   \n",
       "8                        1                       0                          3   \n",
       "9                        0                       0                          0   \n",
       "\n",
       "   count_vectorizer__peopl  count_vectorizer__person  count_vectorizer__phone  \\\n",
       "0                        0                         1                        0   \n",
       "1                        0                         0                        0   \n",
       "2                        0                         1                        0   \n",
       "3                        0                         1                        0   \n",
       "4                        0                         0                        0   \n",
       "5                        0                         0                        0   \n",
       "6                        0                         0                        0   \n",
       "7                        0                         1                        0   \n",
       "8                        0                         0                        0   \n",
       "9                        0                         0                        0   \n",
       "\n",
       "   count_vectorizer__place  count_vectorizer__pleas  count_vectorizer__polici  \\\n",
       "0                        1                        1                         0   \n",
       "1                        0                        0                         0   \n",
       "2                        0                        2                         0   \n",
       "3                        0                        4                         0   \n",
       "4                        0                        4                         0   \n",
       "5                        0                        0                         0   \n",
       "6                        0                        0                         0   \n",
       "7                        0                        0                         0   \n",
       "8                        1                        1                         0   \n",
       "9                        0                        0                         0   \n",
       "\n",
       "   count_vectorizer__polit  count_vectorizer__posit  \\\n",
       "0                        0                        1   \n",
       "1                        0                        0   \n",
       "2                        0                        0   \n",
       "3                        0                        0   \n",
       "4                        0                        0   \n",
       "5                        0                        0   \n",
       "6                        0                        0   \n",
       "7                        0                        0   \n",
       "8                        1                        0   \n",
       "9                        0                        0   \n",
       "\n",
       "   count_vectorizer__possibl  count_vectorizer__present  \\\n",
       "0                          0                          1   \n",
       "1                          0                          0   \n",
       "2                          0                          1   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__presid  count_vectorizer__privat  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         1   \n",
       "8                         0                         1   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__problem  count_vectorizer__process  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          1   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__propos  count_vectorizer__protect  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         1                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         1                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__provid  count_vectorizer__put  count_vectorizer__read  \\\n",
       "0                         0                      2                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      0                       0   \n",
       "3                         2                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "5                         0                      0                       0   \n",
       "6                         0                      0                       0   \n",
       "7                         0                      0                       0   \n",
       "8                         1                      0                       0   \n",
       "9                         0                      0                       0   \n",
       "\n",
       "   count_vectorizer__real  count_vectorizer__reason  count_vectorizer__receiv  \\\n",
       "0                       0                         1                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       0                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       0                         0                         0   \n",
       "5                       0                         0                         1   \n",
       "6                       0                         0                         0   \n",
       "7                       0                         0                         0   \n",
       "8                       0                         0                         1   \n",
       "9                       0                         0                         0   \n",
       "\n",
       "   count_vectorizer__recent  count_vectorizer__releas  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         0   \n",
       "8                         0                         0   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__reliabl  count_vectorizer__repli  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        3   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "5                          0                        0   \n",
       "6                          0                        0   \n",
       "7                          0                        0   \n",
       "8                          0                        0   \n",
       "9                          0                        0   \n",
       "\n",
       "   count_vectorizer__request  count_vectorizer__reserv  \\\n",
       "0                          1                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         2   \n",
       "5                          0                         0   \n",
       "6                          0                         0   \n",
       "7                          1                         0   \n",
       "8                          0                         0   \n",
       "9                          0                         0   \n",
       "\n",
       "   count_vectorizer__respect  count_vectorizer__respons  \\\n",
       "0                          1                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          1   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__result  count_vectorizer__right  count_vectorizer__risk  \\\n",
       "0                         0                        0                       1   \n",
       "1                         0                        0                       0   \n",
       "2                         0                        0                       0   \n",
       "3                         0                        0                       0   \n",
       "4                         0                        0                       0   \n",
       "5                         0                        0                       0   \n",
       "6                         0                        0                       0   \n",
       "7                         0                        0                       0   \n",
       "8                         0                        0                       0   \n",
       "9                         0                        0                       0   \n",
       "\n",
       "   count_vectorizer__run  count_vectorizer__safe  count_vectorizer__said  \\\n",
       "0                      0                       0                       1   \n",
       "1                      0                       0                       0   \n",
       "2                      0                       0                       0   \n",
       "3                      0                       0                       0   \n",
       "4                      0                       0                       0   \n",
       "5                      0                       0                       0   \n",
       "6                      0                       0                       1   \n",
       "7                      0                       0                       0   \n",
       "8                      1                       0                       1   \n",
       "9                      0                       0                       0   \n",
       "\n",
       "   count_vectorizer__say  count_vectorizer__search  count_vectorizer__secur  \\\n",
       "0                      0                         1                        0   \n",
       "1                      0                         0                        0   \n",
       "2                      0                         0                        0   \n",
       "3                      0                         1                        0   \n",
       "4                      0                         0                        0   \n",
       "5                      0                         0                        0   \n",
       "6                      0                         0                        0   \n",
       "7                      0                         0                        0   \n",
       "8                      0                         0                        0   \n",
       "9                      0                         0                        0   \n",
       "\n",
       "   count_vectorizer__see  count_vectorizer__seek  count_vectorizer__send  \\\n",
       "0                      0                       0                       0   \n",
       "1                      1                       0                       0   \n",
       "2                      0                       0                       0   \n",
       "3                      0                       0                       0   \n",
       "4                      0                       0                       0   \n",
       "5                      0                       0                       0   \n",
       "6                      0                       0                       0   \n",
       "7                      0                       0                       0   \n",
       "8                      0                       0                       1   \n",
       "9                      0                       0                       0   \n",
       "\n",
       "   count_vectorizer__sent  count_vectorizer__servic  count_vectorizer__set  \\\n",
       "0                       1                         2                      0   \n",
       "1                       0                         0                      0   \n",
       "2                       0                         0                      0   \n",
       "3                       0                         0                      0   \n",
       "4                       0                         0                      0   \n",
       "5                       0                         0                      0   \n",
       "6                       1                         0                      0   \n",
       "7                       0                         0                      1   \n",
       "8                       0                         0                      0   \n",
       "9                       0                         0                      0   \n",
       "\n",
       "   count_vectorizer__shall  count_vectorizer__share  count_vectorizer__sinc  \\\n",
       "0                        0                        0                       0   \n",
       "1                        0                        0                       0   \n",
       "2                        0                        0                       0   \n",
       "3                        0                        0                       1   \n",
       "4                        0                        0                       0   \n",
       "5                        0                        0                       0   \n",
       "6                        0                        0                       0   \n",
       "7                        0                        0                       1   \n",
       "8                        0                        1                       0   \n",
       "9                        0                        0                       0   \n",
       "\n",
       "   count_vectorizer__sincer  count_vectorizer__sir  count_vectorizer__site  \\\n",
       "0                         0                      0                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      0                       0   \n",
       "3                         0                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "5                         0                      0                       0   \n",
       "6                         0                      0                       0   \n",
       "7                         0                      0                       0   \n",
       "8                         0                      0                       0   \n",
       "9                         0                      0                       0   \n",
       "\n",
       "   count_vectorizer__son  count_vectorizer__soon  count_vectorizer__stand  \\\n",
       "0                      0                       1                        0   \n",
       "1                      0                       0                        0   \n",
       "2                      0                       0                        0   \n",
       "3                      0                       0                        0   \n",
       "4                      0                       0                        0   \n",
       "5                      0                       0                        0   \n",
       "6                      0                       0                        0   \n",
       "7                      0                       0                        1   \n",
       "8                      0                       0                        1   \n",
       "9                      0                       0                        0   \n",
       "\n",
       "   count_vectorizer__start  count_vectorizer__state  count_vectorizer__still  \\\n",
       "0                        0                        0                        1   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "5                        0                        0                        0   \n",
       "6                        0                        0                        0   \n",
       "7                        0                        0                        0   \n",
       "8                        0                        1                        0   \n",
       "9                        0                        0                        0   \n",
       "\n",
       "   count_vectorizer__success  count_vectorizer__sum  \\\n",
       "0                          0                      2   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "5                          0                      0   \n",
       "6                          0                      0   \n",
       "7                          0                      1   \n",
       "8                          0                      1   \n",
       "9                          0                      0   \n",
       "\n",
       "   count_vectorizer__support  count_vectorizer__sure  \\\n",
       "0                          0                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       0   \n",
       "3                          0                       0   \n",
       "4                          0                       0   \n",
       "5                          0                       0   \n",
       "6                          0                       0   \n",
       "7                          0                       0   \n",
       "8                          0                       0   \n",
       "9                          0                       0   \n",
       "\n",
       "   count_vectorizer__system  count_vectorizer__take  \\\n",
       "0                         0                       0   \n",
       "1                         0                       0   \n",
       "2                         0                       0   \n",
       "3                         0                       0   \n",
       "4                         0                       0   \n",
       "5                         0                       0   \n",
       "6                         0                       0   \n",
       "7                         0                       0   \n",
       "8                         0                       0   \n",
       "9                         0                       0   \n",
       "\n",
       "   count_vectorizer__telephon  count_vectorizer__th  count_vectorizer__thank  \\\n",
       "0                           0                     0                        0   \n",
       "1                           0                     0                        0   \n",
       "2                           1                     1                        0   \n",
       "3                           1                     0                        0   \n",
       "4                           0                     0                        0   \n",
       "5                           0                     0                        0   \n",
       "6                           0                     0                        0   \n",
       "7                           1                     1                        0   \n",
       "8                           1                     0                        1   \n",
       "9                           0                     0                        0   \n",
       "\n",
       "   count_vectorizer__therefor  count_vectorizer__think  \\\n",
       "0                           0                        0   \n",
       "1                           0                        0   \n",
       "2                           0                        0   \n",
       "3                           0                        0   \n",
       "4                           0                        0   \n",
       "5                           0                        0   \n",
       "6                           0                        0   \n",
       "7                           0                        0   \n",
       "8                           0                        0   \n",
       "9                           0                        0   \n",
       "\n",
       "   count_vectorizer__though  count_vectorizer__thousand  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           1   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "5                         0                           0   \n",
       "6                         0                           0   \n",
       "7                         0                           1   \n",
       "8                         0                           0   \n",
       "9                         0                           0   \n",
       "\n",
       "   count_vectorizer__time  count_vectorizer__today  count_vectorizer__told  \\\n",
       "0                       0                        0                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       0                        0                       0   \n",
       "3                       0                        0                       0   \n",
       "4                       0                        0                       0   \n",
       "5                       0                        0                       0   \n",
       "6                       0                        0                       0   \n",
       "7                       0                        0                       0   \n",
       "8                       0                        0                       0   \n",
       "9                       0                        0                       0   \n",
       "\n",
       "   count_vectorizer__top  count_vectorizer__total  count_vectorizer__transact  \\\n",
       "0                      2                        1                           4   \n",
       "1                      0                        0                           0   \n",
       "2                      0                        0                           1   \n",
       "3                      0                        0                           1   \n",
       "4                      0                        0                           0   \n",
       "5                      0                        0                           0   \n",
       "6                      0                        0                           0   \n",
       "7                      0                        1                           0   \n",
       "8                      0                        0                           1   \n",
       "9                      0                        0                           0   \n",
       "\n",
       "   count_vectorizer__transfer  count_vectorizer__tri  count_vectorizer__trust  \\\n",
       "0                           2                      0                        2   \n",
       "1                           0                      0                        0   \n",
       "2                           1                      0                        0   \n",
       "3                           0                      1                        0   \n",
       "4                           0                      0                        0   \n",
       "5                           0                      0                        0   \n",
       "6                           0                      0                        0   \n",
       "7                           1                      0                        0   \n",
       "8                           2                      0                        0   \n",
       "9                           0                      1                        0   \n",
       "\n",
       "   count_vectorizer__two  count_vectorizer__understand  \\\n",
       "0                      0                             0   \n",
       "1                      0                             0   \n",
       "2                      0                             0   \n",
       "3                      0                             0   \n",
       "4                      0                             0   \n",
       "5                      0                             0   \n",
       "6                      0                             0   \n",
       "7                      0                             0   \n",
       "8                      0                             0   \n",
       "9                      0                             0   \n",
       "\n",
       "   count_vectorizer__unit  count_vectorizer__updat  count_vectorizer__upon  \\\n",
       "0                       0                        0                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       1                        0                       0   \n",
       "3                       0                        0                       0   \n",
       "4                       2                        2                       0   \n",
       "5                       0                        0                       0   \n",
       "6                       0                        0                       0   \n",
       "7                       1                        0                       0   \n",
       "8                       0                        0                       1   \n",
       "9                       0                        0                       0   \n",
       "\n",
       "   count_vectorizer__urgent  count_vectorizer__us  count_vectorizer__use  \\\n",
       "0                         0                     3                      0   \n",
       "1                         0                     0                      0   \n",
       "2                         2                     0                      0   \n",
       "3                         0                     2                      0   \n",
       "4                         0                     0                      0   \n",
       "5                         0                     0                      0   \n",
       "6                         0                     0                      0   \n",
       "7                         0                     0                      0   \n",
       "8                         0                     0                      0   \n",
       "9                         0                     0                      0   \n",
       "\n",
       "   count_vectorizer__user  count_vectorizer__valu  count_vectorizer__via  \\\n",
       "0                       0                       0                      0   \n",
       "1                       0                       0                      0   \n",
       "2                       0                       0                      1   \n",
       "3                       0                       0                      1   \n",
       "4                       4                       0                      0   \n",
       "5                       0                       0                      0   \n",
       "6                       0                       0                      0   \n",
       "7                       0                       0                      0   \n",
       "8                       0                       0                      0   \n",
       "9                       0                       0                      0   \n",
       "\n",
       "   count_vectorizer__visit  count_vectorizer__want  count_vectorizer__way  \\\n",
       "0                        1                       0                      0   \n",
       "1                        0                       0                      0   \n",
       "2                        0                       0                      0   \n",
       "3                        1                       0                      0   \n",
       "4                        0                       0                      0   \n",
       "5                        0                       0                      0   \n",
       "6                        0                       0                      0   \n",
       "7                        0                       0                      0   \n",
       "8                        0                       1                      0   \n",
       "9                        0                       0                      0   \n",
       "\n",
       "   count_vectorizer__well  count_vectorizer__wish  count_vectorizer__within  \\\n",
       "0                       0                       0                         0   \n",
       "1                       0                       0                         0   \n",
       "2                       0                       0                         0   \n",
       "3                       0                       0                         1   \n",
       "4                       0                       0                         0   \n",
       "5                       0                       0                         0   \n",
       "6                       0                       0                         0   \n",
       "7                       1                       0                         0   \n",
       "8                       0                       0                         0   \n",
       "9                       0                       0                         0   \n",
       "\n",
       "   count_vectorizer__without  count_vectorizer__work  count_vectorizer__world  \\\n",
       "0                          1                       1                        1   \n",
       "1                          0                       0                        0   \n",
       "2                          0                       1                        0   \n",
       "3                          0                       0                        1   \n",
       "4                          0                       0                        0   \n",
       "5                          0                       1                        0   \n",
       "6                          0                       0                        0   \n",
       "7                          0                       0                        0   \n",
       "8                          0                       0                        0   \n",
       "9                          0                       0                        0   \n",
       "\n",
       "   count_vectorizer__would  count_vectorizer__write  count_vectorizer__wrote  \\\n",
       "0                        1                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        2                        0   \n",
       "4                        0                        0                        0   \n",
       "5                        0                        0                        0   \n",
       "6                        0                        0                        0   \n",
       "7                        0                        0                        0   \n",
       "8                        0                        0                        1   \n",
       "9                        0                        0                        0   \n",
       "\n",
       "   count_vectorizer__yahoo  count_vectorizer__year  \\\n",
       "0                        0                       0   \n",
       "1                        0                       0   \n",
       "2                        0                       0   \n",
       "3                        0                       1   \n",
       "4                        0                       0   \n",
       "5                        0                       0   \n",
       "6                        0                       0   \n",
       "7                        0                       0   \n",
       "8                        1                       0   \n",
       "9                        0                       0   \n",
       "\n",
       "   remainder__unsecure_link_count  remainder__secure_link_count  \\\n",
       "0                               1                             0   \n",
       "1                               1                             0   \n",
       "2                               1                             0   \n",
       "3                               1                             0   \n",
       "4                               2                             0   \n",
       "5                               0                             0   \n",
       "6                               0                             0   \n",
       "7                               0                             0   \n",
       "8                               2                             0   \n",
       "9                               0                             0   \n",
       "\n",
       "   remainder__numbers_count  remainder__word_count  \n",
       "0                        57                    504  \n",
       "1                         0                     29  \n",
       "2                         9                    218  \n",
       "3                         7                    170  \n",
       "4                         2                    154  \n",
       "5                         0                     32  \n",
       "6                         0                     15  \n",
       "7                         6                    259  \n",
       "8                         9                    386  \n",
       "9                         0                      3  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using the fitted vectorizer transform the validation data set\n",
    "X_validation_vec = cv_transf.transform(X_validation)\n",
    "# Turn the transformed validation data into a data frame\n",
    "X_validation_vec = pd.DataFrame(\n",
    "    data=X_validation_vec.toarray(),\n",
    "    columns=cv_transf.get_feature_names_out(),\n",
    ")\n",
    "# Look at the top 10 entries of the data frame\n",
    "X_validation_vec.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e3429bd4-4294-4575-8c09-d72f26a6937a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1984, 283)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_validation_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4371b9-9f57-4b4c-9c41-95184527d2ef",
   "metadata": {},
   "source": [
    "## Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb88a21",
   "metadata": {},
   "source": [
    "Now that the data has been appropriately vectorized, models can now be trained on it. For initial analysis, the logistic regression, KNN, decision tree and naive bayes models will be fitted and tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "48c1000a-7d4f-4bf4-acc3-cd9ca9ff7289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a dictionary to record the results of the initial models\n",
    "results_dict = {\n",
    "    'Model': [],\n",
    "    'Train Accuracy': [],\n",
    "    'Validation Accuracy': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5782508c",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f57ee4",
   "metadata": {},
   "source": [
    "The first model that will be tested is a logistic regression model. It should be noted that PCA (Principal Component Analysis) will be applied for this model. This is due to the fact that there is a high amount of correlation between the vectorized words, so PCA will eliminate this correlation allowing the assumptions of logistic regression to be satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e0f690f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PCA version of X_train and X_val\n",
    "pca_tranformer = PCA(n_components=10)\n",
    "X_train_pca = pca_tranformer.fit_transform(X_train_vec)\n",
    "X_val_pca = pca_tranformer.transform(X_validation_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "3f68394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.07308467741935\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the logistic regression model\n",
    "log_reg_pca_model = LogisticRegression()\n",
    "# Fit the logistic regression model to the training data\n",
    "log_reg_pca_model.fit(X_train_pca, y_train)\n",
    "# Get the % accuracy of the logistic regression model\n",
    "log_reg_train_acc = log_reg_pca_model.score(X_train_pca, y_train) * 100\n",
    "# Print the logistic regression accuracy\n",
    "print(log_reg_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cdda9205",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.36290322580645\n"
     ]
    }
   ],
   "source": [
    "# Get the % accuracy of the logistic regression model on the validation data\n",
    "log_reg_val_acc = log_reg_pca_model.score(X_val_pca, y_validation) * 100\n",
    "print(log_reg_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "08b29f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the results of the logistic regression model to the results dictionary\n",
    "results_dict['Model'].append('Logistic Regression')\n",
    "results_dict['Train Accuracy'].append(log_reg_train_acc)\n",
    "results_dict['Validation Accuracy'].append(log_reg_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6588c",
   "metadata": {},
   "source": [
    "This 95% accuracy result seems to be very high, especially without any parameter optimization. This may be due to the prevalence of certain words in fraudulent emails vs those in ham emails."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ecda3c",
   "metadata": {},
   "source": [
    "### SVM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08047965",
   "metadata": {},
   "source": [
    "The next model that will be evaluated is a SVM model using standard settings. For this model, we will use a standard scaler on the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8ff8346d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.34122983870968\n"
     ]
    }
   ],
   "source": [
    "# Initialize scaler\n",
    "standardScaler = StandardScaler()\n",
    "# Fit the scaler on the train data\n",
    "standardScaler.fit(X_train_vec)\n",
    "# Transform the train data\n",
    "x_ss_scaled_vec = standardScaler.transform(X_train_vec)\n",
    "# Instantiate and fit the KNN model with cosine similarity\n",
    "svc_model = SVC()\n",
    "svc_model.fit(x_ss_scaled_vec, y_train)\n",
    "# Get the train % accuracy and print it\n",
    "svc_train_acc = svc_model.score(x_ss_scaled_vec, y_train) * 100\n",
    "print(svc_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "130f37d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.37096774193549\n"
     ]
    }
   ],
   "source": [
    "# Scale the validation data set using the fitted scaler\n",
    "x_val_ss_scaled_vec = standardScaler.transform(X_validation_vec)\n",
    "svc_val_acc = svc_model.score(x_val_ss_scaled_vec, y_validation) * 100\n",
    "print(svc_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8182b432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results of the KNN model to the results dictionary\n",
    "results_dict['Model'].append('SVM')\n",
    "results_dict['Train Accuracy'].append(svc_train_acc)\n",
    "results_dict['Validation Accuracy'].append(svc_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fc8596",
   "metadata": {},
   "source": [
    "It seems the SVM model provides a higher validation accuracy of 97% vs the 95% from logistic regression. Cross-validation will need to be performed to confirm whether the SVM provides consistently high accuracy, which will be performed in a grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102b39de",
   "metadata": {},
   "source": [
    "### KNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462ec69e",
   "metadata": {},
   "source": [
    "The next model that will be evaluated is a KNN model with cosine similarity. The reason cosine similarity will be used for this model is due to the fact that the proportional counts of certain words is likely more important than the cartesian size of the vector. Given this, a cosine similarity will likely place vectors of similar proportions closer together despite difference in magnitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "deac7b48-77c6-43e9-814e-98b0df29b720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.01814516129032\n"
     ]
    }
   ],
   "source": [
    "# Initialize scaler\n",
    "minMaxScaler = MinMaxScaler()\n",
    "# Fit the scaler on the train data\n",
    "minMaxScaler.fit(X_train_vec)\n",
    "# Transform the train data\n",
    "x_mm_scaled_vec = minMaxScaler.transform(X_train_vec)\n",
    "# Instantiate and fit the KNN model with cosine similarity\n",
    "knn_model = KNeighborsClassifier(metric='cosine')\n",
    "knn_model.fit(x_mm_scaled_vec, y_train)\n",
    "# Get the train % accuracy and print it\n",
    "knn_train_acc = knn_model.score(x_mm_scaled_vec, y_train) * 100\n",
    "print(knn_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "912ebd19-9b8c-480b-a367-f27ff4daf882",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.75806451612904\n"
     ]
    }
   ],
   "source": [
    "# Scale the validation data set using the fitted scaler\n",
    "x_val_scaled_vec = minMaxScaler.transform(X_validation_vec)\n",
    "knn_val_acc = knn_model.score(x_val_scaled_vec, y_validation) * 100\n",
    "print(knn_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "e267f42e-67a4-48ef-b77b-db2e79deef9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results of the KNN model to the results dictionary\n",
    "results_dict['Model'].append('KNN (Cosine Similarity)')\n",
    "results_dict['Train Accuracy'].append(knn_train_acc)\n",
    "results_dict['Validation Accuracy'].append(knn_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd350dd",
   "metadata": {},
   "source": [
    "The KNN accuracy of 96% for train and 95% for validation seems quite high, and appears to have similar results to the linear regression model with PCA for the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b855214",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd58a8",
   "metadata": {},
   "source": [
    "Next the decision tree model will be created and evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d29fef6e-f4c6-41ac-a69d-9b921bf2bf0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.92439516129032\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Decision Tree Classifier\n",
    "dec_tree_model = DecisionTreeClassifier()\n",
    "# Fit the model on the training data\n",
    "dec_tree_model.fit(X_train_vec, y_train)\n",
    "# Get the % accuracy of the decision tree model on the train data\n",
    "dt_train_acc = dec_tree_model.score(X_train_vec, y_train) * 100\n",
    "print(dt_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "fba98f15-c6a8-48ec-b218-d60f479e1d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.00201612903226\n"
     ]
    }
   ],
   "source": [
    "# Get the % accuracy of the decision tree model on the validation data\n",
    "dt_val_acc = dec_tree_model.score(X_validation_vec, y_validation) * 100\n",
    "print(dt_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4b57c382-2cee-4d7d-a626-3c5e974120c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results of the decision tree model to the results dictionary\n",
    "results_dict['Model'].append('Decision Tree')\n",
    "results_dict['Train Accuracy'].append(dt_train_acc)\n",
    "results_dict['Validation Accuracy'].append(dt_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517163d",
   "metadata": {},
   "source": [
    "The accuracy of the decision tree model is very high for the training data set at 99% but the validation accuracy is significantly lower at 94%. This is likely the result of overfitting on the training data which results in worse validation accuracy than the other two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2843487a",
   "metadata": {},
   "source": [
    "### Naive Bayes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df6f372",
   "metadata": {},
   "source": [
    "The last model will be fitted and evaluated is the naive bayes model. For this purpose, the Bournoulli Naive Bayes model will be used since the result is a binary categorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d7470466-68d6-41c0-afa1-2f891b7ec5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.33971774193549\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "nb_model = BernoulliNB()\n",
    "# Train the model\n",
    "nb_model.fit(X_train_vec, y_train)\n",
    "# Get the model % accuracy of the model on the train data set\n",
    "nb_train_acc = nb_model.score(X_train_vec, y_train) * 100\n",
    "print(nb_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "585c8cb8-f0fc-47f2-bbb5-09bf95a0f3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.91129032258065\n"
     ]
    }
   ],
   "source": [
    "# Get the model % accuracy on the validation data set\n",
    "nb_test_acc = nb_model.score(X_validation_vec, y_validation) * 100\n",
    "print(nb_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f4ad60f5-8218-442f-9cb5-cc309dc45ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results to the results dictionary\n",
    "results_dict['Model'].append('Naive Bayes')\n",
    "results_dict['Train Accuracy'].append(nb_train_acc)\n",
    "results_dict['Validation Accuracy'].append(nb_test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d9979",
   "metadata": {},
   "source": [
    "The unoptimized results from the Naive Bayes model appear to be disappointing compared to the other models with a train accuracy of 89% and a test accuracy of 89% as well. That said, further optimization may improve the performance of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5829cf",
   "metadata": {},
   "source": [
    "### Comparing The Model Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2608c5",
   "metadata": {},
   "source": [
    "The models' accuracy results will be represented graphically and through a table to have a better visual comparison of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5872f62f-a0ea-426b-8a53-34a666c38b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame from the results dictionary\n",
    "results_df = pd.DataFrame(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "edc534ba-a794-4a13-be15-6a95a26d8ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>95.073085</td>\n",
       "      <td>95.362903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>97.341230</td>\n",
       "      <td>96.370968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN (Cosine Similarity)</td>\n",
       "      <td>96.018145</td>\n",
       "      <td>94.758065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>99.924395</td>\n",
       "      <td>94.002016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>89.339718</td>\n",
       "      <td>88.911290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Train Accuracy  Validation Accuracy\n",
       "0      Logistic Regression       95.073085            95.362903\n",
       "1                      SVM       97.341230            96.370968\n",
       "2  KNN (Cosine Similarity)       96.018145            94.758065\n",
       "3            Decision Tree       99.924395            94.002016\n",
       "4              Naive Bayes       89.339718            88.911290"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the results data frame\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "52eda186-8cb8-4046-b225-f51412c84daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1MAAAHYCAYAAACoULKuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3MklEQVR4nO3dd3yN9///8Wf2EDIIiRF716ZWiJg1WjtVfKjqsEqnVrUVLVW6KKVqlFK1g5o1Ymut2qtKaosgIogkcv3+8Mv5OnKyTobgcb/deqtc13Wu63XO9T7XOc/zvq73ZWMYhiEAAAAAQLrYPuoCAAAAAOBxRJgCAAAAACsQpgAAAADACoQpAAAAALACYQoAAAAArECYAgAAAAArEKYAAAAAwAqEKQAAAACwAmEKAAAAAKxAmAKSMWPGDNnY2GjGjBlZsv6XX35ZNjY2CgsLy5L1wzrsF+Q0e/fuVfPmzeXt7S0bGxtVrVr1UZcEK5w8eVIdO3aUr6+vbG1t5eHhkW3btvbzzMbGRo0aNcrQtsPCwmRjY6OXX345Q+t5lIKDg2VjY6ONGzdmaD18vjyZCFPIUWxsbGRjY/Ooy8gUmXXwtUbiAfvB/3LlyqWKFSvq/fff19WrV7O9JlgvcX+m9EUosb0FBwdnW13JSfzi9vB/uXPnVvXq1fXFF1/o9u3b2VqTtV8Kk3svVapUSR999JEiIyMzvdYHRUVFqVWrVvrrr7/04osvatiwYerTp0+WbhOZLyEhQe3bt9fy5cvVunVrffrpp/rwww9TfVxWfyYWK1ZMxYoVy7L1WyMxfNnY2ChPnjy6deuWxeViYmLk5eVlWvbkyZPZXClwn/2jLgDIqdq3b686derI19c3S9Y/atQoffjhhypUqFCWrF+S2rZta/oV+/Lly1q5cqW+/vprLVq0SLt375aXl1eWbftxlR375WlRpUoVtWvXTtL9L5OXLl3S77//rqFDh2r16tUKDQ2VnZ3doy0yjR58LyU+j1GjRmnhwoXauXNnlvUy7Ny5U5cvX9bIkSP10UcfZck2kPVOnTqlQ4cO6bXXXtNPP/2U7du39vPs6NGjcnV1zaKqUmZvb6+bN29qwYIFFnu1Fi1apOvXr8ve3l7x8fHZXyDw/xGmgGS4u7vL3d09y9bv6+ubZUEtUbt27cw+hGJiYlSnTh3t379fEyZM0Keffpql238cZcd+eVpUrVo1SU9ZZGSkKlWqpC1btmjLli0ZPoUouzz8Xvr6669Vu3ZtHTlyROPHj9cnn3ySJdu9cOGCJKlgwYJZsn5kj0e9H639PCtXrlwWVJM2NWrUUFhYmKZOnWoxTE2dOlXe3t4qXbq0tm/fnv0FAv8fp/nhsRUTE6NRo0apUqVKcnV1VZ48edSgQQPNnTvX4vKGYWjcuHGqUKGCnJ2dVahQIQ0YMEA3btyweKpDcueY//3333rxxRdVtGhROTk5KW/evKpcubIGDRqkuLg4SfdPnRg+fLgkKTAw0OwUoUQpnTu9c+dOvfjiiypUqJCcnJzk6+ur5s2ba/78+da/YJKcnZ3VvXt30zYedu3aNQ0ZMkTly5eXi4uL3N3d1aRJE/3xxx8W13fjxg299dZbKly4sJydnVWuXDl9++23OnXqlMVz5BOf86lTpzR27FhVqlRJLi4uZl+o01PD3bt39d1336latWry9PSUq6urihQpoueff15r1641W3bjxo1q06aNChcuLEdHR3l7e6tWrVpJvuyntF/mzZunBg0ayN3dXS4uLnrmmWf0xRdfKCYmJsmyiW3q9u3bev/99+Xn5ycnJyeVKlVKX375pQzDsPiaZrYTJ07oww8/VM2aNeXt7S0nJycVLVpUr732ms6cOZNkecMwNH36dNWtW1fe3t5ydnZWwYIF1bRp02TfW+nh4eGhZ599VpJ05cqVJPMze/8nvo8ladOmTWbvxYycEunm5qaePXtKkv766y/T9Pj4eE2cOFF16tRRnjx55OrqqmrVqmnChAlKSEgwW8eD15IcO3ZMnTp1kre3t2xtbU11J26jV69eprofPCZduHBB/fr1U7FixUztun379tq1a1eSmh88pq1YsUINGzZUnjx5TK/Pg/PXrl2rBg0ayM3NTd7e3urVq5fplMbdu3erVatW8vT0lJubm9q2bav//vsvyfb27NmjQYMGqUqVKvLy8pKzs7NKly6td955R9euXUuxvtDQUDVq1Ei5c+dWnjx51KpVKx0+fNjivrh9+7ZGjx6tmjVrKnfu3HJzc1P58uU1cOBAXb58Ocmyo0aNUtWqVZUrVy65ubmpbt26+u233yyuOyW7d+9Whw4dlD9/ftP7qm/fvqbglMjGxkYBAQGSpOHDh2e4/T3YbsLCwtSlSxfly5dPzs7OqlGjhpYtW5bkMQ9/nm3cuFE2Njb677//9N9//5m9Lx48bls6PfbChQv67LPPVL9+ffn4+MjR0VEFCxbUSy+9lOw+soa9vb169uypbdu26dixY2bzTp48qU2bNqlHjx5ycHBIdh1r165VixYtzNrfBx98kOzpuXv27NFzzz1nandNmzZNNagdO3ZML7/8sooUKSInJycVKFBAXbt21fHjx9P8XENCQhQYGCgfHx85OTnJx8dH/v7++uGHH9K8Djw69EzhsRQbG6vmzZtry5YtqlChgvr376/bt29rwYIFeumll/T3339r9OjRZo/p37+/Jk2apIIFC+r111+Xo6Ojli1bpp07dyouLi7FA3Kiffv2qW7durK1tdULL7yg4sWLKyoqSidPntSkSZM0cuRIOTg46K233tKSJUu0adMm9ezZM13npE+ZMkV9+/aVnZ2dXnjhBZUuXVrh4eHatWuXJk6cqKCgoPS+XGYSv9DZ25u//f/77z81atRIYWFhatiwoVq2bKno6GgtX75czz33nH788Ue9/vrrpuVjYmLUuHFj7d27V9WqVVO3bt1048YNjRw5Ulu2bEmxhoEDB2rr1q1q3bq1WrVqZTrVK7019OjRQ/Pnz9czzzyjHj16yMXFRRcuXNDWrVu1Zs0aNWvWTJK0cuVKtWnTRu7u7nrhhRdUqFAhXbt2TUePHtWkSZPS9KXmgw8+0JgxY+Tt7a1u3bopV65cWrlypemUtXXr1snR0dHsMXFxcWrevLkuXLigli1byt7eXkuWLNGQIUN0584dU+DOSosXL9aPP/6owMBA1atXT46Ojjp06JCmTZumZcuWac+ePSpcuLBp+Q8//FBjxoxR8eLFFRQUJHd3d128eFG7du3SwoUL1aVLlwzVc+PGDe3atUt2dnaqXr262bys2P9Vq1bVsGHDNHz4cBUtWtTsi2JGe8UeDsRxcXF6/vnntWbNGpUrV05du3aVs7OzQkND9eabb+rPP//U7Nmzk6zn5MmTqlOnjsqWLavu3bsrOjpalSpV0rBhw7Rv3z4tXbrU7DTDxP+fOnVK/v7+unjxopo0aaKXXnpJZ8+e1YIFC7RixQotWLBAbdu2TbK9BQsWaPXq1WrVqpX69Omj06dPm81ftmyZli9frjZt2qhPnz7avn27ZsyYobCwMH3++edq1qyZAgIC1Lt3bx06dEjLli3TyZMndfDgQdna/t9vtFOmTFFISIgCAgLUtGlT3bt3T7t379Z3332nlStXateuXcqdO3eS+pYvX66lS5eqZcuW6tOnj44cOWJa/siRI/L29jYte/36dQUGBmr//v0qV66cXnnlFTk6OurkyZOaPn26OnTooAIFCki63yvauHFj/f3336pRo4ZeeeUVJSQkaM2aNeratasOHz6sESNGpGnfL126VJ07d5aNjY06deokPz8/7d69Wz/++KOWLl2qrVu3qkSJEpKkYcOGKSwsTDNnzlRAQICp3WW0/f3333969tlnVaJECf3vf//TtWvXNG/ePLVr105r165VkyZNkn1ssWLFNGzYMI0dO1aS9NZbb5nmpTbAyebNm/Xll18qMDBQHTt2VK5cufTPP/9o4cKFWrZsmbZt25Zpg6S8+uqrGjNmjKZNm6avvvrKNH3q1KkyDEOvvvqqdu/ebfGxEydO1IABA5QrVy4FBQXJ29tboaGhGjNmjJYtW6bt27fL09PTtPz27dvVtGlTxcbGqkOHDipVqpT27dunwMBANW7c2OI2Vq9erQ4dOig+Pl5t2rRRqVKldO7cOS1evFgrVqxQaGhokuPcwyZNmqR+/frJx8dHL7zwgvLly6fw8HAdOHBAM2bMUP/+/a145ZCtDCAHkWSkpVmOHDnSkGS0adPGiIuLM02/dOmSUaRIEUOSsWXLFtP0zZs3G5KMMmXKGNevXzdNv3v3rtGgQQNDklG0aFGzbfz888+GJOPnn382TXv77bcNSUZISEiSmq5du2bcu3fP9PewYcMMSUZoaKjF59CzZ09DknH69GnTtMOHDxv29vaGp6encejQoSSPOXPmjOUXJJl1P1i7YRjGnTt3jMqVKxuSjK+++spsXkBAgGFjY2PMnz/fbPr169eNKlWqGM7OzsbFixdN0z/77DNDktGlSxcjISHBrMZ8+fIZkoyePXtarKtgwYLGqVOnktSdnhoiIyMNGxsbo0aNGkZ8fHySdUVERJj+3b59e0OS8ffffydZ7sqVKxZrfHC/bN261dRGLl++bJoeFxdntGrVypBkjBgxwmw9RYsWNSQZLVu2NG7fvm2afvnyZcPd3d3IkyePERsbm6QeSxJratu2rTFs2DCL/wUEBBiSjGHDhpk99ty5c0ZMTEySda5cudKwtbU13njjDbPpnp6eRsGCBY3o6Ogkj3n4tUpO4nunSpUqpvo++eQT4/XXXzcKFixouLm5GZMmTUryuKza/4Zx/9gSEBCQpvoflNx76datW0bFihUNScbw4cMNw/i/9/ygQYPMaoqPjzdeeeWVJMeO06dPm455Q4YMsbh9S8ehRM2aNTMkGV9++aXZ9C1bthi2traGp6enERUVlWRdNjY2xqpVq5Ldlp2dnbFp0ybT9Hv37hlNmzY1JBnu7u7G7NmzzR732muvGZKMJUuWmE0PCwuzuG9+/PFHQ5IxatSoZLe/bt06s3kffvihxef60ksvGZKMPn36mB1/DcMwoqKizI73ifvy66+/Nlvuzp07RosWLQwbGxtj7969Sep92M2bNw0vLy/Dzs7O2LZtm9m8L774wpBkNG3a1Gx6aGioxfdnaix9Jj7YboKDg83mrV692pBkPPfcc2bTk2tHRYsWTfLZ9/D2H37fXL582axdJdqzZ4/h6upqtGjRwmK9D38eJCdx+fr16xuGYRgNGzY08ufPbzpexsXFGT4+Pqb5ice+f/75x2wdDg4ORp48eYzjx4+brf+NN94wJBmvvvqqaVpCQoJRtmxZi+147Nixptf7wc/za9euGR4eHka+fPmMo0ePmj3m0KFDRq5cuYyqVauaTbf0+VKtWjXD0dHR7LMlUVqPuXi0CFPIUdIapkqWLGnY2NgkOUgahmH89NNPhiSjV69epmm9e/c2JBkzZ85MsvyDX5QfZOnD55133jEkGWvWrEm1RmvC1IABAwxJxrfffpvq+lNi6ct33759DT8/P0OS4e/vb/Zled++fYYko3PnzhbXt2TJEkOSMWHCBNO0kiVLGra2tmb1JxoxYkSKYeq7775L8pj01hAVFWVIMurVq2cW5izp0KGDIclie3mYpf2S2H6mTJmSZPljx44Ztra2RvHixc2mJ4apkydPJnlMjx49DEnGwYMHU63nwZrS8l96vqw988wzSer28vIyihUrZjGApVXieye5/7p06WIcPnzY7DFZuf8NI+Nh6sH3Up8+fYxChQoZkoySJUuafkjJmzev4evrazFAXL9+3bCxsTE6depkmpb4pbFAgQLJvt7JfQk+e/as6bj14A9Kibp27ZrkmJe4rrZt26a4rf/9739J5s2cOdOQZDRo0CDJvE2bNln8Yp+chIQEI0+ePEZgYKDF7Xfv3j3JY06dOmVIMjp27GiadvnyZcPW1tbw9fU1bt26leI2IyIiDDs7O6NWrVoW5ye2v/feey/V+mfNmmVIMrp165ZkXmxsrOm9HxYWZpqeFWGqWLFiFtuan5+fkTdvXrNpmRmmUtKmTRvDycnJ7IeijIapX375xZBkLFq0yDAMwwgJCTF7LpbC1Oeff25IMoYOHZpk/VevXjXc3NwMZ2dn0/su8XtAw4YNkywfHx9vlCxZMsnneWLI+uGHHyw+j7feesuQZPbDqKXPl+rVqxuurq7GtWvX0vT6IOfhND88dm7evKl///1XhQsXVpkyZZLMb9q0qaT792ZJ9Pfff0uS/P39kyxfp06dJKe8JadLly4aN26c2rVrp86dO6tJkyaqX7++SpYsac1TSeLPP/+UJLVs2TJT1rd06VItXbrUbFrz5s21fPlys9Mad+zYIen+aTCWTnlLvLYl8bz1qKgo/fvvvypSpIjFUxgtvc4Pql27dpJp6a0hd+7cev755/X777+rWrVq6tixo/z9/VW7du0ko09169ZNixcvVu3atdWlSxfTKW8Pnt6WksT2ExgYmGRe2bJlVbhwYZ0+fVqRkZFmo7p5eHhYbBtFihSRdP8UpfT4+eefk71XS3BwsMXTBg3D0K+//qoZM2Zo//79un79uu7du2ea//Cpid26ddP48eNVsWJFBQUFqWHDhqpbt65VF6/37NnT7Pqey5cva926dRo0aJBWrFihjRs3mk6Bycr9nxkefC+5uLioWLFi6tq1qz788EN5enrq2LFjunr1qkqXLq3PP//c4jpcXFySXPsh3R/10MnJKV31JLbJBg0aWDx+NW3aVHPmzNHevXvVo0cPs3mW3n8PqlGjRpJpiQMnpDTv3LlzZtPj4uI0efJkzZ07V0eOHNGNGzfMrhs7f/68xe3XrFkzyTRL75ldu3YpISFBDRs2THWf79q1y9TuLbWvxOtdLe2fh6V0PHBwcFBAQIB++eUX/f333ypatGiq67NW1apVLY6GWaRIEdP7KausWLFCP/74o3bv3q2IiIgko+lFRERk2kA+nTp10sCBAzVt2jR16NBBU6ZMUZ48eVI85T2lfeTl5aXq1atr8+bNOnr0qKpWrWr6vpB4bduD7Ozs5O/vr3///ddseuJrvG/fPott6sSJE5Lut6mKFSsmW2u3bt307rvvqmLFiurSpYsaNmyo+vXrm53OipyNMIXHzo0bNyRJPj4+FucnHsATl3vw34nnzj/Izs5OefPmTdO2a9WqpS1btmjkyJFasGCBfvnlF0n3RzwKDg7Wiy++mPYnYkHiRbGZNSx34pfve/fu6d9//9XHH3+sBQsW6M0339SPP/5oWi7xvlNr165NMnDDg6KjoyXdD1OS5dczpemJLO279NYg3R8QYvTo0ZozZ45pZEJnZ2cFBQXp66+/Nn0YdejQQcuXL9c333yjadOmmZ57zZo19eWXX6Z4bYGUtjZ35swZ3bhxwyxMJRdAEr/8Phhqsso777yjsWPHytfXVy1atFChQoXk4uIi6f5F6Q8PHPDdd9+pZMmSmj59ukaNGqVRo0bJ3t5erVu31rfffmu6DsQaBQoUULdu3XTnzh299tprGjJkiNasWSMpa/d/ZkgpyEr/V/8///yT4rVwD9afKLl2lRJrjoNp3Z6ldpvYZlOalxhIEr344osKCQlRiRIl1LZtW9PF9ZI0duxY3b17N93bf/A9k57jZeL+2bVrl8XBORJZ2j8Py8hrn5lSOr48PNhJZvr+++81aNAgeXp6qlmzZvLz85Orq6tsbGy0ZMkS7d+/P9l9aw0XFxd17dpVkydP1p9//qk1a9bo1VdfTTFAp3cfpfQdIbn1JLapKVOmpFh/am3qnXfeUb58+TRx4kSNGzdO3333nWxsbBQYGKivvvoq1Wuu8OgRpvDYSfwAuXTpksX5Fy9eNFtOkvLkySPp/i/jD38ZvHfvnq5evZrmAFO3bl0tX75cd+/e1Z49e7R69WqNHz9eL730kry9vZO9UDUtEr+Inz9/PlOHpLWzs1OZMmX022+/6cyZM5o8ebJat26t559/XtL/vVbjxo3TwIEDU13fg6+nJclNT2TpJpTprUG6/yEbHBys4OBgnT17Vps3b9aMGTP0yy+/KCwsTJs2bTIt27p1a7Vu3Vq3bt3SX3/9peXLl2vSpElq3bq1/v77b5UvXz7Z7TzY5iz1NFlqczlBeHi4vv/+ez3zzDPavn17kov9LY1gZmdnp0GDBmnQoEEKDw/X1q1bNXfuXC1YsEBHjhzRoUOHkvRmpVdiz8iDI0pm9f7Paon1t2/fXosXL07XY625Kas1x8GMbC+9du/erZCQEDVp0kSrVq0y6wlPSEjQmDFjMryNB4+XqUl8Hd5++219++23GdpuRl77x118fLyGDRsmHx8f7d27N0nvU1b1iL366quaOHGiOnfurHv37ql3794pLv/gPrLUK/TwPkr8f3KfXZb2deJj9u/fr8qVK6fxmVjWo0cP9ejRQ5GRkdq+fbtCQkI0ffp0NW/eXEePHqWXKodjaHQ8dnLnzq2SJUvq/Pnz+ueff5LMDw0NlSSzX3OqVasmSdq6dWuS5f/880+rbvjn5OSkevXq6bPPPtP3338vwzC0ZMkS0/zE0y/S0/tQp04dSTL9Wp/Z7OzsNG7cOEnS4MGDTbUlbje1UfgS5cmTRyVKlND58+ctDiFu6XVOTXpreFiRIkXUrVs3rVmzRqVLl9bmzZstDr+cK1cuNW7cWN9++60++ugj3b17V6tWrUpx3YntZ+PGjUnmnTx5UufOnVPx4sWz7Mat1jp16pQSEhLUvHnzJEHq3LlzOnXqVIqPz58/vzp06KD58+ercePG+ueff3To0KEM15V4qtaDv55n9f63tbXN0p7AcuXKycPDQ3/++WeSHpqs8OAxzdLxy9JxMDudPHlS0v2bHT88UurOnTt1586dDG/j2Wefla2trbZs2aLbt2+nedmMSul4EB8fbzr+PQ49CnZ2dul6X0RERCgyMlL16tVLEqSio6PNTq/PTNWqVVO1atV07tw5Va5cWbVq1Up1ecnyPoqMjNS+ffvk7Oxs+hEtcV9Z+gHm3r17Fj/TMnrMssTDw0OtWrXSlClT9PLLL+vq1auZun5kDcIUHkuvvPKKDMPQ+++/b/ZBEBERYbpe4ZVXXjFNT7xmYOTIkWanXsTGxuqjjz5K83a3bNli8dSNxF+znJ2dTdMSTx08e/Zsmtfft29f2dvb67PPPrN47v7D1yRYo3bt2mrTpo2OHTtmOk2xZs2aatCggRYvXqzp06dbfNzBgwcVHh5u+rtHjx5KSEjQkCFDzIaIPnv2rGm43fRIbw1Xrlwxu79Polu3bunmzZuys7MznRq0fv16i1/eLO03SxLb0ogRI8zujXTv3j299957SkhISPWX0kch8Xq2rVu3mr1PoqOj9dprryX5En737l2tX7/e4pDficEktdcqNffu3TMF+geHhs7K/S/dfz+m572YXvb29nrzzTd18eJFDRw40GJ7u3jxoo4cOZIp2ytcuLCaNWumsLCwJO+3v/76S3PmzJGnp6fat2+fKdtLr8S29/CX2fDw8Ewb6tnb21tdunTRhQsX9MEHHyRpt9HR0abjdf78+dWtWzft3r1bn3/+ucUA+u+//yYZJt6Sdu3aycvLS7/99pvpOtdEY8eO1alTp9S0aVP5+fll4Nllj7x58+rKlSsW75VnSf78+eXq6qrdu3ebnb4WFxenQYMGKSIiIqtK1axZsxQSEqJff/011WW7d+8uBwcHjR8/3hTsE33yySeKiopS9+7dTaed1qtXT2XLltXmzZuTXGc8YcKEJNdLSffv/ebh4aHhw4dbvG9jQkKCxTD3sNWrV1tsj4nHuowec5H1OM0POVJK1yZMnDhR7733nlatWqWlS5eqSpUqatWqlek+U+Hh4Ro8eLDZIAgBAQF6/fXX9dNPP6lixYrq2LGjHBwc9Pvvv8vd3V0FCxY0uz9Kcr755hv98ccfatSokUqUKCE3NzcdPnxYq1atkoeHh9k9cAIDA2Vra6shQ4bo4MGDpvtZfPzxx8muv0KFCpo4caL69OmjqlWrmu4zFRERoV27dsnd3d30i3NGfPbZZ1qxYoWGDx+ubt26ydHRUXPmzFHjxo3Vu3dvff/996pdu7Y8PDx07tw5HThwQIcOHdKOHTuUP39+Sfd7tpYsWaK5c+fq+PHjat68uW7cuKH58+erYcOGWrJkSZpe0welp4bz58+rTp06Kl++vKpXr64iRYooKipKy5cv16VLlzRgwADT6YjvvvuuwsLC1KhRI9PNTffs2aMNGzbIz88v1Xsn1atXT4MHD9aYMWP0zDPPqFOnTsqVK5dWrVqlQ4cOyd/fX++//751OyML+fj4qEuXLpo7d66qVq1q2kdr166Vs7Ozqlatqn379pmWv3Pnjpo2bapixYqpdu3aKlq0qGJiYrR27VodPXpUbdq0UYUKFdK8/YcvzA4PD9eGDRt0/Phx5cuXL8mpXlm1/yWpSZMmmjt3rtq2batq1arJ3t5eDRs2VMOGDa1+fR/2ySefaP/+/frxxx/1+++/q3HjxipUqJDCw8P1zz//aNu2bRo5cmS6XsOU/Pjjj6pfv77ef/99/fHHH6pZs6bpPlO2trb6+eefLd7HKTvUqlVL9evX1+LFi1WvXj35+/vr8uXLWrVqlcqWLWsatCKjJkyYoEOHDmnChAlav369mjdvLkdHR50+fVpr1qzRsmXLTKF9woQJ+ueff/Tpp59q1qxZ8vf3V4ECBXThwgUdPXpUu3bt0m+//abixYunuE03NzdNnz5dnTt3VkBAgDp37iw/Pz/t2bNHf/zxh3x8fDR58uRMeX5ZrUmTJtq1a5datmypBg0ayNHRUVWqVDGdAv4wW1tbDRw4UF9++aUqVaqktm3bKjY2VqGhobp27ZoCAwMz5TPKkooVK6Y4kMODihUrprFjx6p///6qXr266T5TmzZt0o4dO1SuXDmze1Ha2Nho2rRpatasmTp27Gi6z9T+/fu1bt06Pffcc1q9erXZNvLmzauFCxeqffv2qlOnjpo0aaKKFSvK1tZWZ86c0Y4dO3T16tVUg2qXLl3k7Owsf39/FStWTIZhaMuWLdq1a5eqV69uGlQLOdgjHEkQSEJpGPo58b4hd+7cMUaOHGlUrFjRcHZ2Ntzc3Iz69esbc+bMsbjue/fuGd9++61RtmxZw9HR0fD19TX69etnREZGGm5ubknuB2FpKNk1a9YYL7/8slG+fHkjT548hqurq1GmTBnjzTffNBsGN9GsWbNM98fRQ0PcWhoiNdH27duNDh06GN7e3oaDg4Ph6+trtGjRwliwYEGaXsfk7o3zoMThwr///nvTtKioKGPkyJFG9erVjVy5chnOzs5GsWLFjFatWhmTJ09Ocu+h69evG2+++abh6+trODo6GmXLljW+/vpr46+//jIkGW+99ZbFuiw95/TWcP36dWP48OFGYGCgUbBgQcPR0dHw8fExAgICjDlz5pgNlz1v3jyjS5cuRqlSpYxcuXIZuXPnNipWrGh89NFHRnh4eJpr/O2334z69esbbm5uhpOTk1GhQgVjxIgRxp07d5Ism9KQw6kNm/+wtOzPxHU+PPTyrVu3jI8++sgoWbKk4eTkZBQuXNjo16+fERERYRpSOFFsbKwxevRo47nnnjOKFCliODk5Gfny5TNq165tTJo0ybh7926a6k1uaHRnZ2ejXLlyxqBBg4zz589bfGxW7H/DuD+M9ksvvWTkz5/fsLW1TfMw1Wl57R+UkJBg/PLLL0bjxo0NT09Pw8HBwShYsKBRv359Y+TIkWb3ikvLkNEp3WfKMO7fR6xPnz6Gn5+f4eDgYOTNm9do27atsXPnznSvK6X5KQ3tndzzuHr1qtG3b1+jaNGihpOTk1GiRAljyJAhxq1btyy+P1KrT8kM0x0dHW2MGDHCqFSpkuHi4mK4ubkZ5cuXNwYNGpTk3j137941xo8fb9StW9fIkyeP4ejoaBQpUsRo3Lix8d133yW5P1lKdu7cabRr187Ily+f4eDgYBQpUsTo06ePxbadFUOjJ9duHn5fG0byr210dLRpqH87O7sk67X0msfFxRnffPONUb58ecPZ2dkoUKCA0b17dyMsLMzi8TOjQ6OnxtLQ6InWrFljNGvWzPDw8DAcHR2NkiVLGu+//77Z/ccetHv3bqNFixaGm5ub4ebmZjRp0sTYvn17isfs06dPG/379zdKlSplODk5Gblz5zbKli1rdO/ePck9KS29PpMmTTLatWtnFC9e3HBxcTE8PT2NqlWrGqNHj7Z4Py/kPDaG8VC/OPCU+eeff1SmTBl16dLF4gX5SL8pU6bo9ddf148//qg33njjUZcDAACQJbhmCk+NS5cuJRku9vbt23rrrbckSR07dnwEVT3eLly4kGTa2bNn9fnnn8vBwUEvvPDCI6gKAAAge3DNFJ4aY8eO1W+//aZGjRrJ19dXly5d0vr163Xu3Dm1bt2aMGWFjh07Ki4uTjVq1JCHh4fCwsK0fPly3b59W2PGjMm0mzYCAADkRJzmh6fG+vXr9d1332nfvn2KiIiQnZ2dypYtq65du2rQoEFJhu9F6iZNmqRff/1VJ06c0PXr1+Xm5qbq1avrzTffVLt27R51eQAAAFmKMAUAAAAAVuCaKQAAAACwAmEKAAAAAKxAmAIAAAAAKzzy0fyOHDmiZcuW6fTp07p+/bree+89Pfvss6b5hmFowYIFWr9+vaKjo1W6dGn17t1bRYoUMS0TFxenWbNmadu2bYqNjdUzzzyjV199VXnz5n0UTwkAAADAU+CRh6m7d++qWLFiCgwM1DfffJNk/tKlS7VixQr169dPvr6+Wrx4sUaMGKGxY8fKxcVFkjRjxgzt2bNHgwYNUu7cufXLL7/oyy+/1OjRo2Vrm77Ot+vXrys+Pj5TnhsAAACAx4+9vb08PT1TXy4baklRtWrVVK1aNYvzDMPQypUr1b59e9WuXVuS1L9/f7322mvaunWrmjVrptu3b2vDhg168803VblyZUnSm2++qb59++rAgQOqWrVquuqJj49XXFxchp4TAAAAgCffIw9TKQkPD1dkZKSqVKlimubg4KAKFSro+PHjatasmU6dOqV79+6ZgpQkeXl5yc/PTydOnEg2TMXFxZmFJhsbG1NPl42NTdY8IQAAAABPjBwdpiIjIyVJ7u7uZtPd3d0VERFhWsbe3l5ubm5Jlkl8vCUhISFauHCh6e/ixYtr9OjR8vb2zpziAQAAADzRcnSYSvRwT1Fa7jOc2jLt27dXmzZtkmzjypUrXDMFAAAAPMXs7e3T1MmSo8OUh4eHpPu9Tw9eABYVFWXqrfLw8FB8fLyio6PNeqeioqJUtmzZZNft4OAgBwcHi/PSEtYAAAAAPN1y9H2m8ufPLw8PDx04cMA0LT4+XkeOHDEFpRIlSsjOzs5smevXr+vMmTMqU6ZMttcMAAAA4OnwyHumYmJidOnSJdPf4eHhCgsLk5ubm/Lly6dWrVopJCREvr6+8vHxUUhIiJycnOTv7y9JcnV1VePGjTVr1izlzp1bbm5umjVrlvz8/MwGpQAAAACAzGRjPOJz2g4fPqzhw4cnmR4QEKD+/fubbtq7bt063bp1S6VKlVLv3r3l5+dnWjY2NlazZ8/W1q1bzW7amy9fvnTXc+XKFYZGBwAAAJ5iDg4Oabpm6pGHqZyGMAUAAAA83dIapnL0NVMAAAAAkFMRpgAAAADACoQpAAAAALACYQoAAAAArECYAgAAAAArEKYAAAAAwAqEKQAAAACwgv2jLuBJ0XlBwqMuAdloQWd+hwAAAHja8Y0QAAAAAKxAmAIAAAAAKxCmAAAAAMAKXDMFPGa4Pu/pwvV5AADkXHxKAwAAAIAV6JkCAFhEL+jThV5QAEg/jpwAAAAAYAXCFAAAAABYgdP8AADAI8UppU8XTinFk4TWDAAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWIEwBQAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAV7B91AQAAAEB26Lwg4VGXgGy0oHPW9xvRMwUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWIEwBQAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWIEwBQAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFawf9QFpObevXtasGCBtmzZosjISHl6eqpRo0bq0KGDbG3vZ0HDMLRgwQKtX79e0dHRKl26tHr37q0iRYo84uoBAAAAPKlyfJhaunSp1q5dq/79+6tw4cI6deqUJk6cKFdXV7Vq1cq0zIoVK9SvXz/5+vpq8eLFGjFihMaOHSsXF5dH/AwAAAAAPIly/Gl+J06cUM2aNVW9enXlz59fderUUeXKlfXvv/9Kut8rtXLlSrVv3161a9eWn5+f+vfvr7t372rr1q2PuHoAAAAAT6oc3zNVrlw5rV27VhcuXFDBggUVFham48ePq2fPnpKk8PBwRUZGqkqVKqbHODg4qEKFCjp+/LiaNWtmcb1xcXGKi4sz/W1jY2PqxbKxscnCZ4QnAW0E2YW2huxCW0N2oa0hu2RHW8vxYapt27a6ffu23n77bdna2iohIUFdunSRv7+/JCkyMlKS5O7ubvY4d3d3RUREJLvekJAQLVy40PR38eLFNXr0aHl7e1tZ6TkrH4fHka+v7yPcOm3taUJbQ3ahrSG70NaQXbKjreX4MLV9+3Zt2bJFAwcOVJEiRRQWFqYZM2aYBqJI9HDyNAwjxfW2b99ebdq0SfL4K1euKD4+PvOeAJ5IFy9efNQl4ClBW0N2oa0hu9DWkF0y0tbs7e3T1MmS48PU7Nmz1bZtW9WvX1+S5OfnpytXrmjJkiVq1KiRPDw8JMk00l+iqKioJL1VD3JwcJCDg4PFeakFMYA2guxCW0N2oa0hu9DWkF2yo63l+AEo7t69axoCPZGtra3pxcmfP788PDx04MAB0/z4+HgdOXJEZcuWzdZaAQAAADw9cnzPVI0aNbR48WLly5dPhQsXVlhYmJYvX67AwEBJ90/Pa9WqlUJCQuTr6ysfHx+FhITIycnJdF0VAAAAAGS2HB+mXnnlFc2bN09Tp07VjRs35OXlpWbNmqlTp06mZdq2bavY2FhNnTpVt27dUqlSpTR06FDuMQUAAAAgy+T4MOXi4qKXX35ZL7/8crLL2NjYKCgoSEFBQdlXGAAAAICnWo6/ZgoAAAAAciLCFAAAAABYgTAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWIEwBQAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFawz8iDb9++rRkzZujvv/+WYRiqWrWqXn75Zbm5uWVWfQAAAACQI2WoZ2ratGm6fv263njjDb388sv6999/NXXq1MyqDQAAAAByrDT1TF24cEEFCxZMMn3//v36/vvv5erqKklydXXV+PHjM7dCAAAAAMiB0tQzNXjwYC1cuFDx8fFm011cXHT58mXT35cvXzYFKwAAAAB4kqWpZ2rYsGH66aeftG3bNr3xxhsqV66cJKlNmzYKDg5WlSpVdPfuXR04cED/+9//srRgAAAAAMgJ0hSmSpcurdGjR2vZsmUaOXKk/P391b17d7Vo0UIFCxbUvn37ZBiGWrdurcqVK2d1zQAAAADwyKV5ND9bW1u1a9dOdevW1dSpU/X222/r5ZdfVr169VSpUqWsrBEAAAAAcpx0j+ZXoEABDR06VN27d9fPP/+sUaNG6cqVK1lRGwAAAADkWGnumTp27Jj27t2ruLg4lS1bVg0bNlT16tX1yy+/6N1331Xnzp3VunVr2dpyH2AAAAAAT740hal169Zp6tSpqlSpkpycnLRu3Trt379fb7zxhvr166eAgABNmTJFW7Zs0RtvvKGSJUtmdd0AAAAA8EilqRtp6dKl6tGjh4YOHar33ntPQ4cO1YYNGxQdHS1Jqlixor7++mvVqFFDwcHBWVkvAAAAAOQIaeqZio6ONrtpb+K/b926JTc3t/srsrfXiy++KH9//ywoEwAAAAByljSFqSpVqmjmzJm6ffu2nJyctHr1avn6+qpAgQJJli1UqFCmFwkAAAAAOU2awtRrr72mmTNn6ueffzYNQDF48OCsrg0AAAAAcqw0halcuXKpX79+WV0LAAAAADw2GMccAAAAAKxAmAIAAAAAKxCmAAAAAMAKhCkAAAAAsAJhCgAAAACskO4wderUqayoAwAAAAAeK2kaGv1BQ4YMUalSpfTcc8+pbt26srdP9yoAAAAA4LGX7p6pfv36yTAMTZgwQX379tXcuXN19erVrKgNAAAAAHKsdHcrBQQEKCAgQCdPntTq1av1+++/a+nSpapRo4ZatmypihUrZkWdAAAAAJCjWH2OXqlSpTRgwAD16NFD69at07p16/TZZ5+pcOHCeu655xQQECBHR8fMrBUAAAAAcowMj+Znb28vJycn07VTd+/e1dSpUzVo0CCdOHEiwwUCAAAAQE5kdc/Uf//9pzVr1mjr1q2Kj49XnTp1NHDgQJUqVUr//feffvrpJ02ZMkVfffVVZtYLAAAAADlCusPU9u3btWbNGh07dkx58uRRmzZt1Lx5c3l4eJiWKVq0qF566SWNHDkyM2sFAAAAgBwj3WFq3LhxKlasmPr27St/f/9kh0b39vZWgwYNMlwgAAAAAORE6Q5Tw4cPV7ly5VJdrkCBAurXr59VRQEAAABATpfuASjSEqQAAAAA4EmX7jA1c+ZMff/99xbnff/995o1a1aGiwIAAACAnC7dYWr37t2qXLmyxXlVqlTR7t27M1wUAAAAAOR06Q5T165dU/78+S3O8/b21tWrVzNcFAAAAADkdOkOU87OzoqIiLA4LyIiQg4ODhkuCgAAAAByunSHqdKlS2v58uWKj483mx4fH68VK1aobNmymVYcAAAAAORU6R4avWPHjho2bJjeffddNW7cWF5eXrp69apCQ0MVERGh1157LSvqBAAAAIAcJd1hqnTp0ho8eLCmTZumOXPmmKYXKFBAgwcPVqlSpTK1QAAAAADIidIdpiSpatWqGj9+vC5evKioqCjlyZNHvr6+mV0bAAAAAORYVoWpRL6+voQoAAAAAE8lq8PUmTNndP78ecXGxiaZFxAQkKGiAAAAACCnS3eYunv3rsaMGaNDhw4luwxhCgAAAMCTLt1Doy9atEjh4eEKDg6WJL377rv6+OOPVbt2bfn6+mr06NGZXSMAAAAA5DjpDlO7du1S27ZtTfeTypcvnypVqqR33nlHxYsX1x9//JHpRQIAAABATpPuMHXlyhUVKlRItrb3H/rgNVMNGjTQrl27Mq86AAAAAMih0h2mcuXKpbt370qS3N3ddfHiRdO8+Ph40zwAAAAAeJKlO0z5+fnpwoULkqSKFSsqJCREx44d08mTJ7Vo0SIVLVo004sEAAAAgJwm3WEqMDBQMTExkqSXXnpJd+/e1bBhwzR06FBduXJFPXr0yPQiAQAAACCnSffQ6PXq1TP9O3/+/Bo3bpwOHTokGxsblS1bVm5ubplaIAAAAADkROnqmYqNjdW4ceN07Ngx0zRnZ2fVrFlTNWrUIEgBAAAAeGqkK0w5Ojpq9+7dSkhIyKp6AAAAAOCxkO7T/IoVK6azZ8+qQoUKWVGPRdeuXdPs2bO1b98+xcbGytfXV3379lWJEiUkSYZhaMGCBVq/fr2io6NVunRp9e7dW0WKFMm2GgEAAAA8XdI9AEXXrl21bNkyHTlyJCvqSSI6OlqffPKJ7O3t9dFHH+nbb79Vjx495Orqalpm6dKlWrFihV555RWNGjVKHh4eGjFihO7cuZMtNQIAAAB4+qS7Z2rq1KmKiYnR8OHD5ebmJg8PD9nY2Jjm29jY6Kuvvsq0ApcuXaq8efOqX79+pmn58+c3/dswDK1cuVLt27dX7dq1JUn9+/fXa6+9pq1bt6pZs2YW1xsXF6e4uDizul1cXEz/BlJCG0F2oa0hu9DWkF1oa8gu2dHW0h2mcufOrTx58mRFLRbt3r1bVapU0bfffqsjR47Iy8tLzZs3V9OmTSVJ4eHhioyMVJUqVUyPcXBwUIUKFXT8+PFkw1RISIgWLlxo+rt48eIaPXq0vL29raz0nJWPw+PI19f3EW6dtvY0oa0hu9DWkF1oa8gu2dHW0h2mgoODs6CM5IWHh2vt2rVq3bq12rdvr5MnT+rnn3+Wg4ODAgICFBkZKUlyd3c3e5y7u7siIiKSXW/79u3Vpk0b09+JyfXKlSuKj4/P/CeCJ8rFixcfdQl4StDWkF1oa8gutDVkl4y0NXt7+zR1sqQ7TGW3hIQElSxZUl27dpV0vwfp7Nmz+uOPPxQQEGBa7uFuPMMwUlyvg4ODHBwcLM5L7bEAbQTZhbaG7EJbQ3ahrSG7ZEdbS3eYSsvAE5k50p+np6cKFy5sNq1w4cL666+/JEkeHh6SpMjISHl6epqWiYqKStJbBQAAAACZJd1havjw4akuM2/ePKuKsaRs2bK6cOGC2bQLFy6Yut3y588vDw8PHThwQMWLF5ckxcfH68iRI+rWrVum1QEAAAAAD0p3mBo2bFiSaVFRUdq9e7eOHz+u3r17Z0phiVq3bq1PPvlEixcvVr169XTy5EmtX79er7/+uqT7p/e1atVKISEh8vX1lY+Pj0JCQuTk5CR/f/9MrQUAAAAAEqU7TCV3Cl+dOnX0008/ad++fapatWpG6zIpVaqU3nvvPc2ZM0eLFi1S/vz51bNnTzVo0MC0TNu2bRUbG6upU6fq1q1bKlWqlIYOHWoa6hwAAAAAMlumDkDx7LPP6ocfftDLL7+cmatVjRo1VKNGjWTn29jYKCgoSEFBQZm6XQAAAABIjm1mruzWrVsMKw4AAADgqZDunilL926Ki4vTf//9pzlz5qh06dKZUhgAAAAA5GTpDlP9+/dPdl7BggX1yiuvZKggAAAAAHgcpDtM9e3bN8k0R0dHeXt7q2TJkrK1zdQzBwEAAAAgR0p3mGrUqFEWlAEAAAAAj5d0dyNFRUUluYluogsXLigqKirDRQEAAABATpfuMDV16lQtW7bM4rzly5dr+vTpGS4KAAAAAHK6dIep48ePJ3tT3ipVquj48eMZrQkAAAAAcrx0h6mbN2/Kzc3N4rxcuXJxmh8AAACAp0K6w5S7u7vOnDljcd6ZM2eSDVoAAAAA8CRJd5iqWrWqQkJCkgxCcfHiRS1ZskTVqlXLtOIAAAAAIKdK99DonTt31t69e/X++++rYsWK8vLy0rVr13T48GHlzp1bQUFBWVEnAAAAAOQo6Q5TXl5eGjVqlObNm6d9+/bp4MGDypMnjxo0aKCgoCB5eXllRZ0AAAAAkKOkO0xJ9wNV3759M7sWAAAAAHhspPuaqfj4eMXExFicFxMTo/j4+AwXBQAAAAA5XbrD1OTJk/Xjjz9anPfTTz9p6tSpGS4KAAAAAHK6dIepw4cPq2bNmhbn1ahRQwcPHsxwUQAAAACQ06U7TN24cUOenp4W53l4eCgyMjKjNQEAAABAjpfuMOXq6qpLly5ZnHfp0iW5uLhkuCgAAAAAyOnSHaYqVqyoJUuWKDo62mx6dHS0lixZomeeeSbTigMAAACAnCrdQ6MHBQVpyJAhGjhwoOrVqycvLy9dvXpVf/75p+Lj47lpLwAAAICnQrrDVMGCBTV8+HD98ssvWr9+vRISEmRra6sKFSqoR48eKliwYFbUCQAAAAA5ilU37S1WrJg+/fRTxcbGKjo6Wm5ubnJ0dJQk3bt3T3Z2dplaJAAAAADkNOm+ZupBjo6O8vLykqOjo86dO6dffvlFffr0yazaAAAAACDHsqpnKlFMTIy2bt2q0NBQnTx5UpJUunTpTCkMAAAAAHIyq8LU0aNHtWHDBv3111+6e/euJMnf319t27aVn59fphYIAAAAADlRmsPU9evXtWnTJoWGhpruM1WxYkXVqVNH06ZNU5MmTQhSAAAAAJ4aaQpTo0eP1r59+5SQkKC8efOqQ4cOCgwMVP78+XX79m1NmzYtq+sEAAAAgBwlTWFq7969kqTq1aurX79+yp07d5YWBQAAAAA5XZpG82vVqpXy5MmjvXv3qk+fPho7dqwOHDiQ1bUBAAAAQI6Vpp6pnj17qnv37tq1a5c2bNigP//8Uzt27FC+fPlUp06drK4RAAAAAHKcNA9AYWdnpzp16qhOnTq6du2aNmzYoE2bNmn58uWSpHnz5qlly5aqVasWN+0FAAAA8MSzamh0Ly8vderUSZ06ddLBgwe1YcMG7dq1S9999508PDw0efLkzK4TAAAAAHKUDN20V5IqVaqkSpUq6datW9qyZYtCQ0Mzoy4AAAAAyNEyHKYS5cqVS88995yee+65zFolAAAAAORYaRrNDwAAAABgjjAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWMHq0fxu3LihK1euKDY2Nsm8ChUqZKgoAAAAAMjp0h2mrl+/rgkTJujQoUPJLjNv3rwMFQUAAAAAOV26w9S0adN0+vRpdevWTUWLFpWDg0NW1AUAAAAAOVq6w9TRo0f1v//9T4GBgVlRDwAAAAA8FqwagCJv3ryZXQcAAAAAPFbSHabq1q2rvXv3ZkUtAAAAAPDYSPdpfnXr1tXkyZOVkJCgmjVrys3NLckyJUqUyJTiAAAAACCnSneY+uyzzyRJa9as0Zo1aywuw2h+AAAAAJ506Q5Tffv2zYo6AAAAAOCxku4w1ahRoywoAwAAAAAeL+kOUw+6cOGCoqOjlTt3bvn6+mZWTQAAAACQ41kVpnbs2KFZs2bp6tWrpml58+ZVjx49VKdOnUwrDgAAAAByqnQPjb53716NHTtWrq6u6tatmwYMGKCuXbvK1dVVY8eO1d9//50VdQIAAABAjpLunqmQkBBVqVJFH374oWxt/y+LvfDCC/riiy+0ePFiVatWLVOLBAAAAICcJt09U2FhYWrevLlZkJIkGxsbtWjRQmFhYZlVGwAAAADkWOkOU7a2toqPj7c4Lz4+PknIAgAAAIAnUbqTT8mSJbVs2TLFxsaaTY+Li9Pvv/+uUqVKZVpxAAAAAJBTpfuaqaCgIH322WcaMGCA6tSpIw8PD0VGRuqvv/5SdHS0Pv3006yoEwAAAABylHSHqXLlyunjjz/Wr7/+qjVr1ki6f71U6dKlNWjQIJUtWzbTiwQAAACAnMaq+0xVqFBBI0eO1N27d3Xr1i3lypVLTk5OmV0bAAAAAORYVoWpRE5OToQoAAAAAE+lNIWpTZs2qXr16sqdO7c2bdqU6vIBAQEZLgwAAAAAcrI0hamJEydq5MiRyp07tyZOnJjq8oQpAAAAAE+6NIWpCRMmyNPT0/RvAAAAAHjapSlMeXt7W/w3AAAAADyt0n3T3gEDBigsLMzivDNnzmjAgAEZrSlFISEhCgoK0owZM0zTDMPQ/Pnz9cYbb6hbt24KDg7W2bNns7QOAAAAAE+3dIepK1euKD4+3uK8uLg4XblyJcNFJefkyZNat26dihYtajZ96dKlWrFihV555RWNGjVKHh4eGjFihO7cuZNltQAAAAB4uqU7TKXk8uXLcnFxycxVmsTExGj8+PF64403lCtXLtN0wzC0cuVKtW/fXrVr15afn5/69++vu3fvauvWrVlSCwAAAACk6ZqpjRs3mg2JPnXq1CShKTY2Vv/9958qVKiQuRU+sM1q1aqpcuXKWrx4sWl6eHi4IiMjVaVKFdM0BwcHVahQQcePH1ezZs0sri8uLk5xcXGmv21sbEzPycbGJkueA54ctBFkF9oasgttDdmFtobskh1tLU1hKjY2VlFRUaa/b926ZRZEpPsBpl69egoKCsrcCiVt27ZNp0+f1qhRo5LMi4yMlCS5u7ubTXd3d1dERESy6wwJCdHChQtNfxcvXlyjR4/OwAAb56x8HB5Hvr6+j3DrtLWnCW0N2YW2huxCW0N2yY62lqYw1bx5czVv3lyS1L9/f7377rsqVqxYVtZlEhERoRkzZmjo0KFydHRMdrmHk6dhGCmut3379mrTpk2Sx6d0TRiQ6OLFi4+6BDwlaGvILrQ1ZBfaGrJLRtqavb19mjpZ0hSmHvTDDz9YVZC1Tp06pRs3bujDDz80TUtISNDRo0e1evVqjR07VtL9HqrEe2FJUlRUVJLeqgc5ODjIwcHB4rzUghhAG0F2oa0hu9DWkF1oa8gu2dHW0h2mHhQVFaXY2Ngk0/Ply5eR1ZqpVKmSvv76a7NpkyZNUsGCBdW2bVsVKFBAHh4eOnDggIoXLy5Jio+P15EjR9StW7dMqwMAAAAAHmRVmFq0aJFWrVqlmzdvWpw/b968DBX1IBcXF/n5+ZlNc3JyUu7cuU3TW7VqpZCQEPn6+srHx0chISFycnKSv79/ptUBAAAAAA9Kd5jasGGDlixZonbt2mn+/Plq3769JGnz5s1ydHRU27ZtM73I1LRt21axsbGaOnWqbt26pVKlSmno0KFZNkw7AAAAAKQ7TK1Zs0bt27c3halnn31WJUqUUIcOHTRs2LBke6syU3BwsNnfNjY2CgoKypKRBAEAAADAknTftPfSpUsqU6aMafS7xJHvHB0d1aZNG61bty5zKwQAAACAHCjdYcrOzk7S/93k9tq1a6Z5uXPnNvsbAAAAAJ5U6Q5Tvr6+ppvhlixZUuvXr1d8fLwSEhK0bt26DNz0FgAAAAAeH+kOU9WqVdPRo0cl3b/x7aFDh9SrVy/16tVLf/311yMZgAIAAAAAslu6B6Do1KmT6d/PPPOMPv/8c23fvl2SVL16dT3zzDOZVx0AAAAA5FAZummvJJUqVUqlSpXKjFoAAAAA4LGR7tP8AAAAAABp7Jnq37+/aSj0tJgwYYLVBQEAAADA4yBNYapChQpmYerQoUOKjIxU2bJl5e7urhs3buj48ePy9PRUxYoVs6xYAAAAAMgp0twzlWjz5s06fvy4vv/+e+XLl880/cqVKxoxYoQqVKiQ+VUCAAAAQA6T7mumlixZos6dO5sFKUny9vZWp06dtHTp0kwrDgAAAAByqnSHqcuXL8vV1dXivFy5cik8PDzDRQEAAABATpfuMOXt7a0NGzZYnLd+/Xp5e3tnuCgAAAAAyOnSfZ+pdu3aadKkSRoyZIjq168vDw8PRUZGatu2bTp16pT69OmTFXUCAAAAQI6S7jDVqFEjSdLcuXM1a9Ys03QPDw+98cYbCgwMzLTiAAAAACCnSneYku4HqoCAAF24cEE3b95U7ty5VbBgwXTdiwoAAAAAHmdWhSlJsrGxUaFChTKzFgAAAAB4bKQpTB05ckQlSpSQs7Ozjhw5kury3GsKAAAAwJMuTWFq+PDhGjlypEqVKqXhw4enuvy8efMyXBgAAAAA5GRpClPDhg1T4cKFTf8GAAAAgKddmsLUg6ftcQofAAAAAFhx014AAAAAQBp7phYuXJiulXbq1MmqYgAAAADgcZGmMLVgwYJ0rZQwBQAAAOBJl6Ywxeh8AAAAAGCOa6YAAAAAwAqEKQAAAACwQppO83vYkSNHtGrVKp0/f16xsbFm82xsbDR+/PhMKQ4AAAAAcqp090wdO3ZMn3/+uW7fvq3z58+rUKFC8vLyUkREhOzs7FS+fPmsqBMAAAAAcpR0h6n58+erUaNGGjp0qCTpxRdf1GeffabRo0crJiZGzz77bKYXCQAAAAA5TbrD1NmzZ80CU0JCgiSpaNGi6tixoxYtWpR51QEAAABADpXuMHX37l05OzvL1tZW9vb2unnzpmlewYIFde7cuUwtEAAAAAByonSHqXz58unGjRuSpMKFC2vv3r2meUeOHJGbm1vmVQcAAAAAOVS6R/OrUKGCDh8+rDp16qhJkyaaNm2azp8/LwcHB+3fv19t2rTJijoBAAAAIEdJU5iKiopSnjx5JElBQUGKjo6WJDVv3lyxsbHasmWLbGxs1KFDB3Xo0CHrqgUAAACAHCJNYeqNN95QzZo11bhxY1WtWtUUrCSpTZs29EYBAAAAeOqkKUzVrVtXu3bt0s6dO+Xp6alGjRqpUaNG8vHxyer6AAAAACBHSlOYGjhwoG7fvq2tW7dq48aNCgkJUUhIiCpUqKDAwEDVqVNHjo6OWV0rAAAAAOQYaR6AwtXVVc2bN1fz5s117tw5bdiwQVu3btUPP/yg6dOnq379+goMDFSpUqWysl4AAAAAyBHSPZqfdH9I9B49eqh79+7au3evNmzYoNDQUK1bt05FihTR119/ndl1AgAAAECOku77TJk92NZWNWvW1Ouvv67nnntOknT27NlMKQwAAAAAcjKreqYkKSEhQbt371ZoaKj27dunhIQE+fn5qXHjxplZHwAAAADkSOkOU2fPnlVoaKi2bNmiqKgoubq6qkmTJmrcuLFKlCiRFTUCAAAAQI6TpjCVOJJfaGioTp06JUmM5AcAAADgqZamMPX6668rLi5Onp6eateunQIDA7nHFAAAAICnWprCVNWqVdW4cWNVrVpVtrYZGrMCAAAAAJ4IaQpT7733XlbXAQAAAACPFbqZAAAAAMAKhCkAAAAAsAJhCgAAAACsQJgCAAAAACsQpgAAAADACoQpAAAAALACYQoAAAAArECYAgAAAAArEKYAAAAAwAqEKQAAAACwAmEKAAAAAKxAmAIAAAAAKxCmAAAAAMAKhCkAAAAAsAJhCgAAAACsQJgCAAAAACsQpgAAAADACoQpAAAAALCC/aMuIDUhISHauXOnzp8/L0dHR5UpU0bdu3dXwYIFTcsYhqEFCxZo/fr1io6OVunSpdW7d28VKVLkEVYOAAAA4EmW43umjhw5ohYtWmjkyJH6+OOPlZCQoBEjRigmJsa0zNKlS7VixQq98sorGjVqlDw8PDRixAjduXPnEVYOAAAA4EmW48PU0KFD1ahRIxUpUkTFihVTv379FBERoVOnTkm63yu1cuVKtW/fXrVr15afn5/69++vu3fvauvWrY+4egAAAABPqhx/mt/Dbt++LUlyc3OTJIWHhysyMlJVqlQxLePg4KAKFSro+PHjatasmcX1xMXFKS4uzvS3jY2NXFxcTP8GUkIbQXahrSG70NaQXWhryC7Z0dYeqzBlGIZmzpypcuXKyc/PT5IUGRkpSXJ3dzdb1t3dXREREcmuKyQkRAsXLjT9Xbx4cY0ePVre3t5WVnfOysfhceTr6/sIt05be5rQ1pBdaGvILrQ1ZJfsaGuPVZiaNm2azpw5o88++yzJvIeTp2EYKa6rffv2atOmTZLHX7lyRfHx8ZlQLZ5kFy9efNQl4ClBW0N2oa0hu9DWkF0y0tbs7e3T1Mny2ISp6dOna8+ePRo+fLjy5s1rmu7h4SHpfg+Vp6enaXpUVFSS3qoHOTg4yMHBweK81IIYQBtBdqGtIbvQ1pBdaGvILtnR1nL8ABSGYWjatGn666+/9Omnnyp//vxm8/Pnzy8PDw8dOHDANC0+Pl5HjhxR2bJls7tcAAAAAE+JHN8zNW3aNG3dulWDBw+Wi4uL6RopV1dXOTo6ysbGRq1atVJISIh8fX3l4+OjkJAQOTk5yd/f/9EWDwAAAOCJlePD1B9//CFJCg4ONpver18/NWrUSJLUtm1bxcbGaurUqbp165ZKlSqloUOHmkbnAwAAAIDMluPD1Pz581NdxsbGRkFBQQoKCsqGigAAAADgMbhmCgAAAAByIsIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWIEwBQAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWIEwBQAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWIEwBQAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWIEwBQAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAXCFAAAAABYgTAFAAAAAFYgTAEAAACAFQhTAAAAAGAFwhQAAAAAWIEwBQAAAABWIEwBAAAAgBUIUwAAAABgBcIUAAAAAFiBMAUAAAAAViBMAQAAAIAVCFMAAAAAYAX7R11AZlqzZo2WLVumyMhIFS5cWC+//LLKly//qMsCAAAA8AR6Ynqmtm/frhkzZqhDhw4aPXq0ypcvry+++EIRERGPujQAAAAAT6AnJkwtX75cjRs3VpMmTUy9Uvny5dMff/zxqEsDAAAA8AR6Ik7zi4+P16lTp9SuXTuz6ZUrV9bx48ctPiYuLk5xcXGmv21sbOTi4iJ7e+tekjLeCVY9Do8nB4dH9zsEbe3pQltDdqGtIbvQ1pBdMtLW0poJnogwFRUVpYSEBLm7u5tNd3d3V2RkpMXHhISEaOHChaa/69evr0GDBsnT09OqGn7uatXDgHSjrSG70NaQXWhryC60NWS2J+Y0P+l+71JapklS+/btNWPGDNN/r732mllPFVJ3584dffDBB7pz586jLgVPONoasgttDdmFtobsQlvLWk9Ez1SePHlka2ubpBfqxo0bSXqrEjk4OMjBwSEbqntyGYah06dPyzCMR10KnnC0NWQX2hqyC20N2YW2lrWeiJ4pe3t7lShRQgcOHDCbfuDAAZUtW/YRVQUAAADgSfZE9ExJUps2bTR+/HiVKFFCZcqU0bp16xQREaFmzZo96tIAAAAAPIGemDBVr1493bx5U4sWLdL169dVpEgRDRkyRN7e3o+6tCeWg4ODOnXqxOmSyHK0NWQX2hqyC20N2YW2lrVsDE6gBAAAAIB0eyKumQIAAACA7EaYAgAAAAArEKYAAAAAwAqEKQCSpP79+2vFihVWP37jxo16+eWXM6+gJ0hwcLBmzJjxqMt4ZIYNG6atW7dm6zZ/+OEHjRkzJlu3aUlmvS+CgoK0c+dOSVJ4eLiCgoIUFhaW4fVm9H0vSWfOnFGfPn0UExOT4XoeF+l53TLjNcbT4Wn/rHhcMQAFTG7cuKF58+bp77//1o0bN5QrVy4VK1ZM7du31zfffKNWrVqpY8eOSR4XEhKi5cuXa/Lkydq6dasmTpyoQoUK6bvvvjNbbvv27Ro7dqy8vb31ww8/ZNfTeiL88MMPunXrlgYPHpxl24iKipKTk5OcnJxSXbZ///5q1aqVWrdubZoWGxurO3fuJHuj7NRs3LhREydONP3t7u6ukiVLqlu3bipSpIhV68wpoqOjZWdnJxcXl2zZnqX28ueff2r8+PEKCgpS27ZtNX/+fC1cuFBNmzbV66+/blouLCxMgwcP1oQJE5Q/f36Fh4drwIABypMnj8aPH2/2HN5//33VqlVLQUFBydayZ88e/fLLL/ruu+9ka/t/v9+dPn1aISEhOnr0qG7fvq18+fKpfPnyeuGFF1SwYMEMvwa3b9+WYRjKlStXhteVkkOHDmnRokUKCwtTXFycvLy8VKZMGfXt21d2dnYZfl8kioyMVK5cueTg4GDaJ2PGjFGxYsUytN6H3/dBQUF677339Oyzz6ZrPV9//bWKFy9u8TMiu/zwww/atGmTJMnOzk5ubm7y8/NT/fr11ahRI7P2l1HpOV6mZ1lrPPi8kzN//vws2Tb+7/Xv2rWr2rVrZ5q+c+dOff311+l67bPjs+Lh9uLm5qaSJUuqe/fuKlq0aJZt90n2xAyNjoz75ptvdO/ePfXv318FChTQjRs3dPDgQcXExKhBgwbauHGjOnToIBsbG7PHbdy4UQ0aNJC9/f3m5OTkpBs3bujEiRMqU6aMabnQ0FDly5cvW58T0i5PnjwZeryjo6McHR0ztA4XFxeNGzdOhmHo2rVrmj17tr788kuNGzfO1L6yQnx8fJau383NLcvWnRbr16/XtGnT1Lt3bzVp0sQ03cHBQaGhoWrTpk2qAebOnTv6/fffUwxOlqxatSrJF9k9e/bom2++UZUqVfTmm2/Kx8dHN27c0I4dOzRv3jy9/fbb6XuCFri6umZ4Hak5e/asRo0apZYtW6pXr15ydHTUpUuX9Oeffyrxd8rMeF9IkoeHR4bX8aDENp/R932iRo0aacqUKWrfvn2mhpb0qlq1qvr166eEhARFRkZq3759mjFjhv766y8NHjxYdnZ2mbKd9LxumfUaJ6dXr17q1q2b6e/XX39d/fr1U9WqVS0un9XHu6eRg4ODli5dqqZNm2boeJ9dnxWJ7xPp/g81c+fO1ZdffqlJkyZly/afNLybIEm6deuWjh07puDgYFWoUEGS5O3trVKlSkmS8uXLp5UrV+ro0aOm+ZJ09OhRXbx4Ue+++65pmp2dnfz9/bVhwwZTmLp69aqOHDmi1q1ba9u2bdn4zJ4OR44c0axZs/Tff//Jzc1NAQEB6tKli+mLw507dzRlyhTt2rVLLi4ueuGFF7R7924VK1bMdArSw71N8+fPV2hoqG7cuKHcuXOrdu3aeuWVVxQcHKwrV65o5syZmjlzpmnZjRs3asaMGWanKOzevVsLFy7U2bNn5ezsrPLly+u9995L9nnY2NiYvjR6enqqdevWGjNmjC5cuCA/Pz9J0vHjxzVnzhydPHlSefLkUa1atdS1a1c5OztLkq5fv64ff/xRhw4dkoeHh1566SX99ttvZs8tKChIr776qvbt26eDBw/q+eefV1BQkHbv3q0FCxbo3Llz8vT0VEBAgDp06GB6HZN7TSRpzZo1WrFiha5evSpXV1eVK1fO9L4IDg42e62jo6M1Y8YM7dmzR3FxcapQoYJ69eolX19fSTK9lm+99ZZmzpypiIgIlStXTv369ZOnp2e62sbSpUs1f/58DRw4UHXq1DGbV7BgQbm7u2vu3Ll65513UlxPy5YttXz5crVo0SLNvSxRUVE6ePCgevbsaZp29+5dTZw4UdWqVdP7779vmp4/f36VLl1at27dMk1LrV3/+eefWrBggS5duiQnJycVL15c77//vpydnZP0zgUHB8vPz0+Ojo5av3697O3t1axZM7NwePv2bc2aNUu7du1SXFycSpQooZ49eybb+3PgwAF5eHioe/fupmk+Pj5mX2Iffl/Mnz9fu3btUsuWLbVgwQJFR0erYcOG6t27t37//XctX75chmGoVatW6tChg2k9KfUYJSQkaPLkyTp06JAiIyOVL18+tWjRQq1atTItk/h6lC5dWqtXr5a9vb1++OEHs/d9//79Jd3vZZLufwYMGzZMb775pr744guVLFnStL5Vq1bp999/1w8//CAbGxtVrVpV0dHROnLkiJ555hmLr1d2sLe3Nx1DvLy8VKJECZUpU0afffaZNm7caPoxIS37OqXjV1qPl5aWjYiI0PTp03Xw4EHZ2tqqSpUqeuWVV0x1J7aR559/XvPmzVN0dLSqVaumN954w2KPhaura5IfD1xdXU3rCw4OVpEiRWRvb6/NmzercOHCGj58uM6dO6dZs2bpyJEjcnZ2VuXKldWzZ09T+DMMQ8uWLdPatWt1/fp1FSxYUB07dkxyHIFUqVIlXb58WUuWLDE7Hjzo5s2bmjZtmo4dO6bo6GgVKFBA7du3l7+/v2mZBz8r5syZo8OHD2vkyJFm60k8DiQeu0JDQ7Vs2TKFh4fL29tbLVu2VIsWLVKs98H3iYeHh9q2bathw4YpKirKtP9nz56tXbt26erVq/Lw8JC/v786deoke3t7hYeHp+m4kFobS+kY/jghTEGS5OzsLGdnZ+3cuVOlS5dOcmM3Pz8/lSxZUqGhoWZhKjQ0VKVKlTJ90U3UuHFjDRs2TL169ZKTk5M2btyoKlWqZPhUFyR17do1jRo1SgEBARowYIDOnz+vyZMny8HBwXSwnTlzpo4fP67BgwfL3d1d8+fP1+nTp5P9kvjnn39qxYoVeuutt1SkSBFFRkaars9477339P7776tJkyZq2rRpsnXt3btXX3/9tTp06KABAwYoPj5ee/fuTfPzunXrluk6m8Qvz2fOnNHIkSP14osvqk+fPoqKitL06dM1ffp0069sEyZM0M2bNxUcHCw7Ozv98ssvunHjRpL1L1iwQC+99JJ69uwpW1tb7du3T+PHj1evXr1Uvnx5Xb58WZMnT5Ykde7cOcXX5N9//9XPP/+sAQMGqGzZsoqOjtbRo0eTfW4TJ07UxYsXNXjwYLm4uOjXX3/VqFGj9O2335p+Mb57965+//13DRgwQDY2Nho/frxmzZqlgQMHpvk1/PXXX7VmzRp98MEHqly5ssVlunbtqiFDhujkyZOmH08sqV+/vg4cOKCFCxeqd+/eadr+sWPH5OjoqEKFCpmm7d+/Xzdv3lTbtm0tPibxtLzU2vX169c1btw4devWTc8++6xiYmJSfM0ladOmTWrTpo2++OILnThxQhMnTlS5cuVUuXJlGYahUaNGyc3NTUOGDJGrq6vWrl2rzz//XOPGjbP4i7GHh4ciIyN15MgRs+Niai5fvqx9+/Zp6NChunTpkr799luFh4fL19dXw4cP1/HjxzVp0iQ988wzZr37yUlISFDevHn19ttvK0+ePDp+/Lh++ukneXh4qF69eqblDh06JFdXV3388ceydIb/qFGj9Oqrr5p6NWxtbZUnTx5VqlRJoaGhZl+aNm7cqEaNGpnOVLC3t1fRokV19OjRRxqmLHnmmWdUtGhR7dy5U02aNEnTvk7P8SulY8PDDMPQV199JScnJw0fPlz37t3T1KlTNXbsWAUHB5uWu3z5snbu3KkPPvhAt27d0nfffaclS5bopZdesuo12LRpk5o3b67PP/9chmHo+vXrGjZsmJo0aaIePXooNjZWv/76q7777jsNGzZMkjR37lzt3LlTr776qnx9fXX06FGNHz9eefLkSVd7fxrY2trqpZde0rhx49SyZUvlzZs3yTKJob1du3ZycXHR3r17NWHCBBUoUEClS5dOsry/v7+WLFmiS5cuycfHR9L93vAzZ86Yfvxat26dFixYoFdeeUXFixfX6dOnNXnyZDk5OalRo0Zpqj0mJkZbtmyRj4+P2XHOxcXF9APemTNnNHnyZLm4uKht27bKnz9/qseF1NqYNcfwnIowBUn3v6z269dPkydP1tq1a1WiRAmVL19e9evXN51DGxgYqFmzZql3795ydnZWTEyMduzYYfarc6JixYqpQIEC+vPPP9WwYUNt3LhRPXv21OXLl7P7qT3x1qxZo7x586p3796ysbFRoUKFdP36df3666/q1KmT7t69q02bNmnQoEGqVKmSJKlfv3564403kl1nRESEPDw8VKlSJdnb2ytfvnymL9pubm6ytbWVi4tLiqceLV68WPXq1TP75T+16ztu376t//3vf5LuhwlJqlmzpunL+LJly+Tv72/6hdfX11e9evXSsGHD9Oqrr+rKlSs6ePCgRo0aZTrA9+nTx2IAqV+/vho3bmz6e8KECWrXrp3pA6hAgQJ68cUX9euvv6pz584pviYRERFycnJSjRo15OLiIm9vbxUvXtzic7x48aJ2796tzz//XGXLlpUkDRw4UH379tWuXbtUt25dSdK9e/f02muvmT5En3vuOS1cuDDF1+9B+/bt0+7du/Xpp5+m+OW2RIkSqlu3rubMmaNPP/002eVsbGzUtWtXjR49Wq1btzbVlZIrV67Iw8PD7LSvixcvSlKqpxWm1q6vX7+ue/fuqXbt2vL29pakJD/qPKxo0aLq3LmzpPttZ/Xq1Tp48KAqV66sw4cP68yZM5o6darpx6QePXpo165d+vPPPy3+cFC3bl3t379fwcHB8vDwUOnSpVWpUiU1bNgwxdMMDcNQ37595eLiosKFC6tixYq6cOGChgwZIltbWxUsWFBLly7VkSNH0hSm7O3tzd5n+fPn1/Hjx7Vjxw6zMOXk5KQ+ffoke4pX4q/FD/ZqSPd/HJsyZYp69uwpBwcHhYWFKSwszOyMBOl+T9CVK1dSrfdRKFSokP777z9JStO+Ts/xK6Vjw8MOHjyo//77TxMmTDCd9v7mm2/qnXfeMftBwzAM9e/f39QT1bBhQx06dMjq5+/j42PWYzJv3jyVKFFCXbt2NU3r27ev+vbtqwsXLsjLy0vLly/XsGHDTG2wQIECOnbsmNauXUuYsuDZZ59VsWLFNH/+fPXt2zfJfC8vL73wwgumv1u2bKl9+/Zpx44dFsOUn5+fihYtqq1bt6pTp06SpC1btqhkyZKm4+eiRYv0v//9T7Vr15Z0/71/7tw5rVu3LsUwtXfvXrPPWk9PT33wwQdmx+oHr3/Mnz+/Lly4oO3bt5t+CEvtuPDHH3+k2MZiYmLSfQzPqQhTMKlTp46qV6+uY8eO6cSJE9q3b5+WLVumPn36qFGjRvL399cvv/yi7du3q3Hjxtq+fbskmX1YPygwMFAbN25Uvnz5FBMTo2rVqmn16tXZ+ZSeCufPn1eZMmXMrmUrW7asYmJidO3aNUVHR+vevXtmH+6urq4pfpmtU6eOVqxYoTfffFNVqlRR9erVVaNGjXRdbxAWFmZ2fU5auLi4aPTo0bp3756OHDmiZcuW6bXXXjPNP3XqlC5duqQtW7aYPc4wDIWHh+vixYuys7MzCzI+Pj4WByF48Ne0xHWfPHlSixcvNk1LSEhQXFyc7t69m+JrUrlyZXl7e2vAgAGqWrWqqlatqmeffdbiBefnz5+XnZ2d2Ydn7ty5VbBgQZ0/f940zcnJySyweHp6KioqKi0vo6T7wSEqKkrz5s1TyZIlU7yguUuXLnr77be1f//+FHuPq1atqnLlymnevHkaNGhQqjXExsYm6eVO65hHqbXrYsWKqVKlSnrvvfdUpUoVVa5cWXXq1EnxmoOHP6g9PT1NvZanTp1STEyM6dSsB5/DpUuXLK7P1tZW/fr1U5cuXXTo0CGdOHFCixcv1tKlS/XFF18ke0qmt7e32f5wd3eXra2t2RcZd3d3iz2qyfnjjz+0YcMGXblyRbGxsYqPj0/y5d/Pz8+qa2WeffZZTZ8+XTt37lT9+vUVGhqqihUrKn/+/GbLOTo6mn4EyWkMwzC1pbTs6/Qcv9JzvDx37pzy5s1rdv1w4cKFlStXLp0/f950nH64jXh4eKSrPTysRIkSZn+fOnVKhw4dMn2hftDly5d1+/ZtxcXF6fPPPzebFx8fn+wPRZC6deumzz77TM8//3ySeQkJCVqyZIm2b9+ua9euKS4uTvHx8SkOTOLv76/Q0FB16tRJhmFo27Ztph8To6KidPXqVf3444+msygSt5PaNaMVK1Y0fbZGR0drzZo1GjVqlL744gtTsEnscb106ZJiYmKUkJBg1iZTOy6k1saqVKmS7mN4TkWYghlHR0dVrlxZlStXVqdOnfTjjz9q/vz5atSokVxdXVWnTh2FhoaqcePGCg0NVe3atZN90zZo0ECzZ8/WggULFBAQkGkX/sKctQNypvS4fPnyady4cTpw4IAOHDigqVOnatmyZQoODk7zlzFrLrq3sbExBYhChQopMjJSY8eO1fDhw001N23a1OxakAdrvnDhQpq39fAHWEJCgoKCgky/8D3IwcEhxdckMQQePnxYBw4c0Pz587VgwQKNGjUqSZBL7nV/eLql90t69rWnp6feffddDR8+XF988YU++uijZAOVj4+PmjRpojlz5qhPnz4prrdbt24aOnSo2S+sycmdO7fZNVDS//VIXbhwIcVel9Seq62trT7++GMdP35cBw4c0OrVqzV37lx98cUXSb7kJ7LUdhO3k5CQIE9PT7NTrRKl9sXEy8tLDRs2VMOGDdWlSxcNGjRIa9euTXawjof3rY2NjcVpad3f27dv18yZM9WjRw+VKVNGLi4uWrZsmf755x+z5awdTc7e3t50hkHt2rW1detWi8O9J14HkhOdP3/e1C7Ssq/Tc/xK7/Hy4UGcJPOwJ1luIxkZfPnha1AMw1CNGjUsXt/j4eGhs2fPSpKGDBkiLy8vs/kMXpG8ChUqqEqVKpozZ06SnqHff/9dK1asUM+ePeXn5ydnZ2fNmDFD8fHxya7P399fc+bM0alTpxQbG6urV6+afsBOSEiQJL3xxhtJerZSGwTm4R/rEq8ZXL9+vbp06aITJ05o7NixCgoKUpUqVeTq6qpt27Zp+fLlpsekdlxIrY1ZcwzPqbjPFFJUuHBhs18aGzdurOPHj2vPnj06fvy42WlSD3Nzc1PNmjV15MgRBQYGZke5T6XChQvrxIkTZh+0x48fl4uLi7y8vFSgQAHZ2dnp5MmTpvm3b982nW6VHEdHR9WsWdM06MSJEyd05swZSfcPookH8uQULVpUBw8ezMAzk1q3bq2wsDDT/XWKFy+uc+fOycfHJ8l/9vb2KlSokO7du2d2vcKlS5eSfKG3pESJErpw4YLFdSd+MKX0miT2UHXv3l1fffWVrly5YvG0nMKFC+vevXtmX3Rv3rypixcvqnDhwhl5uZLIly+fgoODdePGDY0YMUK3b99OdtlOnTrpwoULqQ4QU6pUKdWuXVtz5sxJdfvFixdXZGSkoqOjTdMqV66s3Llza+nSpRYfk7ivUmvX0v0vmOXKlVNQUJDGjBkje3t7U1tJrxIlSigyMlK2trZJ9n96RmNzc3OTp6dntt5z6dixYypbtqxatGih4sWLy8fHx+pTqu3s7Cy+txs3bqwDBw5ozZo1plNzHnb27Nkc2Wtx6NAhnTlzxlRzWvZ1eo9fKR0bHlS4cGFFREQoIiLCNO3cuXO6ffu22bWFWS3xWOrt7Z3kNXB2dlbhwoXl4OCgiIiIJPMZlTdl3bp10549e3TixAmz6UePHlXNmjXVsGFDFStWTPnz50/1czhv3rwqX768tm7dqq1bt6pSpUpmA0d4eXnp8uXLSfaRNWHE1tZWsbGxku4fa729vdWhQweVLFlSvr6+Zm02UUrHhdTamJS5x/BHiTAFSfe/zA0fPlybN2/Wf//9p/DwcO3YsUNLly5VzZo1TctVqFBBPj4+mjBhgnx8fFI9b7p///6aNm1atn5IPKnu3LljOic58b+IiAi1aNFCV69e1fTp03X+/Hnt2rVL8+fPV+vWrU3XNgUEBGj27Nk6dOiQzp49q0mTJqX4y9XGjRu1YcMGnTlzRpcvX9bmzZvl6Oho6v739vbW0aNHde3atWRPPevUqZO2bdum+fPn69y5czpz5kyyX6CT4+rqqiZNmmj+/PkyDENt27bViRMnNHXqVIWFhZmuP5o+fbqk+71ZlSpV0uTJk3Xy5EnTxbiOjo4Wfw1+UMeOHbV582bNnz9fZ8+e1blz57R9+3bNnTs31ddkz549WrlypcLCwnTlyhVt3rxZCQkJFk+l9PX1Vc2aNTV58mQdO3ZMYWFhGj9+vLy8vMzea5klb968Cg4OVnR0tEaOHJlsoPLw8FCbNm20atWqVNeZeFpbaj2BxYsXNw2IkMjZ2Vl9+vTR3r17NXr0aB04cEDh4eH6999/NXv2bE2ZMkWSUm3X//zzjxYvXqx///1XERER+uuvvxQVFWX1saZSpUoqU6aMvvrqK+3bt0/h4eE6fvy45s6dq3///dfiY9auXaspU6Zo//79unTpks6ePavZs2fr7NmzWbIvk+Pj46N///1X+/bt04ULFzR37lyzH0/SI3/+/KZRAR8MwYULF1aZMmX066+/qn79+kl6bsLDw3Xt2jXTdZmPSnx8vCIjI3Xt2jWdOnVKixcv1pgxY1S9enUFBARIStu+Ts/xK7Xj5YMqVaqkokWLavz48aZTiydMmKAKFSokOfU4K7Vo0ULR0dEaN26cTp48qcuXL2v//v2aOHGi6XSu559/XjNnztTGjRt16dIlnT59WqtXr9bGjRuzrc7HkZ+fnxo0aJDkWOrj46MDBw7o+PHjOnfunH766SdFRkamuj5/f39t27ZNO3bsUIMGDczmde7cWUuWLNHKlSt14cIFnTlzRqGhoWY9SJYkvk8iIyN17tw5TZ8+XTExMapRo4ap1oiICG3btk2XLl3SypUrLYaclI4LqbWxzD6GP0r01ULS/S84pUuX1ooVK3T58mXdu3dPefPmVZMmTcyG55XuXwv122+/pek0n8y6xwruXzT98E17AwIC1L9/fw0ZMkSzZs3S+++/Lzc3NzVu3Njs4tGePXtqypQpGj16tGlo9KtXrya7b1xdXbV06VLNnDlTCQkJ8vPz0wcffKDcuXNLuj9M85QpU/Tmm28qLi7O4k0JK1asqHfeeUeLFi3SkiVL5OLiovLly6f7ebdq1UqrVq0yXUwfHBysuXPn6tNPP5VhGPLx8TEN2iBJAwYM0I8//qhhw4aZhkY/d+5ckmt3Hla1alV98MEHWrRokZYtWyY7OzsVKlTI1Pua0muSK1cu7dy5UwsWLFBcXJx8fX01aNCgZG823K9fP82YMUNffvml4uPjVb58eQ0ZMiTLTp/x8vJScHCwhg8frs8//1wff/yxxeVeeOEF/fHHH4qLi0txfQULFlRgYKDWrVuX4nK2trYKDAzUli1bTB/SklSrVi2NGDFCISEh+v7773Xnzh3lzZtXzzzzjLp06WKqOaV27eLioqNHj2rlypW6c+eO8uXLpx49eqhatWrpeWlMbGxsNGTIEP3222+aNGmSoqKi5OHhofLlyyd7HVmpUqV07NgxTZkyRdevXzf9ov/+++9n6wX6zZo1U1hYmMaOHSsbGxvVr19fLVq00N9//53udf3vf//TL7/8ovXr18vLy8vsBuuBgYE6fvy4xTMNtm3bZrp28FHat2+fXn/9ddnZ2SlXrlwqWrSoevXqpYCAANMPSGnZ1+k5fqV2vHyQjY2N3n//fU2fPl3Dhg0zGxo9O3l5eenzzz/Xr7/+qpEjRyouLk7e3t6qUqWK6YenF198UXny5NGSJUt0+fJl5cqVS8WLF1f79u2ztdbH0YsvvqgdO3aYTevUqZPCw8M1cuRIOTk5qUmTJqpVq1aKZwxI9we6+fnnn2Vra5vk1ghNmjSRk5OTli1bptmzZ8vJyUl+fn6m66qSk/g+ke4fSwsWLKi3335bFStWlHT/GN26dWtNnz5dcXFxql69ujp27KgFCxYkWVdyx4XU2lhmH8MfJRsjIyfhAngsxcTEqE+fPurRo0eKp2o+Ca5evaq+ffvqk08+eeS/mj+NIiMj9e677+rLL7985F+0kTGLFy/Wtm3b9M0335hNj4uL08CBAzVo0CCVK1fuEVUH4FFI7rjwNKFnCngKnD592jRS1O3bt01DbGfnqUjZ5dChQ4qJiZGfn5+uX7+u2bNny9vb26peMWSch4eH+vTpo4iICMLUYyomJkbnzp3TqlWr9OKLLyaZf+XKFXXo0IEgBTxFUjsuPE0IU8BT4vfff9eFCxdkb2+vEiVK6LPPPkvXhfWPi/j4eP3222+6fPmyXFxcVKZMGQ0cOJARqB6hWrVqPeoSkAHTpk3Ttm3bVKtWLYs92QULFkz1vmEAniypHReeJpzmBwAAAABWYDQ/AAAAALACYQoAAAAArECYAgAAAAArEKYAAAAAwAqEKQAAAACwAmMFAwCyzMaNGzVx4kRJ0rBhw1SxYkWz+YZhaODAgbp8+bIqVKig4ODgTNt2UFCQOnXqpKCgoHQ9Ljw8XAMGDFC/fv3UqFEji8sEBwfryJEjqa7Lmu0DAB4fhCkAQJZzcXHRhg0bkoSpI0eOmO4J9jh59dVXdfv2bdPfe/fu1eLFi9WvXz+zey7lzZv3UZQHAMgmhCkAQJarW7eutm7dqt69e8vV1dU0fcOGDSpTpozu3LnzCKtLv8KFC5v9feHCBUlSkSJFVLJkyUdREgDgESBMAQCynL+/v7Zu3apt27apWbNmkqTbt2/rr7/+Uq9evbRy5cokj4mOjtbcuXO1a9cuRUVFKW/evKpfv746deokBwcH03K3b9/WL7/8op07dyouLk7lypVTr169LNZx8eJFzZ8/XwcPHtTt27dVoEABtWjRQs8991ymPt/NmzdrwoQJGjFihMqUKWM2b+HChVq0aJF++OEHeXl5KTg4WDdv3tSrr76q2bNnKywsTG5ubgoMDFRQUJBsbf/v8ub4+HgtXbpUW7ZsUXh4uFxcXFSjRg11795defLkydTnAABIHWEKAJDlXFxcVKdOHYWGhprC1NatW2VjY6N69eolCVOxsbEaPny4Ll26pKCgIBUtWlRHjx7VkiVLFBYWpiFDhki6f83VV199pRMnTqhjx44qVaqUjh07plGjRiWp4dy5c/r444+VL18+9ejRQx4eHtq3b59+/vln3bx5U507d86051uvXj3Nnj1bq1evNgtT9+7d09q1a1WrVi15eXmZpkdGRmrs2LFq166dgoKCTKcN3rp1S71795YkJSQkaMyYMTp69Kjatm2rMmXKKCIiQvPnz1dwcLC+/PJLOTo6ZtpzAACkjjAFAMgWgYGBGj58uM6ePasiRYooNDRUdevWtXi91KZNm/Tff//p7bffVt26dSVJlStXlrOzs3799VcdOHBAlStX1v79+3X48GG9/PLLatWqlWk5e3t7zZ0712ydM2fOlIuLiz777DPTqYaVK1dWfHy8lixZopYtW8rNzS1Tnqu9vb2aNm2qJUuWqGfPnnJ3d5ck/fXXX7p+/XqSnrCbN29q8ODBqlmzpiSpSpUqio2N1R9//KG2bdsqX7582rFjh/bt26d3331XtWvXNj22aNGiGjJkiDZu3KjmzZtnSv0AgLRhaHQAQLaoUKGCChQooNDQUJ05c0b//vuvAgMDLS576NAhOTk5qU6dOmbTE0fXO3jwoGk5SWrQoIHZcv7+/mZ/x8bG6tChQ6pVq5acnJx0794903/VqlVTXFyc/vnnn8x4miaJwWb9+vWmaWvWrJGfn58qVKhgtqyLi4spSD34HAzDMI0auGfPHuXKlUs1atQwq79YsWLy8PDQ4cOHM7V+AEDq6JkCAGQLGxsbBQYGatWqVYqNjZWvr6/Kly9vcdno6Gh5eHjIxsbGbLq7u7vs7Ox08+ZN03J2dnbKnTu32XIeHh5J1nfv3j2tXr1aq1evtrjNxHVmFg8PD9WrV09r165Vu3btdPbsWR09elSvv/56kmUTe64efnxi7ZJ048YN3bp1S127drW4vcyuHwCQOsIUACDbNGrUSPPmzdPatWv10ksvJbucm5ub/vnnHxmGYRaobty4oXv37pkGW3Bzc9O9e/d08+ZNs0AVGRlptr5cuXLJ1tZWDRs2VIsWLSxuM3/+/Bl4Zpa1atVKmzdv1q5du7Rv3z7lypUrSa+ZdP95PSzxOSSeepg7d27lzp1bH330kcVtPW7DywPAk4AwBQDINl5eXnrhhRd0/vx5BQQEJLtcpUqVtGPHDu3atUvPPvusafqmTZskSc8884zp/8uWLdOWLVtM10xJ9we3eJCTk5MqVqyo06dPq2jRorK3z56PvxIlSqhs2bJaunSpzp49qyZNmsjZ2TnJcnfu3NHu3bvNTvVLHKAj8ZTAGjVqaPv27UpISFDp0qWzpX4AQMoIUwCAbNWtW7dUl2nYsKHWrFmjH374QeHh4fLz89OxY8cUEhKiatWqqXLlypLuDyBRvnx5/frrr7p7965KliypY8eOacuWLUnW2atXL33yySf69NNP1bx5c3l7e+vOnTu6dOmS9uzZo2HDhmX6c5Wkli1bauzYsbKxsUm2Vyx37tyaMmWKIiIi5Ovrq7///lvr169X8+bNlS9fPklS/fr1tXXrVo0aNUqtWrVSqVKlZGdnp6tXr+rw4cOqVauWWfAEAGQ9whQAIMdxdHTUsGHD9Ntvv+n3339XVFSUvLy89Pzzz5sNYW5ra6sPPvhAM2fO1LJlyxQfH6+yZctqyJAheuutt8zWWbhwYY0ePVqLFi3S3LlzdePGDeXKlUu+vr6qVq1alj2XZ599Vg4ODqpYsaJ8fX0tLuPh4aHevXtr1qxZOnPmjNzc3NS+fXsFBQWZPdfBgwdr5cqV2rx5s0JCQmRnZ6e8efOqfPny8vPzy7LnAACwzMYwDONRFwEAwJNq9+7dGjNmjD788ENVr149yfzEm/Z+8803j6A6AEBG0DMFAEAWOHfunK5cuaJZs2apWLFiWdr7BQB4NAhTAABkgalTp+r48eMqXry4+vfvn2SYdwDA44/T/AAAAADACraPugAAAAAAeBwRpgAAAADACoQpAAAAALACYQoAAAAArECYAgAAAAArEKYAAAAAwAqEKQAAAACwAmEKAAAAAKzw/wAQYf/moeUG4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the chart\n",
    "plt.figure(figsize=(10,5))\n",
    "# Create a bar plot from the validation accuracies in the results data frame\n",
    "mod_perf_fig = sns.barplot(\n",
    "    x='Model',\n",
    "    y='Validation Accuracy',\n",
    "    data=results_df.sort_values('Validation Accuracy', ascending=False),\n",
    "    color='dodgerblue'\n",
    ")\n",
    "# Add a title and labels\n",
    "plt.title('Logistic Regression Has Best Performance of Initial Models')\n",
    "plt.xlabel('Model Type')\n",
    "plt.ylabel('Validation Accuracy %')\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff6214c",
   "metadata": {},
   "source": [
    "As demonstrated by the results table and chart, of the four models with no hyper-parameter optimization, the SVM model performs best with a validation accuracy of 96%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a81757fc-4443-43a5-b9a9-c672ea3c2979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the chart\n",
    "mod_perf_fig.figure.savefig('model_perf', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27e3ef0-c5ab-4278-931f-e9767271eec9",
   "metadata": {},
   "source": [
    "### TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abfe159",
   "metadata": {},
   "source": [
    "The previous models had been trained and evaluated on data transformed by a count vectorizer. Since the count vectorizer does not take term frequency into account, it is possible that some words may be weighted too heavily especially if they are repeated multiple times in a single document. As such, the data will be transformed using a TFIDF vectorizer and the same simple models trained and evaluated using the data vectorized by the TFIDF vectorizer. In order to do this, the text content will need to be transformed using this TFIDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "3afb7a13-941d-4122-b833-34409eec94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate column transformer with TFIDF vectorizer\n",
    "tfidf_transf = ColumnTransformer([\n",
    "        (\n",
    "            # Name the transformation\n",
    "            'tfidf_vectorizer',\n",
    "            # Instantate the TFIDF vectorizer with the custom tokenizer and a minimum term frequency of 5%\n",
    "            TfidfVectorizer(\n",
    "                tokenizer=custom_tokenizer,\n",
    "                min_df=0.05\n",
    "            ),\n",
    "            # Select the column to be transformed\n",
    "            'content',\n",
    "        )\n",
    "    ],\n",
    "    # Specify that all other columns should remain unchanged\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "4489f040-6043-43a4-85ad-181c074ae3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the x training data with the TFIDF vectorizer\n",
    "X_train_tfidf = tfidf_transf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "b0bf4475-ffdc-439e-b801-fb761259436e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_vectorizer__abl</th>\n",
       "      <th>count_vectorizer__accept</th>\n",
       "      <th>count_vectorizer__access</th>\n",
       "      <th>count_vectorizer__accord</th>\n",
       "      <th>count_vectorizer__account</th>\n",
       "      <th>count_vectorizer__actual</th>\n",
       "      <th>count_vectorizer__address</th>\n",
       "      <th>count_vectorizer__agre</th>\n",
       "      <th>count_vectorizer__agreement</th>\n",
       "      <th>count_vectorizer__along</th>\n",
       "      <th>count_vectorizer__also</th>\n",
       "      <th>count_vectorizer__amount</th>\n",
       "      <th>count_vectorizer__anoth</th>\n",
       "      <th>count_vectorizer__arrang</th>\n",
       "      <th>count_vectorizer__ask</th>\n",
       "      <th>count_vectorizer__assist</th>\n",
       "      <th>count_vectorizer__assur</th>\n",
       "      <th>count_vectorizer__attent</th>\n",
       "      <th>count_vectorizer__back</th>\n",
       "      <th>count_vectorizer__bank</th>\n",
       "      <th>count_vectorizer__base</th>\n",
       "      <th>count_vectorizer__behalf</th>\n",
       "      <th>count_vectorizer__believ</th>\n",
       "      <th>count_vectorizer__beneficiari</th>\n",
       "      <th>count_vectorizer__best</th>\n",
       "      <th>count_vectorizer__bless</th>\n",
       "      <th>count_vectorizer__busi</th>\n",
       "      <th>count_vectorizer__call</th>\n",
       "      <th>count_vectorizer__care</th>\n",
       "      <th>count_vectorizer__case</th>\n",
       "      <th>count_vectorizer__chang</th>\n",
       "      <th>count_vectorizer__choos</th>\n",
       "      <th>count_vectorizer__claim</th>\n",
       "      <th>count_vectorizer__click</th>\n",
       "      <th>count_vectorizer__client</th>\n",
       "      <th>count_vectorizer__close</th>\n",
       "      <th>count_vectorizer__come</th>\n",
       "      <th>count_vectorizer__commun</th>\n",
       "      <th>count_vectorizer__compani</th>\n",
       "      <th>count_vectorizer__complet</th>\n",
       "      <th>count_vectorizer__concern</th>\n",
       "      <th>count_vectorizer__confid</th>\n",
       "      <th>count_vectorizer__confidenti</th>\n",
       "      <th>count_vectorizer__confirm</th>\n",
       "      <th>count_vectorizer__contact</th>\n",
       "      <th>count_vectorizer__corpor</th>\n",
       "      <th>count_vectorizer__could</th>\n",
       "      <th>count_vectorizer__countri</th>\n",
       "      <th>count_vectorizer__cours</th>\n",
       "      <th>count_vectorizer__current</th>\n",
       "      <th>count_vectorizer__custom</th>\n",
       "      <th>count_vectorizer__day</th>\n",
       "      <th>count_vectorizer__deal</th>\n",
       "      <th>count_vectorizer__dear</th>\n",
       "      <th>count_vectorizer__death</th>\n",
       "      <th>count_vectorizer__deceas</th>\n",
       "      <th>count_vectorizer__decid</th>\n",
       "      <th>count_vectorizer__depart</th>\n",
       "      <th>count_vectorizer__deposit</th>\n",
       "      <th>count_vectorizer__develop</th>\n",
       "      <th>count_vectorizer__direct</th>\n",
       "      <th>count_vectorizer__discov</th>\n",
       "      <th>count_vectorizer__discuss</th>\n",
       "      <th>count_vectorizer__done</th>\n",
       "      <th>count_vectorizer__due</th>\n",
       "      <th>count_vectorizer__easi</th>\n",
       "      <th>count_vectorizer__enabl</th>\n",
       "      <th>count_vectorizer__end</th>\n",
       "      <th>count_vectorizer__even</th>\n",
       "      <th>count_vectorizer__everi</th>\n",
       "      <th>count_vectorizer__execut</th>\n",
       "      <th>count_vectorizer__fact</th>\n",
       "      <th>count_vectorizer__faith</th>\n",
       "      <th>count_vectorizer__famili</th>\n",
       "      <th>count_vectorizer__father</th>\n",
       "      <th>count_vectorizer__file</th>\n",
       "      <th>count_vectorizer__final</th>\n",
       "      <th>count_vectorizer__financi</th>\n",
       "      <th>count_vectorizer__find</th>\n",
       "      <th>count_vectorizer__first</th>\n",
       "      <th>count_vectorizer__five</th>\n",
       "      <th>count_vectorizer__follow</th>\n",
       "      <th>count_vectorizer__foreign</th>\n",
       "      <th>count_vectorizer__form</th>\n",
       "      <th>count_vectorizer__former</th>\n",
       "      <th>count_vectorizer__forward</th>\n",
       "      <th>count_vectorizer__free</th>\n",
       "      <th>count_vectorizer__friend</th>\n",
       "      <th>count_vectorizer__full</th>\n",
       "      <th>count_vectorizer__fund</th>\n",
       "      <th>count_vectorizer__futur</th>\n",
       "      <th>count_vectorizer__gener</th>\n",
       "      <th>count_vectorizer__get</th>\n",
       "      <th>count_vectorizer__give</th>\n",
       "      <th>count_vectorizer__given</th>\n",
       "      <th>count_vectorizer__go</th>\n",
       "      <th>count_vectorizer__god</th>\n",
       "      <th>count_vectorizer__good</th>\n",
       "      <th>count_vectorizer__got</th>\n",
       "      <th>count_vectorizer__govern</th>\n",
       "      <th>count_vectorizer__great</th>\n",
       "      <th>count_vectorizer__group</th>\n",
       "      <th>count_vectorizer__hear</th>\n",
       "      <th>count_vectorizer__help</th>\n",
       "      <th>count_vectorizer__henc</th>\n",
       "      <th>count_vectorizer__home</th>\n",
       "      <th>count_vectorizer__hope</th>\n",
       "      <th>count_vectorizer__hous</th>\n",
       "      <th>count_vectorizer__howev</th>\n",
       "      <th>count_vectorizer__hundr</th>\n",
       "      <th>count_vectorizer__id</th>\n",
       "      <th>count_vectorizer__immedi</th>\n",
       "      <th>count_vectorizer__import</th>\n",
       "      <th>count_vectorizer__includ</th>\n",
       "      <th>count_vectorizer__inform</th>\n",
       "      <th>count_vectorizer__interest</th>\n",
       "      <th>count_vectorizer__intern</th>\n",
       "      <th>count_vectorizer__invest</th>\n",
       "      <th>count_vectorizer__involv</th>\n",
       "      <th>count_vectorizer__issu</th>\n",
       "      <th>count_vectorizer__keep</th>\n",
       "      <th>count_vectorizer__kin</th>\n",
       "      <th>count_vectorizer__know</th>\n",
       "      <th>count_vectorizer__last</th>\n",
       "      <th>count_vectorizer__late</th>\n",
       "      <th>count_vectorizer__law</th>\n",
       "      <th>count_vectorizer__leav</th>\n",
       "      <th>count_vectorizer__left</th>\n",
       "      <th>count_vectorizer__legal</th>\n",
       "      <th>count_vectorizer__let</th>\n",
       "      <th>count_vectorizer__letter</th>\n",
       "      <th>count_vectorizer__life</th>\n",
       "      <th>count_vectorizer__like</th>\n",
       "      <th>count_vectorizer__link</th>\n",
       "      <th>count_vectorizer__list</th>\n",
       "      <th>count_vectorizer__live</th>\n",
       "      <th>count_vectorizer__long</th>\n",
       "      <th>count_vectorizer__look</th>\n",
       "      <th>count_vectorizer__made</th>\n",
       "      <th>count_vectorizer__mail</th>\n",
       "      <th>count_vectorizer__mailman</th>\n",
       "      <th>count_vectorizer__make</th>\n",
       "      <th>count_vectorizer__manag</th>\n",
       "      <th>count_vectorizer__mani</th>\n",
       "      <th>count_vectorizer__matter</th>\n",
       "      <th>count_vectorizer__may</th>\n",
       "      <th>count_vectorizer__meet</th>\n",
       "      <th>count_vectorizer__member</th>\n",
       "      <th>count_vectorizer__messag</th>\n",
       "      <th>count_vectorizer__might</th>\n",
       "      <th>count_vectorizer__million</th>\n",
       "      <th>count_vectorizer__money</th>\n",
       "      <th>count_vectorizer__move</th>\n",
       "      <th>count_vectorizer__much</th>\n",
       "      <th>count_vectorizer__must</th>\n",
       "      <th>count_vectorizer__name</th>\n",
       "      <th>count_vectorizer__nation</th>\n",
       "      <th>count_vectorizer__necessari</th>\n",
       "      <th>count_vectorizer__need</th>\n",
       "      <th>count_vectorizer__net</th>\n",
       "      <th>count_vectorizer__never</th>\n",
       "      <th>count_vectorizer__new</th>\n",
       "      <th>count_vectorizer__next</th>\n",
       "      <th>count_vectorizer__note</th>\n",
       "      <th>count_vectorizer__number</th>\n",
       "      <th>count_vectorizer__offer</th>\n",
       "      <th>count_vectorizer__offic</th>\n",
       "      <th>count_vectorizer__offici</th>\n",
       "      <th>count_vectorizer__old</th>\n",
       "      <th>count_vectorizer__one</th>\n",
       "      <th>count_vectorizer__open</th>\n",
       "      <th>count_vectorizer__oper</th>\n",
       "      <th>count_vectorizer__order</th>\n",
       "      <th>count_vectorizer__part</th>\n",
       "      <th>count_vectorizer__partner</th>\n",
       "      <th>count_vectorizer__peopl</th>\n",
       "      <th>count_vectorizer__person</th>\n",
       "      <th>count_vectorizer__phone</th>\n",
       "      <th>count_vectorizer__place</th>\n",
       "      <th>count_vectorizer__pleas</th>\n",
       "      <th>count_vectorizer__polici</th>\n",
       "      <th>count_vectorizer__polit</th>\n",
       "      <th>count_vectorizer__posit</th>\n",
       "      <th>count_vectorizer__possibl</th>\n",
       "      <th>count_vectorizer__present</th>\n",
       "      <th>count_vectorizer__presid</th>\n",
       "      <th>count_vectorizer__privat</th>\n",
       "      <th>count_vectorizer__problem</th>\n",
       "      <th>count_vectorizer__process</th>\n",
       "      <th>count_vectorizer__propos</th>\n",
       "      <th>count_vectorizer__protect</th>\n",
       "      <th>count_vectorizer__provid</th>\n",
       "      <th>count_vectorizer__put</th>\n",
       "      <th>count_vectorizer__read</th>\n",
       "      <th>count_vectorizer__real</th>\n",
       "      <th>count_vectorizer__reason</th>\n",
       "      <th>count_vectorizer__receiv</th>\n",
       "      <th>count_vectorizer__recent</th>\n",
       "      <th>count_vectorizer__releas</th>\n",
       "      <th>count_vectorizer__reliabl</th>\n",
       "      <th>count_vectorizer__repli</th>\n",
       "      <th>count_vectorizer__request</th>\n",
       "      <th>count_vectorizer__reserv</th>\n",
       "      <th>count_vectorizer__respect</th>\n",
       "      <th>count_vectorizer__respons</th>\n",
       "      <th>count_vectorizer__result</th>\n",
       "      <th>count_vectorizer__right</th>\n",
       "      <th>count_vectorizer__risk</th>\n",
       "      <th>count_vectorizer__run</th>\n",
       "      <th>count_vectorizer__safe</th>\n",
       "      <th>count_vectorizer__said</th>\n",
       "      <th>count_vectorizer__say</th>\n",
       "      <th>count_vectorizer__search</th>\n",
       "      <th>count_vectorizer__secur</th>\n",
       "      <th>count_vectorizer__see</th>\n",
       "      <th>count_vectorizer__seek</th>\n",
       "      <th>count_vectorizer__send</th>\n",
       "      <th>count_vectorizer__sent</th>\n",
       "      <th>count_vectorizer__servic</th>\n",
       "      <th>count_vectorizer__set</th>\n",
       "      <th>count_vectorizer__shall</th>\n",
       "      <th>count_vectorizer__share</th>\n",
       "      <th>count_vectorizer__sinc</th>\n",
       "      <th>count_vectorizer__sincer</th>\n",
       "      <th>count_vectorizer__sir</th>\n",
       "      <th>count_vectorizer__site</th>\n",
       "      <th>count_vectorizer__son</th>\n",
       "      <th>count_vectorizer__soon</th>\n",
       "      <th>count_vectorizer__stand</th>\n",
       "      <th>count_vectorizer__start</th>\n",
       "      <th>count_vectorizer__state</th>\n",
       "      <th>count_vectorizer__still</th>\n",
       "      <th>count_vectorizer__success</th>\n",
       "      <th>count_vectorizer__sum</th>\n",
       "      <th>count_vectorizer__support</th>\n",
       "      <th>count_vectorizer__sure</th>\n",
       "      <th>count_vectorizer__system</th>\n",
       "      <th>count_vectorizer__take</th>\n",
       "      <th>count_vectorizer__telephon</th>\n",
       "      <th>count_vectorizer__th</th>\n",
       "      <th>count_vectorizer__thank</th>\n",
       "      <th>count_vectorizer__therefor</th>\n",
       "      <th>count_vectorizer__think</th>\n",
       "      <th>count_vectorizer__though</th>\n",
       "      <th>count_vectorizer__thousand</th>\n",
       "      <th>count_vectorizer__time</th>\n",
       "      <th>count_vectorizer__today</th>\n",
       "      <th>count_vectorizer__told</th>\n",
       "      <th>count_vectorizer__top</th>\n",
       "      <th>count_vectorizer__total</th>\n",
       "      <th>count_vectorizer__transact</th>\n",
       "      <th>count_vectorizer__transfer</th>\n",
       "      <th>count_vectorizer__tri</th>\n",
       "      <th>count_vectorizer__trust</th>\n",
       "      <th>count_vectorizer__two</th>\n",
       "      <th>count_vectorizer__understand</th>\n",
       "      <th>count_vectorizer__unit</th>\n",
       "      <th>count_vectorizer__updat</th>\n",
       "      <th>count_vectorizer__upon</th>\n",
       "      <th>count_vectorizer__urgent</th>\n",
       "      <th>count_vectorizer__us</th>\n",
       "      <th>count_vectorizer__use</th>\n",
       "      <th>count_vectorizer__user</th>\n",
       "      <th>count_vectorizer__valu</th>\n",
       "      <th>count_vectorizer__via</th>\n",
       "      <th>count_vectorizer__visit</th>\n",
       "      <th>count_vectorizer__want</th>\n",
       "      <th>count_vectorizer__way</th>\n",
       "      <th>count_vectorizer__well</th>\n",
       "      <th>count_vectorizer__wish</th>\n",
       "      <th>count_vectorizer__within</th>\n",
       "      <th>count_vectorizer__without</th>\n",
       "      <th>count_vectorizer__work</th>\n",
       "      <th>count_vectorizer__world</th>\n",
       "      <th>count_vectorizer__would</th>\n",
       "      <th>count_vectorizer__write</th>\n",
       "      <th>count_vectorizer__wrote</th>\n",
       "      <th>count_vectorizer__yahoo</th>\n",
       "      <th>count_vectorizer__year</th>\n",
       "      <th>remainder__unsecure_link_count</th>\n",
       "      <th>remainder__secure_link_count</th>\n",
       "      <th>remainder__numbers_count</th>\n",
       "      <th>remainder__word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.338175</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.442286</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329279</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.415945</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.353386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.449216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.146328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.172443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198513</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160313</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.195154</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186998</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.750291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132206</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068017</td>\n",
       "      <td>0.065498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062228</td>\n",
       "      <td>0.080480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090342</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.203602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.141116</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067102</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.137728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097831</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094191</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.141289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162574</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.202936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.158721</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106992</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.083583</td>\n",
       "      <td>0.105271</td>\n",
       "      <td>0.128356</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.190408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183753</td>\n",
       "      <td>0.060398</td>\n",
       "      <td>0.130221</td>\n",
       "      <td>0.100668</td>\n",
       "      <td>0.061986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054071</td>\n",
       "      <td>0.093206</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095084</td>\n",
       "      <td>0.058671</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094682</td>\n",
       "      <td>0.065143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138044</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049175</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093913</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066061</td>\n",
       "      <td>0.053069</td>\n",
       "      <td>0.051619</td>\n",
       "      <td>0.062337</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.27951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.061510</td>\n",
       "      <td>0.063494</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077742</td>\n",
       "      <td>0.067867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062228</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109794</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065433</td>\n",
       "      <td>0.119781</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.167290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.123864</td>\n",
       "      <td>0.068244</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.062419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.045829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052135</td>\n",
       "      <td>0.057384</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.053951</td>\n",
       "      <td>0.066505</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.047142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.112679</td>\n",
       "      <td>0.196439</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116593</td>\n",
       "      <td>0.059374</td>\n",
       "      <td>0.129967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.04771</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.139838</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.143819</td>\n",
       "      <td>0.056834</td>\n",
       "      <td>0.05726</td>\n",
       "      <td>0.068590</td>\n",
       "      <td>0.065465</td>\n",
       "      <td>0.058604</td>\n",
       "      <td>0.089233</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>680.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.401157</td>\n",
       "      <td>0.101332</td>\n",
       "      <td>0.655260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.230924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110575</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072752</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.113182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.081269</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.079843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078665</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.136105</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111881</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151775</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077089</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126595</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.10046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.082815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083716</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.093443</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076765</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.109267</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.115322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.541824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.584018</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.604442</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.073021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448617</td>\n",
       "      <td>0.079052</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.240962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.173197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075211</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057631</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.236568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218304</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075049</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063117</td>\n",
       "      <td>0.062359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196481</td>\n",
       "      <td>0.075663</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.186189</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.070625</td>\n",
       "      <td>0.067036</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.078374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125447</td>\n",
       "      <td>0.060281</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097548</td>\n",
       "      <td>0.048529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067861</td>\n",
       "      <td>0.164469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052350</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069497</td>\n",
       "      <td>0.060435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137149</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.075913</td>\n",
       "      <td>0.043336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.069376</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.064968</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124336</td>\n",
       "      <td>0.075998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.073094</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.057315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056162</td>\n",
       "      <td>0.069681</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074454</td>\n",
       "      <td>0.062810</td>\n",
       "      <td>0.273751</td>\n",
       "      <td>0.275359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064992</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059200</td>\n",
       "      <td>0.074809</td>\n",
       "      <td>0.069897</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.076468</td>\n",
       "      <td>0.072985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052069</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>409.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.086052</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.069619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069516</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061291</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248221</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.104604</td>\n",
       "      <td>0.064371</td>\n",
       "      <td>0.110739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074101</td>\n",
       "      <td>0.121709</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055273</td>\n",
       "      <td>0.068849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15006</td>\n",
       "      <td>0.064475</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069790</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071978</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213451</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.242137</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065546</td>\n",
       "      <td>0.235550</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142515</td>\n",
       "      <td>0.09805</td>\n",
       "      <td>0.056570</td>\n",
       "      <td>0.075817</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.119047</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.051653</td>\n",
       "      <td>0.14952</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058563</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.044685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.213772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053819</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.060157</td>\n",
       "      <td>0.057814</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.101667</td>\n",
       "      <td>0.125465</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068460</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.187111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066653</td>\n",
       "      <td>0.057962</td>\n",
       "      <td>0.070925</td>\n",
       "      <td>0.130546</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132383</td>\n",
       "      <td>0.070527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065768</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051285</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.133073</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066248</td>\n",
       "      <td>0.058698</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.064037</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.054378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146019</td>\n",
       "      <td>0.054970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.116333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067642</td>\n",
       "      <td>0.066220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.13176</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072526</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.115372</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056865</td>\n",
       "      <td>0.063435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.053864</td>\n",
       "      <td>0.200488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.127068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050406</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.071407</td>\n",
       "      <td>0.120480</td>\n",
       "      <td>0.052510</td>\n",
       "      <td>0.052818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062333</td>\n",
       "      <td>0.126969</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056777</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288979</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.095411</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.06811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>538.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_vectorizer__abl  count_vectorizer__accept  count_vectorizer__access  \\\n",
       "0               0.000000                  0.000000                  0.000000   \n",
       "1               0.000000                  0.000000                  0.000000   \n",
       "2               0.000000                  0.000000                  0.000000   \n",
       "3               0.068017                  0.065498                  0.000000   \n",
       "4               0.000000                  0.000000                  0.401157   \n",
       "5               0.000000                  0.000000                  0.000000   \n",
       "6               0.000000                  0.000000                  0.000000   \n",
       "7               0.000000                  0.073021                  0.000000   \n",
       "8               0.000000                  0.000000                  0.000000   \n",
       "9               0.000000                  0.000000                  0.000000   \n",
       "\n",
       "   count_vectorizer__accord  count_vectorizer__account  \\\n",
       "0                  0.000000                   0.000000   \n",
       "1                  0.000000                   0.000000   \n",
       "2                  0.000000                   0.000000   \n",
       "3                  0.062228                   0.080480   \n",
       "4                  0.101332                   0.655260   \n",
       "5                  0.000000                   0.000000   \n",
       "6                  0.000000                   0.000000   \n",
       "7                  0.000000                   0.448617   \n",
       "8                  0.000000                   0.086052   \n",
       "9                  0.000000                   0.000000   \n",
       "\n",
       "   count_vectorizer__actual  count_vectorizer__address  \\\n",
       "0                  0.000000                   0.000000   \n",
       "1                  0.000000                   0.000000   \n",
       "2                  0.000000                   0.000000   \n",
       "3                  0.000000                   0.000000   \n",
       "4                  0.000000                   0.230924   \n",
       "5                  0.000000                   0.000000   \n",
       "6                  0.000000                   0.000000   \n",
       "7                  0.079052                   0.052700   \n",
       "8                  0.000000                   0.050543   \n",
       "9                  0.000000                   0.000000   \n",
       "\n",
       "   count_vectorizer__agre  count_vectorizer__agreement  \\\n",
       "0                0.000000                     0.000000   \n",
       "1                0.000000                     0.000000   \n",
       "2                0.000000                     0.192215   \n",
       "3                0.063553                     0.000000   \n",
       "4                0.000000                     0.110575   \n",
       "5                0.000000                     0.000000   \n",
       "6                0.000000                     0.000000   \n",
       "7                0.000000                     0.075704   \n",
       "8                0.000000                     0.072606   \n",
       "9                0.000000                     0.000000   \n",
       "\n",
       "   count_vectorizer__along  count_vectorizer__also  count_vectorizer__amount  \\\n",
       "0                      0.0                0.000000                  0.000000   \n",
       "1                      0.0                0.000000                  0.000000   \n",
       "2                      0.0                0.000000                  0.000000   \n",
       "3                      0.0                0.090342                  0.000000   \n",
       "4                      0.0                0.000000                  0.000000   \n",
       "5                      0.0                0.000000                  0.000000   \n",
       "6                      0.0                0.000000                  0.000000   \n",
       "7                      0.0                0.000000                  0.000000   \n",
       "8                      0.0                0.000000                  0.064164   \n",
       "9                      0.0                0.000000                  0.000000   \n",
       "\n",
       "   count_vectorizer__anoth  count_vectorizer__arrang  count_vectorizer__ask  \\\n",
       "0                      0.0                       0.0               0.000000   \n",
       "1                      0.0                       0.0               0.000000   \n",
       "2                      0.0                       0.0               0.000000   \n",
       "3                      0.0                       0.0               0.203602   \n",
       "4                      0.0                       0.0               0.000000   \n",
       "5                      0.0                       0.0               0.000000   \n",
       "6                      0.0                       0.0               0.000000   \n",
       "7                      0.0                       0.0               0.000000   \n",
       "8                      0.0                       0.0               0.000000   \n",
       "9                      0.0                       0.0               0.000000   \n",
       "\n",
       "   count_vectorizer__assist  count_vectorizer__assur  \\\n",
       "0                  0.000000                 0.000000   \n",
       "1                  0.000000                 0.000000   \n",
       "2                  0.000000                 0.000000   \n",
       "3                  0.000000                 0.000000   \n",
       "4                  0.072752                 0.000000   \n",
       "5                  0.000000                 0.000000   \n",
       "6                  0.000000                 0.000000   \n",
       "7                  0.000000                 0.000000   \n",
       "8                  0.047771                 0.069619   \n",
       "9                  0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__attent  count_vectorizer__back  count_vectorizer__bank  \\\n",
       "0                       0.0                0.000000                0.000000   \n",
       "1                       0.0                0.000000                0.000000   \n",
       "2                       0.0                0.000000                0.000000   \n",
       "3                       0.0                0.000000                0.216137   \n",
       "4                       0.0                0.000000                0.000000   \n",
       "5                       0.0                0.000000                0.000000   \n",
       "6                       0.0                0.000000                0.000000   \n",
       "7                       0.0                0.062723                0.240962   \n",
       "8                       0.0                0.000000                0.000000   \n",
       "9                       0.0                0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__base  count_vectorizer__behalf  count_vectorizer__believ  \\\n",
       "0                0.000000                       0.0                       0.0   \n",
       "1                0.000000                       0.0                       0.0   \n",
       "2                0.000000                       0.0                       0.0   \n",
       "3                0.000000                       0.0                       0.0   \n",
       "4                0.000000                       0.0                       0.0   \n",
       "5                0.000000                       0.0                       0.0   \n",
       "6                0.000000                       0.0                       0.0   \n",
       "7                0.000000                       0.0                       0.0   \n",
       "8                0.069516                       0.0                       0.0   \n",
       "9                0.000000                       0.0                       0.0   \n",
       "\n",
       "   count_vectorizer__beneficiari  count_vectorizer__best  \\\n",
       "0                       0.000000                0.000000   \n",
       "1                       0.000000                0.000000   \n",
       "2                       0.000000                0.000000   \n",
       "3                       0.064391                0.000000   \n",
       "4                       0.000000                0.000000   \n",
       "5                       0.000000                0.000000   \n",
       "6                       0.000000                0.000000   \n",
       "7                       0.071787                0.000000   \n",
       "8                       0.000000                0.061291   \n",
       "9                       0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__bless  count_vectorizer__busi  count_vectorizer__call  \\\n",
       "0                 0.000000                0.000000                0.000000   \n",
       "1                 0.000000                0.000000                0.000000   \n",
       "2                 0.000000                0.000000                0.000000   \n",
       "3                 0.141116                0.000000                0.000000   \n",
       "4                 0.000000                0.000000                0.000000   \n",
       "5                 0.000000                0.000000                0.541824   \n",
       "6                 0.000000                0.000000                0.000000   \n",
       "7                 0.000000                0.049854                0.000000   \n",
       "8                 0.000000                0.095628                0.000000   \n",
       "9                 0.000000                0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__care  count_vectorizer__case  count_vectorizer__chang  \\\n",
       "0                0.000000                     0.0                      0.0   \n",
       "1                0.000000                     0.0                      0.0   \n",
       "2                0.000000                     0.0                      0.0   \n",
       "3                0.067102                     0.0                      0.0   \n",
       "4                0.000000                     0.0                      0.0   \n",
       "5                0.000000                     0.0                      0.0   \n",
       "6                0.000000                     0.0                      0.0   \n",
       "7                0.000000                     0.0                      0.0   \n",
       "8                0.000000                     0.0                      0.0   \n",
       "9                0.000000                     0.0                      0.0   \n",
       "\n",
       "   count_vectorizer__choos  count_vectorizer__claim  count_vectorizer__click  \\\n",
       "0                 0.000000                 0.000000                 0.000000   \n",
       "1                 0.000000                 0.000000                 0.000000   \n",
       "2                 0.000000                 0.000000                 0.000000   \n",
       "3                 0.000000                 0.000000                 0.000000   \n",
       "4                 0.113182                 0.000000                 0.200664   \n",
       "5                 0.000000                 0.000000                 0.000000   \n",
       "6                 0.000000                 0.000000                 0.000000   \n",
       "7                 0.000000                 0.000000                 0.000000   \n",
       "8                 0.000000                 0.248221                 0.000000   \n",
       "9                 0.000000                 0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__client  count_vectorizer__close  count_vectorizer__come  \\\n",
       "0                  0.000000                      0.0                0.000000   \n",
       "1                  0.000000                      0.0                0.000000   \n",
       "2                  0.000000                      0.0                0.000000   \n",
       "3                  0.137728                      0.0                0.097831   \n",
       "4                  0.000000                      0.0                0.000000   \n",
       "5                  0.000000                      0.0                0.000000   \n",
       "6                  0.000000                      0.0                0.000000   \n",
       "7                  0.000000                      0.0                0.000000   \n",
       "8                  0.000000                      0.0                0.104604   \n",
       "9                  0.000000                      0.0                0.000000   \n",
       "\n",
       "   count_vectorizer__commun  count_vectorizer__compani  \\\n",
       "0                  0.000000                   0.000000   \n",
       "1                  0.000000                   0.000000   \n",
       "2                  0.000000                   0.000000   \n",
       "3                  0.000000                   0.000000   \n",
       "4                  0.000000                   0.000000   \n",
       "5                  0.000000                   0.000000   \n",
       "6                  0.000000                   0.000000   \n",
       "7                  0.000000                   0.173197   \n",
       "8                  0.064371                   0.110739   \n",
       "9                  0.000000                   0.000000   \n",
       "\n",
       "   count_vectorizer__complet  count_vectorizer__concern  \\\n",
       "0                   0.000000                        0.0   \n",
       "1                   0.000000                        0.0   \n",
       "2                   0.000000                        0.0   \n",
       "3                   0.062668                        0.0   \n",
       "4                   0.000000                        0.0   \n",
       "5                   0.000000                        0.0   \n",
       "6                   0.000000                        0.0   \n",
       "7                   0.000000                        0.0   \n",
       "8                   0.000000                        0.0   \n",
       "9                   0.000000                        0.0   \n",
       "\n",
       "   count_vectorizer__confid  count_vectorizer__confidenti  \\\n",
       "0                  0.000000                      0.000000   \n",
       "1                  0.000000                      0.000000   \n",
       "2                  0.000000                      0.000000   \n",
       "3                  0.138605                      0.000000   \n",
       "4                  0.000000                      0.000000   \n",
       "5                  0.000000                      0.000000   \n",
       "6                  0.000000                      0.000000   \n",
       "7                  0.000000                      0.126903   \n",
       "8                  0.074101                      0.121709   \n",
       "9                  0.000000                      0.000000   \n",
       "\n",
       "   count_vectorizer__confirm  count_vectorizer__contact  \\\n",
       "0                   0.000000                   0.000000   \n",
       "1                   0.000000                   0.000000   \n",
       "2                   0.000000                   0.000000   \n",
       "3                   0.000000                   0.094191   \n",
       "4                   0.102093                   0.000000   \n",
       "5                   0.584018                   0.000000   \n",
       "6                   0.000000                   0.000000   \n",
       "7                   0.000000                   0.052505   \n",
       "8                   0.000000                   0.000000   \n",
       "9                   0.000000                   0.000000   \n",
       "\n",
       "   count_vectorizer__corpor  count_vectorizer__could  \\\n",
       "0                       0.0                      0.0   \n",
       "1                       0.0                      0.0   \n",
       "2                       0.0                      0.0   \n",
       "3                       0.0                      0.0   \n",
       "4                       0.0                      0.0   \n",
       "5                       0.0                      0.0   \n",
       "6                       0.0                      0.0   \n",
       "7                       0.0                      0.0   \n",
       "8                       0.0                      0.0   \n",
       "9                       0.0                      0.0   \n",
       "\n",
       "   count_vectorizer__countri  count_vectorizer__cours  \\\n",
       "0                   0.000000                      0.0   \n",
       "1                   0.000000                      0.0   \n",
       "2                   0.000000                      0.0   \n",
       "3                   0.000000                      0.0   \n",
       "4                   0.078263                      0.0   \n",
       "5                   0.000000                      0.0   \n",
       "6                   0.000000                      0.0   \n",
       "7                   0.107164                      0.0   \n",
       "8                   0.051389                      0.0   \n",
       "9                   0.000000                      0.0   \n",
       "\n",
       "   count_vectorizer__current  count_vectorizer__custom  count_vectorizer__day  \\\n",
       "0                   0.000000                  0.000000               0.338175   \n",
       "1                   0.000000                  0.000000               0.000000   \n",
       "2                   0.000000                  0.000000               0.146328   \n",
       "3                   0.000000                  0.060227               0.000000   \n",
       "4                   0.000000                  0.000000               0.000000   \n",
       "5                   0.000000                  0.000000               0.000000   \n",
       "6                   0.000000                  0.000000               0.000000   \n",
       "7                   0.075211                  0.000000               0.057631   \n",
       "8                   0.000000                  0.000000               0.055273   \n",
       "9                   0.000000                  0.000000               0.000000   \n",
       "\n",
       "   count_vectorizer__deal  count_vectorizer__dear  count_vectorizer__death  \\\n",
       "0                0.000000                     0.0                      0.0   \n",
       "1                0.000000                     0.0                      0.0   \n",
       "2                0.000000                     0.0                      0.0   \n",
       "3                0.064391                     0.0                      0.0   \n",
       "4                0.000000                     0.0                      0.0   \n",
       "5                0.000000                     0.0                      0.0   \n",
       "6                0.000000                     0.0                      0.0   \n",
       "7                0.000000                     0.0                      0.0   \n",
       "8                0.068849                     0.0                      0.0   \n",
       "9                0.000000                     0.0                      0.0   \n",
       "\n",
       "   count_vectorizer__deceas  count_vectorizer__decid  \\\n",
       "0                  0.000000                 0.000000   \n",
       "1                  0.000000                 0.000000   \n",
       "2                  0.000000                 0.000000   \n",
       "3                  0.141289                 0.000000   \n",
       "4                  0.000000                 0.000000   \n",
       "5                  0.000000                 0.000000   \n",
       "6                  0.000000                 0.000000   \n",
       "7                  0.000000                 0.000000   \n",
       "8                  0.000000                 0.059725   \n",
       "9                  0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__depart  count_vectorizer__deposit  \\\n",
       "0                  0.000000                        0.0   \n",
       "1                  0.000000                        0.0   \n",
       "2                  0.172443                        0.0   \n",
       "3                  0.000000                        0.0   \n",
       "4                  0.000000                        0.0   \n",
       "5                  0.000000                        0.0   \n",
       "6                  0.000000                        0.0   \n",
       "7                  0.000000                        0.0   \n",
       "8                  0.000000                        0.0   \n",
       "9                  0.000000                        0.0   \n",
       "\n",
       "   count_vectorizer__develop  count_vectorizer__direct  \\\n",
       "0                   0.000000                  0.000000   \n",
       "1                   0.000000                  0.000000   \n",
       "2                   0.000000                  0.000000   \n",
       "3                   0.000000                  0.068474   \n",
       "4                   0.000000                  0.000000   \n",
       "5                   0.000000                  0.000000   \n",
       "6                   0.000000                  0.000000   \n",
       "7                   0.236568                  0.000000   \n",
       "8                   0.000000                  0.000000   \n",
       "9                   0.000000                  0.000000   \n",
       "\n",
       "   count_vectorizer__discov  count_vectorizer__discuss  \\\n",
       "0                       0.0                        0.0   \n",
       "1                       0.0                        0.0   \n",
       "2                       0.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "5                       0.0                        0.0   \n",
       "6                       0.0                        0.0   \n",
       "7                       0.0                        0.0   \n",
       "8                       0.0                        0.0   \n",
       "9                       0.0                        0.0   \n",
       "\n",
       "   count_vectorizer__done  count_vectorizer__due  count_vectorizer__easi  \\\n",
       "0                 0.00000               0.000000                0.000000   \n",
       "1                 0.00000               0.000000                0.000000   \n",
       "2                 0.00000               0.000000                0.000000   \n",
       "3                 0.00000               0.000000                0.069262   \n",
       "4                 0.00000               0.000000                0.000000   \n",
       "5                 0.00000               0.000000                0.000000   \n",
       "6                 0.00000               0.000000                0.000000   \n",
       "7                 0.00000               0.000000                0.000000   \n",
       "8                 0.15006               0.064475                0.000000   \n",
       "9                 0.00000               0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__enabl  count_vectorizer__end  count_vectorizer__even  \\\n",
       "0                      0.0               0.000000                     0.0   \n",
       "1                      0.0               0.000000                     0.0   \n",
       "2                      0.0               0.000000                     0.0   \n",
       "3                      0.0               0.060719                     0.0   \n",
       "4                      0.0               0.000000                     0.0   \n",
       "5                      0.0               0.000000                     0.0   \n",
       "6                      0.0               0.000000                     0.0   \n",
       "7                      0.0               0.000000                     0.0   \n",
       "8                      0.0               0.000000                     0.0   \n",
       "9                      0.0               0.000000                     0.0   \n",
       "\n",
       "   count_vectorizer__everi  count_vectorizer__execut  count_vectorizer__fact  \\\n",
       "0                 0.000000                  0.000000                0.000000   \n",
       "1                 0.000000                  0.000000                0.000000   \n",
       "2                 0.198513                  0.000000                0.000000   \n",
       "3                 0.000000                  0.000000                0.067462   \n",
       "4                 0.000000                  0.000000                0.000000   \n",
       "5                 0.000000                  0.000000                0.000000   \n",
       "6                 0.000000                  0.000000                0.000000   \n",
       "7                 0.000000                  0.218304                0.000000   \n",
       "8                 0.000000                  0.069790                0.000000   \n",
       "9                 0.000000                  0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__faith  count_vectorizer__famili  \\\n",
       "0                      0.0                  0.000000   \n",
       "1                      0.0                  0.000000   \n",
       "2                      0.0                  0.000000   \n",
       "3                      0.0                  0.162574   \n",
       "4                      0.0                  0.000000   \n",
       "5                      0.0                  0.000000   \n",
       "6                      0.0                  0.000000   \n",
       "7                      0.0                  0.000000   \n",
       "8                      0.0                  0.000000   \n",
       "9                      0.0                  0.000000   \n",
       "\n",
       "   count_vectorizer__father  count_vectorizer__file  count_vectorizer__final  \\\n",
       "0                       0.0                     0.0                 0.000000   \n",
       "1                       0.0                     0.0                 0.000000   \n",
       "2                       0.0                     0.0                 0.000000   \n",
       "3                       0.0                     0.0                 0.000000   \n",
       "4                       0.0                     0.0                 0.000000   \n",
       "5                       0.0                     0.0                 0.000000   \n",
       "6                       0.0                     0.0                 0.000000   \n",
       "7                       0.0                     0.0                 0.075049   \n",
       "8                       0.0                     0.0                 0.071978   \n",
       "9                       0.0                     0.0                 0.000000   \n",
       "\n",
       "   count_vectorizer__financi  count_vectorizer__find  count_vectorizer__first  \\\n",
       "0                        0.0                0.000000                 0.000000   \n",
       "1                        0.0                0.000000                 0.000000   \n",
       "2                        0.0                0.000000                 0.160313   \n",
       "3                        0.0                0.202936                 0.000000   \n",
       "4                        0.0                0.000000                 0.000000   \n",
       "5                        0.0                0.000000                 0.000000   \n",
       "6                        0.0                0.000000                 0.000000   \n",
       "7                        0.0                0.000000                 0.000000   \n",
       "8                        0.0                0.000000                 0.000000   \n",
       "9                        0.0                0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__five  count_vectorizer__follow  \\\n",
       "0                 0.00000                       0.0   \n",
       "1                 0.00000                       0.0   \n",
       "2                 0.00000                       0.0   \n",
       "3                 0.00000                       0.0   \n",
       "4                 0.00000                       0.0   \n",
       "5                 0.00000                       0.0   \n",
       "6                 0.00000                       0.0   \n",
       "7                 0.06581                       0.0   \n",
       "8                 0.00000                       0.0   \n",
       "9                 0.00000                       0.0   \n",
       "\n",
       "   count_vectorizer__foreign  count_vectorizer__form  \\\n",
       "0                   0.000000                     0.0   \n",
       "1                   0.000000                     0.0   \n",
       "2                   0.000000                     0.0   \n",
       "3                   0.049907                     0.0   \n",
       "4                   0.081269                     0.0   \n",
       "5                   0.000000                     0.0   \n",
       "6                   0.000000                     0.0   \n",
       "7                   0.166919                     0.0   \n",
       "8                   0.213451                     0.0   \n",
       "9                   0.000000                     0.0   \n",
       "\n",
       "   count_vectorizer__former  count_vectorizer__forward  \\\n",
       "0                       0.0                   0.000000   \n",
       "1                       0.0                   0.000000   \n",
       "2                       0.0                   0.000000   \n",
       "3                       0.0                   0.000000   \n",
       "4                       0.0                   0.000000   \n",
       "5                       0.0                   0.000000   \n",
       "6                       0.0                   0.000000   \n",
       "7                       0.0                   0.063117   \n",
       "8                       0.0                   0.242137   \n",
       "9                       0.0                   0.000000   \n",
       "\n",
       "   count_vectorizer__free  count_vectorizer__friend  count_vectorizer__full  \\\n",
       "0                0.000000                       0.0                0.000000   \n",
       "1                0.000000                       0.0                0.000000   \n",
       "2                0.000000                       0.0                0.000000   \n",
       "3                0.000000                       0.0                0.000000   \n",
       "4                0.000000                       0.0                0.099824   \n",
       "5                0.000000                       0.0                0.000000   \n",
       "6                0.000000                       0.0                0.000000   \n",
       "7                0.062359                       0.0                0.000000   \n",
       "8                0.000000                       0.0                0.065546   \n",
       "9                0.000000                       0.0                0.000000   \n",
       "\n",
       "   count_vectorizer__fund  count_vectorizer__futur  count_vectorizer__gener  \\\n",
       "0                0.000000                 0.000000                 0.000000   \n",
       "1                0.000000                 0.000000                 0.000000   \n",
       "2                0.000000                 0.000000                 0.000000   \n",
       "3                0.044060                 0.000000                 0.000000   \n",
       "4                0.000000                 0.000000                 0.000000   \n",
       "5                0.000000                 0.000000                 0.000000   \n",
       "6                0.000000                 0.000000                 0.000000   \n",
       "7                0.196481                 0.075663                 0.000000   \n",
       "8                0.235550                 0.000000                 0.142515   \n",
       "9                0.000000                 0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__get  count_vectorizer__give  count_vectorizer__given  \\\n",
       "0                0.00000                0.000000                 0.000000   \n",
       "1                0.00000                0.000000                 0.000000   \n",
       "2                0.00000                0.000000                 0.000000   \n",
       "3                0.00000                0.158721                 0.000000   \n",
       "4                0.00000                0.000000                 0.000000   \n",
       "5                0.00000                0.000000                 0.000000   \n",
       "6                0.00000                0.000000                 0.000000   \n",
       "7                0.00000                0.000000                 0.000000   \n",
       "8                0.09805                0.056570                 0.075817   \n",
       "9                0.00000                0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__go  count_vectorizer__god  count_vectorizer__good  \\\n",
       "0              0.000000                    0.0                0.000000   \n",
       "1              0.000000                    0.0                0.000000   \n",
       "2              0.000000                    0.0                0.000000   \n",
       "3              0.000000                    0.0                0.106992   \n",
       "4              0.079843                    0.0                0.000000   \n",
       "5              0.000000                    0.0                0.000000   \n",
       "6              0.000000                    0.0                0.000000   \n",
       "7              0.000000                    0.0                0.000000   \n",
       "8              0.000000                    0.0                0.057200   \n",
       "9              0.000000                    0.0                0.000000   \n",
       "\n",
       "   count_vectorizer__got  count_vectorizer__govern  count_vectorizer__great  \\\n",
       "0                    0.0                  0.000000                 0.442286   \n",
       "1                    0.0                  0.000000                 0.000000   \n",
       "2                    0.0                  0.000000                 0.000000   \n",
       "3                    0.0                  0.000000                 0.000000   \n",
       "4                    0.0                  0.000000                 0.000000   \n",
       "5                    0.0                  0.000000                 0.000000   \n",
       "6                    0.0                  0.000000                 0.000000   \n",
       "7                    0.0                  0.186189                 0.000000   \n",
       "8                    0.0                  0.119047                 0.000000   \n",
       "9                    0.0                  0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__group  count_vectorizer__hear  count_vectorizer__help  \\\n",
       "0                      0.0                0.000000                0.000000   \n",
       "1                      0.0                0.000000                0.000000   \n",
       "2                      0.0                0.000000                0.000000   \n",
       "3                      0.0                0.000000                0.000000   \n",
       "4                      0.0                0.000000                0.078665   \n",
       "5                      0.0                0.000000                0.000000   \n",
       "6                      0.0                0.000000                0.000000   \n",
       "7                      0.0                0.000000                0.000000   \n",
       "8                      0.0                0.067797                0.051653   \n",
       "9                      0.0                0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__henc  count_vectorizer__home  count_vectorizer__hope  \\\n",
       "0                 0.00000                     0.0                     0.0   \n",
       "1                 0.00000                     0.0                     0.0   \n",
       "2                 0.00000                     0.0                     0.0   \n",
       "3                 0.00000                     0.0                     0.0   \n",
       "4                 0.00000                     0.0                     0.0   \n",
       "5                 0.00000                     0.0                     0.0   \n",
       "6                 0.00000                     0.0                     0.0   \n",
       "7                 0.00000                     0.0                     0.0   \n",
       "8                 0.14952                     0.0                     0.0   \n",
       "9                 0.00000                     0.0                     0.0   \n",
       "\n",
       "   count_vectorizer__hous  count_vectorizer__howev  count_vectorizer__hundr  \\\n",
       "0                0.000000                 0.000000                 0.000000   \n",
       "1                0.000000                 0.000000                 0.000000   \n",
       "2                0.195042                 0.000000                 0.000000   \n",
       "3                0.000000                 0.000000                 0.000000   \n",
       "4                0.000000                 0.000000                 0.000000   \n",
       "5                0.000000                 0.000000                 0.000000   \n",
       "6                0.000000                 0.000000                 0.000000   \n",
       "7                0.000000                 0.070625                 0.067036   \n",
       "8                0.000000                 0.000000                 0.000000   \n",
       "9                0.000000                 0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__id  count_vectorizer__immedi  count_vectorizer__import  \\\n",
       "0                   0.0                  0.000000                       0.0   \n",
       "1                   0.0                  0.000000                       0.0   \n",
       "2                   0.0                  0.000000                       0.0   \n",
       "3                   0.0                  0.000000                       0.0   \n",
       "4                   0.0                  0.000000                       0.0   \n",
       "5                   0.0                  0.000000                       0.0   \n",
       "6                   0.0                  0.000000                       0.0   \n",
       "7                   0.0                  0.000000                       0.0   \n",
       "8                   0.0                  0.058563                       0.0   \n",
       "9                   0.0                  0.000000                       0.0   \n",
       "\n",
       "   count_vectorizer__includ  count_vectorizer__inform  \\\n",
       "0                       0.0                  0.000000   \n",
       "1                       0.0                  0.000000   \n",
       "2                       0.0                  0.118297   \n",
       "3                       0.0                  0.083583   \n",
       "4                       0.0                  0.136105   \n",
       "5                       0.0                  0.000000   \n",
       "6                       0.0                  0.000000   \n",
       "7                       0.0                  0.000000   \n",
       "8                       0.0                  0.044685   \n",
       "9                       0.0                  0.000000   \n",
       "\n",
       "   count_vectorizer__interest  count_vectorizer__intern  \\\n",
       "0                    0.000000                  0.000000   \n",
       "1                    0.000000                  0.000000   \n",
       "2                    0.000000                  0.000000   \n",
       "3                    0.105271                  0.128356   \n",
       "4                    0.000000                  0.000000   \n",
       "5                    0.000000                  0.000000   \n",
       "6                    0.000000                  0.000000   \n",
       "7                    0.000000                  0.000000   \n",
       "8                    0.000000                  0.000000   \n",
       "9                    0.000000                  0.000000   \n",
       "\n",
       "   count_vectorizer__invest  count_vectorizer__involv  count_vectorizer__issu  \\\n",
       "0                       0.0                  0.000000                0.000000   \n",
       "1                       0.0                  0.000000                0.000000   \n",
       "2                       0.0                  0.000000                0.000000   \n",
       "3                       0.0                  0.066643                0.000000   \n",
       "4                       0.0                  0.000000                0.111881   \n",
       "5                       0.0                  0.000000                0.000000   \n",
       "6                       0.0                  0.000000                0.000000   \n",
       "7                       0.0                  0.000000                0.000000   \n",
       "8                       0.0                  0.213772                0.000000   \n",
       "9                       0.0                  0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__keep  count_vectorizer__kin  count_vectorizer__know  \\\n",
       "0                0.000000                    0.0                0.000000   \n",
       "1                0.000000                    0.0                0.000000   \n",
       "2                0.000000                    0.0                0.000000   \n",
       "3                0.000000                    0.0                0.190408   \n",
       "4                0.000000                    0.0                0.000000   \n",
       "5                0.000000                    0.0                0.000000   \n",
       "6                0.000000                    0.0                0.000000   \n",
       "7                0.000000                    0.0                0.000000   \n",
       "8                0.065164                    0.0                0.000000   \n",
       "9                0.000000                    0.0                0.000000   \n",
       "\n",
       "   count_vectorizer__last  count_vectorizer__late  count_vectorizer__law  \\\n",
       "0                     0.0                     0.0               0.000000   \n",
       "1                     0.0                     0.0               0.000000   \n",
       "2                     0.0                     0.0               0.000000   \n",
       "3                     0.0                     0.0               0.000000   \n",
       "4                     0.0                     0.0               0.000000   \n",
       "5                     0.0                     0.0               0.000000   \n",
       "6                     0.0                     0.0               0.000000   \n",
       "7                     0.0                     0.0               0.072732   \n",
       "8                     0.0                     0.0               0.000000   \n",
       "9                     0.0                     0.0               0.000000   \n",
       "\n",
       "   count_vectorizer__leav  count_vectorizer__left  count_vectorizer__legal  \\\n",
       "0                     0.0                     0.0                 0.000000   \n",
       "1                     0.0                     0.0                 0.000000   \n",
       "2                     0.0                     0.0                 0.000000   \n",
       "3                     0.0                     0.0                 0.000000   \n",
       "4                     0.0                     0.0                 0.000000   \n",
       "5                     0.0                     0.0                 0.000000   \n",
       "6                     0.0                     0.0                 0.000000   \n",
       "7                     0.0                     0.0                 0.078374   \n",
       "8                     0.0                     0.0                 0.000000   \n",
       "9                     0.0                     0.0                 0.000000   \n",
       "\n",
       "   count_vectorizer__let  count_vectorizer__letter  count_vectorizer__life  \\\n",
       "0               0.000000                  0.000000                0.000000   \n",
       "1               0.000000                  0.000000                0.000000   \n",
       "2               0.000000                  0.000000                0.000000   \n",
       "3               0.183753                  0.060398                0.130221   \n",
       "4               0.000000                  0.000000                0.000000   \n",
       "5               0.000000                  0.000000                0.000000   \n",
       "6               0.000000                  0.000000                0.000000   \n",
       "7               0.000000                  0.000000                0.000000   \n",
       "8               0.000000                  0.000000                0.000000   \n",
       "9               0.000000                  0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__like  count_vectorizer__link  count_vectorizer__list  \\\n",
       "0                0.329279                0.000000                     0.0   \n",
       "1                0.000000                0.000000                     0.0   \n",
       "2                0.000000                0.000000                     0.0   \n",
       "3                0.100668                0.061986                     0.0   \n",
       "4                0.000000                0.100936                     0.0   \n",
       "5                0.000000                0.000000                     0.0   \n",
       "6                0.000000                0.000000                     0.0   \n",
       "7                0.000000                0.000000                     0.0   \n",
       "8                0.053819                0.000000                     0.0   \n",
       "9                0.000000                0.000000                     0.0   \n",
       "\n",
       "   count_vectorizer__live  count_vectorizer__long  count_vectorizer__look  \\\n",
       "0                     0.0                     0.0                0.000000   \n",
       "1                     0.0                     0.0                0.000000   \n",
       "2                     0.0                     0.0                0.000000   \n",
       "3                     0.0                     0.0                0.000000   \n",
       "4                     0.0                     0.0                0.000000   \n",
       "5                     0.0                     0.0                0.000000   \n",
       "6                     0.0                     0.0                0.000000   \n",
       "7                     0.0                     0.0                0.125447   \n",
       "8                     0.0                     0.0                0.060157   \n",
       "9                     0.0                     0.0                0.000000   \n",
       "\n",
       "   count_vectorizer__made  count_vectorizer__mail  count_vectorizer__mailman  \\\n",
       "0                0.000000                0.000000                   0.415945   \n",
       "1                0.000000                0.000000                   0.000000   \n",
       "2                0.000000                0.000000                   0.000000   \n",
       "3                0.054071                0.093206                   0.000000   \n",
       "4                0.000000                0.151775                   0.000000   \n",
       "5                0.000000                0.000000                   0.000000   \n",
       "6                0.000000                0.000000                   0.000000   \n",
       "7                0.060281                0.103911                   0.000000   \n",
       "8                0.057814                0.000000                   0.000000   \n",
       "9                0.000000                0.000000                   0.000000   \n",
       "\n",
       "   count_vectorizer__make  count_vectorizer__manag  count_vectorizer__mani  \\\n",
       "0                0.000000                 0.000000                0.000000   \n",
       "1                0.000000                 0.000000                0.000000   \n",
       "2                0.000000                 0.000000                0.195154   \n",
       "3                0.095084                 0.058671                0.000000   \n",
       "4                0.000000                 0.000000                0.000000   \n",
       "5                0.000000                 0.000000                0.000000   \n",
       "6                0.000000                 0.000000                0.000000   \n",
       "7                0.000000                 0.000000                0.000000   \n",
       "8                0.101667                 0.125465                0.000000   \n",
       "9                0.000000                 0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__matter  count_vectorizer__may  count_vectorizer__meet  \\\n",
       "0                  0.000000               0.000000                0.000000   \n",
       "1                  0.000000               0.000000                0.000000   \n",
       "2                  0.000000               0.000000                0.000000   \n",
       "3                  0.000000               0.094682                0.065143   \n",
       "4                  0.000000               0.077089                0.000000   \n",
       "5                  0.000000               0.000000                0.000000   \n",
       "6                  0.000000               0.000000                0.000000   \n",
       "7                  0.071381               0.000000                0.000000   \n",
       "8                  0.068460               0.000000                0.069653   \n",
       "9                  0.000000               0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__member  count_vectorizer__messag  \\\n",
       "0                       0.0                  0.000000   \n",
       "1                       0.0                  0.000000   \n",
       "2                       0.0                  0.000000   \n",
       "3                       0.0                  0.059121   \n",
       "4                       0.0                  0.000000   \n",
       "5                       0.0                  0.000000   \n",
       "6                       0.0                  0.000000   \n",
       "7                       0.0                  0.000000   \n",
       "8                       0.0                  0.000000   \n",
       "9                       0.0                  0.000000   \n",
       "\n",
       "   count_vectorizer__might  count_vectorizer__million  \\\n",
       "0                      0.0                   0.286200   \n",
       "1                      0.0                   0.000000   \n",
       "2                      0.0                   0.000000   \n",
       "3                      0.0                   0.000000   \n",
       "4                      0.0                   0.000000   \n",
       "5                      0.0                   0.000000   \n",
       "6                      0.0                   0.000000   \n",
       "7                      0.0                   0.097548   \n",
       "8                      0.0                   0.187111   \n",
       "9                      0.0                   0.000000   \n",
       "\n",
       "   count_vectorizer__money  count_vectorizer__move  count_vectorizer__much  \\\n",
       "0                 0.000000                0.000000                0.000000   \n",
       "1                 0.000000                0.000000                0.000000   \n",
       "2                 0.000000                0.000000                0.180984   \n",
       "3                 0.000000                0.138044                0.000000   \n",
       "4                 0.000000                0.000000                0.000000   \n",
       "5                 0.000000                0.000000                0.000000   \n",
       "6                 0.000000                0.000000                0.000000   \n",
       "7                 0.048529                0.000000                0.000000   \n",
       "8                 0.000000                0.000000                0.068364   \n",
       "9                 0.000000                0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__must  count_vectorizer__name  count_vectorizer__nation  \\\n",
       "0                0.000000                0.000000                       0.0   \n",
       "1                0.000000                0.000000                       0.0   \n",
       "2                0.000000                0.000000                       0.0   \n",
       "3                0.000000                0.049175                       0.0   \n",
       "4                0.000000                0.000000                       0.0   \n",
       "5                0.000000                0.000000                       0.0   \n",
       "6                0.000000                0.000000                       0.0   \n",
       "7                0.067861                0.164469                       0.0   \n",
       "8                0.000000                0.000000                       0.0   \n",
       "9                0.000000                0.000000                       0.0   \n",
       "\n",
       "   count_vectorizer__necessari  count_vectorizer__need  count_vectorizer__net  \\\n",
       "0                     0.000000                0.000000                    0.0   \n",
       "1                     0.000000                0.000000                    0.0   \n",
       "2                     0.000000                0.000000                    0.0   \n",
       "3                     0.000000                0.093913                    0.0   \n",
       "4                     0.104854                0.000000                    0.0   \n",
       "5                     0.000000                0.000000                    0.0   \n",
       "6                     0.000000                0.000000                    0.0   \n",
       "7                     0.000000                0.052350                    0.0   \n",
       "8                     0.000000                0.050208                    0.0   \n",
       "9                     0.000000                0.000000                    0.0   \n",
       "\n",
       "   count_vectorizer__never  count_vectorizer__new  count_vectorizer__next  \\\n",
       "0                 0.000000               0.000000                0.000000   \n",
       "1                 0.000000               0.000000                0.000000   \n",
       "2                 0.186998               0.000000                0.000000   \n",
       "3                 0.066061               0.053069                0.051619   \n",
       "4                 0.000000               0.000000                0.000000   \n",
       "5                 0.000000               0.000000                0.000000   \n",
       "6                 0.000000               0.000000                0.000000   \n",
       "7                 0.000000               0.000000                0.000000   \n",
       "8                 0.000000               0.000000                0.000000   \n",
       "9                 0.000000               0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__note  count_vectorizer__number  count_vectorizer__offer  \\\n",
       "0                0.000000                  0.000000                 0.000000   \n",
       "1                0.000000                  0.000000                 0.000000   \n",
       "2                0.000000                  0.000000                 0.000000   \n",
       "3                0.062337                  0.000000                 0.066333   \n",
       "4                0.000000                  0.000000                 0.000000   \n",
       "5                0.000000                  0.000000                 0.000000   \n",
       "6                0.000000                  0.000000                 0.000000   \n",
       "7                0.069497                  0.060435                 0.000000   \n",
       "8                0.066653                  0.057962                 0.070925   \n",
       "9                0.000000                  0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__offic  count_vectorizer__offici  count_vectorizer__old  \\\n",
       "0                 0.000000                   0.00000                    0.0   \n",
       "1                 0.000000                   0.00000                    0.0   \n",
       "2                 0.000000                   0.00000                    0.0   \n",
       "3                 0.000000                   0.27951                    0.0   \n",
       "4                 0.000000                   0.00000                    0.0   \n",
       "5                 0.000000                   0.00000                    0.0   \n",
       "6                 0.000000                   0.00000                    0.0   \n",
       "7                 0.000000                   0.00000                    0.0   \n",
       "8                 0.130546                   0.00000                    0.0   \n",
       "9                 0.000000                   0.00000                    0.0   \n",
       "\n",
       "   count_vectorizer__one  count_vectorizer__open  count_vectorizer__oper  \\\n",
       "0               0.000000                     0.0                0.000000   \n",
       "1               0.000000                     0.0                0.000000   \n",
       "2               0.000000                     0.0                0.000000   \n",
       "3               0.130587                     0.0                0.000000   \n",
       "4               0.070882                     0.0                0.000000   \n",
       "5               0.000000                     0.0                0.000000   \n",
       "6               0.000000                     0.0                0.000000   \n",
       "7               0.000000                     0.0                0.069016   \n",
       "8               0.000000                     0.0                0.132383   \n",
       "9               0.000000                     0.0                0.000000   \n",
       "\n",
       "   count_vectorizer__order  count_vectorizer__part  count_vectorizer__partner  \\\n",
       "0                 0.000000                     0.0                   0.000000   \n",
       "1                 0.000000                     0.0                   0.000000   \n",
       "2                 0.000000                     0.0                   0.000000   \n",
       "3                 0.000000                     0.0                   0.061510   \n",
       "4                 0.000000                     0.0                   0.000000   \n",
       "5                 0.000000                     0.0                   0.000000   \n",
       "6                 0.000000                     0.0                   0.000000   \n",
       "7                 0.000000                     0.0                   0.137149   \n",
       "8                 0.070527                     0.0                   0.065768   \n",
       "9                 0.000000                     0.0                   0.000000   \n",
       "\n",
       "   count_vectorizer__peopl  count_vectorizer__person  count_vectorizer__phone  \\\n",
       "0                 0.000000                  0.000000                 0.000000   \n",
       "1                 0.000000                  0.000000                 0.000000   \n",
       "2                 0.000000                  0.000000                 0.000000   \n",
       "3                 0.063494                  0.000000                 0.063788   \n",
       "4                 0.000000                  0.000000                 0.000000   \n",
       "5                 0.000000                  0.000000                 0.000000   \n",
       "6                 0.000000                  0.000000                 0.000000   \n",
       "7                 0.000000                  0.000000                 0.000000   \n",
       "8                 0.000000                  0.051285                 0.000000   \n",
       "9                 0.000000                  0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__place  count_vectorizer__pleas  count_vectorizer__polici  \\\n",
       "0                 0.000000                 0.000000                  0.000000   \n",
       "1                 0.000000                 0.000000                  0.000000   \n",
       "2                 0.000000                 0.000000                  0.000000   \n",
       "3                 0.000000                 0.077742                  0.067867   \n",
       "4                 0.000000                 0.126595                  0.000000   \n",
       "5                 0.000000                 0.000000                  0.000000   \n",
       "6                 0.000000                 0.000000                  0.000000   \n",
       "7                 0.075913                 0.043336                  0.000000   \n",
       "8                 0.000000                 0.000000                  0.000000   \n",
       "9                 0.000000                 0.000000                  0.000000   \n",
       "\n",
       "   count_vectorizer__polit  count_vectorizer__posit  \\\n",
       "0                      0.0                 0.000000   \n",
       "1                      0.0                 0.000000   \n",
       "2                      0.0                 0.000000   \n",
       "3                      0.0                 0.062228   \n",
       "4                      0.0                 0.000000   \n",
       "5                      0.0                 0.000000   \n",
       "6                      0.0                 0.000000   \n",
       "7                      0.0                 0.069376   \n",
       "8                      0.0                 0.133073   \n",
       "9                      0.0                 0.000000   \n",
       "\n",
       "   count_vectorizer__possibl  count_vectorizer__present  \\\n",
       "0                    0.00000                   0.000000   \n",
       "1                    0.00000                   0.000000   \n",
       "2                    0.00000                   0.000000   \n",
       "3                    0.00000                   0.000000   \n",
       "4                    0.10046                   0.000000   \n",
       "5                    0.00000                   0.000000   \n",
       "6                    0.00000                   0.000000   \n",
       "7                    0.00000                   0.064968   \n",
       "8                    0.00000                   0.000000   \n",
       "9                    0.00000                   0.000000   \n",
       "\n",
       "   count_vectorizer__presid  count_vectorizer__privat  \\\n",
       "0                  0.000000                  0.000000   \n",
       "1                  0.000000                  0.000000   \n",
       "2                  0.000000                  0.000000   \n",
       "3                  0.000000                  0.109794   \n",
       "4                  0.000000                  0.000000   \n",
       "5                  0.000000                  0.000000   \n",
       "6                  0.000000                  0.000000   \n",
       "7                  0.000000                  0.000000   \n",
       "8                  0.066248                  0.058698   \n",
       "9                  0.000000                  0.000000   \n",
       "\n",
       "   count_vectorizer__problem  count_vectorizer__process  \\\n",
       "0                        0.0                   0.000000   \n",
       "1                        0.0                   0.000000   \n",
       "2                        0.0                   0.000000   \n",
       "3                        0.0                   0.065433   \n",
       "4                        0.0                   0.000000   \n",
       "5                        0.0                   0.000000   \n",
       "6                        0.0                   0.000000   \n",
       "7                        0.0                   0.000000   \n",
       "8                        0.0                   0.000000   \n",
       "9                        0.0                   0.000000   \n",
       "\n",
       "   count_vectorizer__propos  count_vectorizer__protect  \\\n",
       "0                  0.000000                        0.0   \n",
       "1                  0.000000                        0.0   \n",
       "2                  0.000000                        0.0   \n",
       "3                  0.119781                        0.0   \n",
       "4                  0.000000                        0.0   \n",
       "5                  0.000000                        0.0   \n",
       "6                  0.000000                        0.0   \n",
       "7                  0.000000                        0.0   \n",
       "8                  0.064037                        0.0   \n",
       "9                  0.000000                        0.0   \n",
       "\n",
       "   count_vectorizer__provid  count_vectorizer__put  count_vectorizer__read  \\\n",
       "0                  0.000000               0.000000                     0.0   \n",
       "1                  0.000000               0.000000                     0.0   \n",
       "2                  0.000000               0.000000                     0.0   \n",
       "3                  0.167290               0.000000                     0.0   \n",
       "4                  0.000000               0.000000                     0.0   \n",
       "5                  0.000000               0.000000                     0.0   \n",
       "6                  0.000000               0.000000                     0.0   \n",
       "7                  0.124336               0.075998                     0.0   \n",
       "8                  0.000000               0.072888                     0.0   \n",
       "9                  0.000000               0.000000                     0.0   \n",
       "\n",
       "   count_vectorizer__real  count_vectorizer__reason  count_vectorizer__receiv  \\\n",
       "0                     0.0                  0.000000                  0.000000   \n",
       "1                     0.0                  0.000000                  0.000000   \n",
       "2                     0.0                  0.000000                  0.000000   \n",
       "3                     0.0                  0.000000                  0.000000   \n",
       "4                     0.0                  0.000000                  0.082815   \n",
       "5                     0.0                  0.000000                  0.000000   \n",
       "6                     0.0                  0.000000                  0.000000   \n",
       "7                     0.0                  0.073094                  0.000000   \n",
       "8                     0.0                  0.000000                  0.054378   \n",
       "9                     0.0                  0.000000                  0.000000   \n",
       "\n",
       "   count_vectorizer__recent  count_vectorizer__releas  \\\n",
       "0                       0.0                       0.0   \n",
       "1                       0.0                       0.0   \n",
       "2                       0.0                       0.0   \n",
       "3                       0.0                       0.0   \n",
       "4                       0.0                       0.0   \n",
       "5                       0.0                       0.0   \n",
       "6                       0.0                       0.0   \n",
       "7                       0.0                       0.0   \n",
       "8                       0.0                       0.0   \n",
       "9                       0.0                       0.0   \n",
       "\n",
       "   count_vectorizer__reliabl  count_vectorizer__repli  \\\n",
       "0                   0.000000                 0.000000   \n",
       "1                   0.000000                 0.000000   \n",
       "2                   0.000000                 0.000000   \n",
       "3                   0.000000                 0.000000   \n",
       "4                   0.000000                 0.083716   \n",
       "5                   0.000000                 0.000000   \n",
       "6                   0.000000                 0.000000   \n",
       "7                   0.000000                 0.057315   \n",
       "8                   0.146019                 0.054970   \n",
       "9                   0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__request  count_vectorizer__reserv  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        0.0                       0.0   \n",
       "4                        0.0                       0.0   \n",
       "5                        0.0                       0.0   \n",
       "6                        0.0                       0.0   \n",
       "7                        0.0                       0.0   \n",
       "8                        0.0                       0.0   \n",
       "9                        0.0                       0.0   \n",
       "\n",
       "   count_vectorizer__respect  count_vectorizer__respons  \\\n",
       "0                        0.0                   0.000000   \n",
       "1                        0.0                   0.000000   \n",
       "2                        0.0                   0.000000   \n",
       "3                        0.0                   0.108800   \n",
       "4                        0.0                   0.000000   \n",
       "5                        0.0                   0.000000   \n",
       "6                        0.0                   0.000000   \n",
       "7                        0.0                   0.060648   \n",
       "8                        0.0                   0.116333   \n",
       "9                        0.0                   0.000000   \n",
       "\n",
       "   count_vectorizer__result  count_vectorizer__right  count_vectorizer__risk  \\\n",
       "0                       0.0                 0.000000                0.000000   \n",
       "1                       0.0                 0.000000                0.000000   \n",
       "2                       0.0                 0.000000                0.000000   \n",
       "3                       0.0                 0.000000                0.123864   \n",
       "4                       0.0                 0.000000                0.000000   \n",
       "5                       0.0                 0.000000                0.000000   \n",
       "6                       0.0                 0.000000                0.000000   \n",
       "7                       0.0                 0.000000                0.069045   \n",
       "8                       0.0                 0.067642                0.066220   \n",
       "9                       0.0                 0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__run  count_vectorizer__safe  count_vectorizer__said  \\\n",
       "0               0.000000                 0.00000                0.000000   \n",
       "1               0.000000                 0.00000                0.000000   \n",
       "2               0.000000                 0.00000                0.000000   \n",
       "3               0.068244                 0.00000                0.062419   \n",
       "4               0.000000                 0.00000                0.000000   \n",
       "5               0.000000                 0.00000                0.000000   \n",
       "6               0.000000                 0.00000                0.000000   \n",
       "7               0.000000                 0.00000                0.000000   \n",
       "8               0.000000                 0.13176                0.000000   \n",
       "9               0.000000                 0.00000                0.000000   \n",
       "\n",
       "   count_vectorizer__say  count_vectorizer__search  count_vectorizer__secur  \\\n",
       "0                    0.0                       0.0                 0.000000   \n",
       "1                    0.0                       0.0                 0.000000   \n",
       "2                    0.0                       0.0                 0.000000   \n",
       "3                    0.0                       0.0                 0.045829   \n",
       "4                    0.0                       0.0                 0.223883   \n",
       "5                    0.0                       0.0                 0.000000   \n",
       "6                    0.0                       0.0                 0.000000   \n",
       "7                    0.0                       0.0                 0.000000   \n",
       "8                    0.0                       0.0                 0.000000   \n",
       "9                    0.0                       0.0                 0.000000   \n",
       "\n",
       "   count_vectorizer__see  count_vectorizer__seek  count_vectorizer__send  \\\n",
       "0                    0.0                     0.0                0.000000   \n",
       "1                    1.0                     0.0                0.000000   \n",
       "2                    0.0                     0.0                0.000000   \n",
       "3                    0.0                     0.0                0.052135   \n",
       "4                    0.0                     0.0                0.000000   \n",
       "5                    0.0                     0.0                0.000000   \n",
       "6                    0.0                     0.0                0.000000   \n",
       "7                    0.0                     0.0                0.000000   \n",
       "8                    0.0                     0.0                0.000000   \n",
       "9                    0.0                     0.0                0.000000   \n",
       "\n",
       "   count_vectorizer__sent  count_vectorizer__servic  count_vectorizer__set  \\\n",
       "0                0.000000                  0.000000               0.000000   \n",
       "1                0.000000                  0.000000               0.000000   \n",
       "2                0.000000                  0.000000               0.000000   \n",
       "3                0.057384                  0.000000               0.061277   \n",
       "4                0.093443                  0.000000               0.000000   \n",
       "5                0.000000                  0.000000               0.000000   \n",
       "6                0.000000                  0.000000               0.000000   \n",
       "7                0.000000                  0.000000               0.000000   \n",
       "8                0.000000                  0.061269               0.000000   \n",
       "9                0.000000                  0.000000               0.000000   \n",
       "\n",
       "   count_vectorizer__shall  count_vectorizer__share  count_vectorizer__sinc  \\\n",
       "0                 0.000000                      0.0                     0.0   \n",
       "1                 0.000000                      0.0                     0.0   \n",
       "2                 0.000000                      0.0                     0.0   \n",
       "3                 0.000000                      0.0                     0.0   \n",
       "4                 0.000000                      0.0                     0.0   \n",
       "5                 0.000000                      0.0                     0.0   \n",
       "6                 0.000000                      0.0                     0.0   \n",
       "7                 0.138091                      0.0                     0.0   \n",
       "8                 0.066220                      0.0                     0.0   \n",
       "9                 0.000000                      0.0                     0.0   \n",
       "\n",
       "   count_vectorizer__sincer  count_vectorizer__sir  count_vectorizer__site  \\\n",
       "0                       0.0               0.000000                     0.0   \n",
       "1                       0.0               0.000000                     0.0   \n",
       "2                       0.0               0.000000                     0.0   \n",
       "3                       0.0               0.000000                     0.0   \n",
       "4                       0.0               0.000000                     0.0   \n",
       "5                       0.0               0.000000                     0.0   \n",
       "6                       0.0               0.000000                     0.0   \n",
       "7                       0.0               0.000000                     0.0   \n",
       "8                       0.0               0.072526                     0.0   \n",
       "9                       0.0               0.000000                     0.0   \n",
       "\n",
       "   count_vectorizer__son  count_vectorizer__soon  count_vectorizer__stand  \\\n",
       "0                    0.0                0.000000                 0.000000   \n",
       "1                    0.0                0.000000                 0.000000   \n",
       "2                    0.0                0.000000                 0.000000   \n",
       "3                    0.0                0.053951                 0.066505   \n",
       "4                    0.0                0.087853                 0.000000   \n",
       "5                    0.0                0.000000                 0.000000   \n",
       "6                    0.0                0.000000                 0.000000   \n",
       "7                    0.0                0.000000                 0.000000   \n",
       "8                    0.0                0.115372                 0.000000   \n",
       "9                    0.0                0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__start  count_vectorizer__state  count_vectorizer__still  \\\n",
       "0                 0.000000                 0.000000                 0.000000   \n",
       "1                 0.000000                 0.000000                 0.000000   \n",
       "2                 0.000000                 0.301084                 0.000000   \n",
       "3                 0.000000                 0.000000                 0.000000   \n",
       "4                 0.000000                 0.000000                 0.000000   \n",
       "5                 0.604442                 0.000000                 0.000000   \n",
       "6                 0.000000                 0.000000                 0.000000   \n",
       "7                 0.000000                 0.000000                 0.000000   \n",
       "8                 0.000000                 0.056865                 0.063435   \n",
       "9                 0.000000                 0.000000                 0.000000   \n",
       "\n",
       "   count_vectorizer__success  count_vectorizer__sum  \\\n",
       "0                   0.000000               0.000000   \n",
       "1                   0.000000               0.000000   \n",
       "2                   0.000000               0.000000   \n",
       "3                   0.061852               0.000000   \n",
       "4                   0.000000               0.000000   \n",
       "5                   0.000000               0.000000   \n",
       "6                   0.000000               0.000000   \n",
       "7                   0.000000               0.056162   \n",
       "8                   0.000000               0.053864   \n",
       "9                   0.000000               0.000000   \n",
       "\n",
       "   count_vectorizer__support  count_vectorizer__sure  \\\n",
       "0                   0.000000                0.000000   \n",
       "1                   0.000000                0.000000   \n",
       "2                   0.000000                0.000000   \n",
       "3                   0.000000                0.064638   \n",
       "4                   0.000000                0.000000   \n",
       "5                   0.000000                0.000000   \n",
       "6                   0.000000                0.000000   \n",
       "7                   0.069681                0.000000   \n",
       "8                   0.200488                0.000000   \n",
       "9                   0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__system  count_vectorizer__take  \\\n",
       "0                       0.0                0.353386   \n",
       "1                       0.0                0.000000   \n",
       "2                       0.0                0.000000   \n",
       "3                       0.0                0.000000   \n",
       "4                       0.0                0.000000   \n",
       "5                       0.0                0.000000   \n",
       "6                       0.0                0.000000   \n",
       "7                       0.0                0.000000   \n",
       "8                       0.0                0.000000   \n",
       "9                       0.0                0.000000   \n",
       "\n",
       "   count_vectorizer__telephon  count_vectorizer__th  count_vectorizer__thank  \\\n",
       "0                    0.000000                   0.0                 0.000000   \n",
       "1                    0.000000                   0.0                 0.000000   \n",
       "2                    0.000000                   0.0                 0.133740   \n",
       "3                    0.000000                   0.0                 0.000000   \n",
       "4                    0.000000                   0.0                 0.076936   \n",
       "5                    0.000000                   0.0                 0.000000   \n",
       "6                    0.000000                   0.0                 0.000000   \n",
       "7                    0.000000                   0.0                 0.000000   \n",
       "8                    0.127068                   0.0                 0.000000   \n",
       "9                    0.000000                   0.0                 0.000000   \n",
       "\n",
       "   count_vectorizer__therefor  count_vectorizer__think  \\\n",
       "0                         0.0                      0.0   \n",
       "1                         0.0                      0.0   \n",
       "2                         0.0                      0.0   \n",
       "3                         0.0                      0.0   \n",
       "4                         0.0                      0.0   \n",
       "5                         0.0                      0.0   \n",
       "6                         0.0                      0.0   \n",
       "7                         0.0                      0.0   \n",
       "8                         0.0                      0.0   \n",
       "9                         0.0                      0.0   \n",
       "\n",
       "   count_vectorizer__though  count_vectorizer__thousand  \\\n",
       "0                       0.0                         0.0   \n",
       "1                       0.0                         0.0   \n",
       "2                       0.0                         0.0   \n",
       "3                       0.0                         0.0   \n",
       "4                       0.0                         0.0   \n",
       "5                       0.0                         0.0   \n",
       "6                       0.0                         0.0   \n",
       "7                       0.0                         0.0   \n",
       "8                       0.0                         0.0   \n",
       "9                       0.0                         0.0   \n",
       "\n",
       "   count_vectorizer__time  count_vectorizer__today  count_vectorizer__told  \\\n",
       "0                0.000000                 0.000000                     0.0   \n",
       "1                0.000000                 0.000000                     0.0   \n",
       "2                0.000000                 0.750291                     0.0   \n",
       "3                0.047142                 0.000000                     0.0   \n",
       "4                0.076765                 0.000000                     0.0   \n",
       "5                0.000000                 0.000000                     0.0   \n",
       "6                0.000000                 0.000000                     0.0   \n",
       "7                0.000000                 0.000000                     0.0   \n",
       "8                0.050406                 0.000000                     0.0   \n",
       "9                0.000000                 0.000000                     0.0   \n",
       "\n",
       "   count_vectorizer__top  count_vectorizer__total  count_vectorizer__transact  \\\n",
       "0               0.000000                 0.000000                    0.000000   \n",
       "1               0.000000                 0.000000                    0.000000   \n",
       "2               0.000000                 0.000000                    0.000000   \n",
       "3               0.000000                 0.112679                    0.196439   \n",
       "4               0.000000                 0.000000                    0.000000   \n",
       "5               0.000000                 0.000000                    0.000000   \n",
       "6               0.000000                 0.000000                    0.000000   \n",
       "7               0.074454                 0.062810                    0.273751   \n",
       "8               0.071407                 0.120480                    0.052510   \n",
       "9               1.000000                 0.000000                    0.000000   \n",
       "\n",
       "   count_vectorizer__transfer  count_vectorizer__tri  count_vectorizer__trust  \\\n",
       "0                    0.000000                    0.0                 0.000000   \n",
       "1                    0.000000                    0.0                 0.000000   \n",
       "2                    0.000000                    0.0                 0.000000   \n",
       "3                    0.000000                    0.0                 0.116593   \n",
       "4                    0.000000                    0.0                 0.000000   \n",
       "5                    0.000000                    0.0                 0.000000   \n",
       "6                    0.000000                    0.0                 0.000000   \n",
       "7                    0.275359                    0.0                 0.064992   \n",
       "8                    0.052818                    0.0                 0.062333   \n",
       "9                    0.000000                    0.0                 0.000000   \n",
       "\n",
       "   count_vectorizer__two  count_vectorizer__understand  \\\n",
       "0               0.000000                      0.000000   \n",
       "1               0.000000                      0.000000   \n",
       "2               0.000000                      0.000000   \n",
       "3               0.059374                      0.129967   \n",
       "4               0.000000                      0.000000   \n",
       "5               0.000000                      0.000000   \n",
       "6               0.000000                      0.000000   \n",
       "7               0.000000                      0.000000   \n",
       "8               0.126969                      0.000000   \n",
       "9               0.000000                      0.000000   \n",
       "\n",
       "   count_vectorizer__unit  count_vectorizer__updat  count_vectorizer__upon  \\\n",
       "0                0.000000                 0.000000                0.000000   \n",
       "1                0.000000                 0.000000                0.000000   \n",
       "2                0.000000                 0.000000                0.000000   \n",
       "3                0.000000                 0.000000                0.000000   \n",
       "4                0.000000                 0.109267                0.000000   \n",
       "5                0.000000                 0.000000                0.000000   \n",
       "6                0.000000                 0.000000                0.000000   \n",
       "7                0.059200                 0.074809                0.069897   \n",
       "8                0.056777                 0.000000                0.000000   \n",
       "9                0.000000                 0.000000                0.000000   \n",
       "\n",
       "   count_vectorizer__urgent  count_vectorizer__us  count_vectorizer__use  \\\n",
       "0                       0.0              0.000000                0.00000   \n",
       "1                       0.0              0.000000                0.00000   \n",
       "2                       0.0              0.000000                0.00000   \n",
       "3                       0.0              0.000000                0.04771   \n",
       "4                       0.0              0.000000                0.00000   \n",
       "5                       0.0              0.000000                0.00000   \n",
       "6                       0.0              0.000000                0.00000   \n",
       "7                       0.0              0.000000                0.00000   \n",
       "8                       0.0              0.288979                0.00000   \n",
       "9                       0.0              0.000000                0.00000   \n",
       "\n",
       "   count_vectorizer__user  count_vectorizer__valu  count_vectorizer__via  \\\n",
       "0                0.000000                     0.0               0.000000   \n",
       "1                0.000000                     0.0               0.000000   \n",
       "2                0.000000                     0.0               0.000000   \n",
       "3                0.000000                     0.0               0.139838   \n",
       "4                0.115322                     0.0               0.000000   \n",
       "5                0.000000                     0.0               0.000000   \n",
       "6                0.000000                     0.0               0.000000   \n",
       "7                0.000000                     0.0               0.000000   \n",
       "8                0.000000                     0.0               0.000000   \n",
       "9                0.000000                     0.0               0.000000   \n",
       "\n",
       "   count_vectorizer__visit  count_vectorizer__want  count_vectorizer__way  \\\n",
       "0                      0.0                0.000000               0.000000   \n",
       "1                      0.0                0.000000               0.000000   \n",
       "2                      0.0                0.000000               0.000000   \n",
       "3                      0.0                0.143819               0.056834   \n",
       "4                      0.0                0.000000               0.000000   \n",
       "5                      0.0                0.000000               0.000000   \n",
       "6                      0.0                0.000000               0.000000   \n",
       "7                      0.0                0.000000               0.000000   \n",
       "8                      0.0                0.000000               0.000000   \n",
       "9                      0.0                0.000000               0.000000   \n",
       "\n",
       "   count_vectorizer__well  count_vectorizer__wish  count_vectorizer__within  \\\n",
       "0                 0.00000                0.000000                  0.000000   \n",
       "1                 0.00000                0.000000                  0.000000   \n",
       "2                 0.00000                0.000000                  0.000000   \n",
       "3                 0.05726                0.068590                  0.065465   \n",
       "4                 0.00000                0.000000                  0.000000   \n",
       "5                 0.00000                0.000000                  0.000000   \n",
       "6                 0.00000                0.000000                  0.000000   \n",
       "7                 0.00000                0.076468                  0.072985   \n",
       "8                 0.00000                0.000000                  0.000000   \n",
       "9                 0.00000                0.000000                  0.000000   \n",
       "\n",
       "   count_vectorizer__without  count_vectorizer__work  count_vectorizer__world  \\\n",
       "0                   0.000000                0.000000                      0.0   \n",
       "1                   0.000000                0.000000                      0.0   \n",
       "2                   0.000000                0.000000                      0.0   \n",
       "3                   0.058604                0.089233                      0.0   \n",
       "4                   0.000000                0.000000                      0.0   \n",
       "5                   0.000000                0.000000                      0.0   \n",
       "6                   0.000000                0.000000                      0.0   \n",
       "7                   0.000000                0.049741                      0.0   \n",
       "8                   0.000000                0.095411                      0.0   \n",
       "9                   0.000000                0.000000                      0.0   \n",
       "\n",
       "   count_vectorizer__would  count_vectorizer__write  count_vectorizer__wrote  \\\n",
       "0                 0.000000                  0.00000                 0.449216   \n",
       "1                 0.000000                  0.00000                 0.000000   \n",
       "2                 0.132206                  0.00000                 0.000000   \n",
       "3                 0.000000                  0.00000                 0.000000   \n",
       "4                 0.000000                  0.00000                 0.000000   \n",
       "5                 0.000000                  0.00000                 0.000000   \n",
       "6                 0.000000                  0.00000                 0.000000   \n",
       "7                 0.052069                  0.00000                 0.000000   \n",
       "8                 0.000000                  0.06811                 0.000000   \n",
       "9                 0.000000                  0.00000                 0.000000   \n",
       "\n",
       "   count_vectorizer__yahoo  count_vectorizer__year  \\\n",
       "0                 0.000000                     0.0   \n",
       "1                 0.000000                     0.0   \n",
       "2                 0.000000                     0.0   \n",
       "3                 0.064638                     0.0   \n",
       "4                 0.000000                     0.0   \n",
       "5                 0.000000                     0.0   \n",
       "6                 0.000000                     0.0   \n",
       "7                 0.000000                     0.0   \n",
       "8                 0.000000                     0.0   \n",
       "9                 0.000000                     0.0   \n",
       "\n",
       "   remainder__unsecure_link_count  remainder__secure_link_count  \\\n",
       "0                             3.0                           0.0   \n",
       "1                             0.0                           0.0   \n",
       "2                             0.0                           0.0   \n",
       "3                             0.0                           0.0   \n",
       "4                             0.0                           1.0   \n",
       "5                             0.0                           0.0   \n",
       "6                             0.0                           0.0   \n",
       "7                             0.0                           0.0   \n",
       "8                             0.0                           0.0   \n",
       "9                             0.0                           0.0   \n",
       "\n",
       "   remainder__numbers_count  remainder__word_count  \n",
       "0                       5.0                   56.0  \n",
       "1                       0.0                    3.0  \n",
       "2                       7.0                   93.0  \n",
       "3                       1.0                  680.0  \n",
       "4                      47.0                  167.0  \n",
       "5                       0.0                    8.0  \n",
       "6                       0.0                    1.0  \n",
       "7                      63.0                  409.0  \n",
       "8                      10.0                  538.0  \n",
       "9                      24.0                   43.0  "
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put the transformed x training data into a data frame\n",
    "X_train_tfidf = pd.DataFrame(\n",
    "    data=X_train_tfidf.toarray(),\n",
    "    columns=cv_transf.get_feature_names_out(),\n",
    ")\n",
    "# Check the top 10 columns of the data frame\n",
    "X_train_tfidf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f514aa12-84f4-47b4-8e54-248969ab6d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7936, 283)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the data\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "a2841c82-92d0-4bc8-a322-24beab634816",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count_vectorizer__abl</th>\n",
       "      <th>count_vectorizer__accept</th>\n",
       "      <th>count_vectorizer__access</th>\n",
       "      <th>count_vectorizer__accord</th>\n",
       "      <th>count_vectorizer__account</th>\n",
       "      <th>count_vectorizer__actual</th>\n",
       "      <th>count_vectorizer__address</th>\n",
       "      <th>count_vectorizer__agre</th>\n",
       "      <th>count_vectorizer__agreement</th>\n",
       "      <th>count_vectorizer__along</th>\n",
       "      <th>count_vectorizer__also</th>\n",
       "      <th>count_vectorizer__amount</th>\n",
       "      <th>count_vectorizer__anoth</th>\n",
       "      <th>count_vectorizer__arrang</th>\n",
       "      <th>count_vectorizer__ask</th>\n",
       "      <th>count_vectorizer__assist</th>\n",
       "      <th>count_vectorizer__assur</th>\n",
       "      <th>count_vectorizer__attent</th>\n",
       "      <th>count_vectorizer__back</th>\n",
       "      <th>count_vectorizer__bank</th>\n",
       "      <th>count_vectorizer__base</th>\n",
       "      <th>count_vectorizer__behalf</th>\n",
       "      <th>count_vectorizer__believ</th>\n",
       "      <th>count_vectorizer__beneficiari</th>\n",
       "      <th>count_vectorizer__best</th>\n",
       "      <th>count_vectorizer__bless</th>\n",
       "      <th>count_vectorizer__busi</th>\n",
       "      <th>count_vectorizer__call</th>\n",
       "      <th>count_vectorizer__care</th>\n",
       "      <th>count_vectorizer__case</th>\n",
       "      <th>count_vectorizer__chang</th>\n",
       "      <th>count_vectorizer__choos</th>\n",
       "      <th>count_vectorizer__claim</th>\n",
       "      <th>count_vectorizer__click</th>\n",
       "      <th>count_vectorizer__client</th>\n",
       "      <th>count_vectorizer__close</th>\n",
       "      <th>count_vectorizer__come</th>\n",
       "      <th>count_vectorizer__commun</th>\n",
       "      <th>count_vectorizer__compani</th>\n",
       "      <th>count_vectorizer__complet</th>\n",
       "      <th>count_vectorizer__concern</th>\n",
       "      <th>count_vectorizer__confid</th>\n",
       "      <th>count_vectorizer__confidenti</th>\n",
       "      <th>count_vectorizer__confirm</th>\n",
       "      <th>count_vectorizer__contact</th>\n",
       "      <th>count_vectorizer__corpor</th>\n",
       "      <th>count_vectorizer__could</th>\n",
       "      <th>count_vectorizer__countri</th>\n",
       "      <th>count_vectorizer__cours</th>\n",
       "      <th>count_vectorizer__current</th>\n",
       "      <th>count_vectorizer__custom</th>\n",
       "      <th>count_vectorizer__day</th>\n",
       "      <th>count_vectorizer__deal</th>\n",
       "      <th>count_vectorizer__dear</th>\n",
       "      <th>count_vectorizer__death</th>\n",
       "      <th>count_vectorizer__deceas</th>\n",
       "      <th>count_vectorizer__decid</th>\n",
       "      <th>count_vectorizer__depart</th>\n",
       "      <th>count_vectorizer__deposit</th>\n",
       "      <th>count_vectorizer__develop</th>\n",
       "      <th>count_vectorizer__direct</th>\n",
       "      <th>count_vectorizer__discov</th>\n",
       "      <th>count_vectorizer__discuss</th>\n",
       "      <th>count_vectorizer__done</th>\n",
       "      <th>count_vectorizer__due</th>\n",
       "      <th>count_vectorizer__easi</th>\n",
       "      <th>count_vectorizer__enabl</th>\n",
       "      <th>count_vectorizer__end</th>\n",
       "      <th>count_vectorizer__even</th>\n",
       "      <th>count_vectorizer__everi</th>\n",
       "      <th>count_vectorizer__execut</th>\n",
       "      <th>count_vectorizer__fact</th>\n",
       "      <th>count_vectorizer__faith</th>\n",
       "      <th>count_vectorizer__famili</th>\n",
       "      <th>count_vectorizer__father</th>\n",
       "      <th>count_vectorizer__file</th>\n",
       "      <th>count_vectorizer__final</th>\n",
       "      <th>count_vectorizer__financi</th>\n",
       "      <th>count_vectorizer__find</th>\n",
       "      <th>count_vectorizer__first</th>\n",
       "      <th>count_vectorizer__five</th>\n",
       "      <th>count_vectorizer__follow</th>\n",
       "      <th>count_vectorizer__foreign</th>\n",
       "      <th>count_vectorizer__form</th>\n",
       "      <th>count_vectorizer__former</th>\n",
       "      <th>count_vectorizer__forward</th>\n",
       "      <th>count_vectorizer__free</th>\n",
       "      <th>count_vectorizer__friend</th>\n",
       "      <th>count_vectorizer__full</th>\n",
       "      <th>count_vectorizer__fund</th>\n",
       "      <th>count_vectorizer__futur</th>\n",
       "      <th>count_vectorizer__gener</th>\n",
       "      <th>count_vectorizer__get</th>\n",
       "      <th>count_vectorizer__give</th>\n",
       "      <th>count_vectorizer__given</th>\n",
       "      <th>count_vectorizer__go</th>\n",
       "      <th>count_vectorizer__god</th>\n",
       "      <th>count_vectorizer__good</th>\n",
       "      <th>count_vectorizer__got</th>\n",
       "      <th>count_vectorizer__govern</th>\n",
       "      <th>count_vectorizer__great</th>\n",
       "      <th>count_vectorizer__group</th>\n",
       "      <th>count_vectorizer__hear</th>\n",
       "      <th>count_vectorizer__help</th>\n",
       "      <th>count_vectorizer__henc</th>\n",
       "      <th>count_vectorizer__home</th>\n",
       "      <th>count_vectorizer__hope</th>\n",
       "      <th>count_vectorizer__hous</th>\n",
       "      <th>count_vectorizer__howev</th>\n",
       "      <th>count_vectorizer__hundr</th>\n",
       "      <th>count_vectorizer__id</th>\n",
       "      <th>count_vectorizer__immedi</th>\n",
       "      <th>count_vectorizer__import</th>\n",
       "      <th>count_vectorizer__includ</th>\n",
       "      <th>count_vectorizer__inform</th>\n",
       "      <th>count_vectorizer__interest</th>\n",
       "      <th>count_vectorizer__intern</th>\n",
       "      <th>count_vectorizer__invest</th>\n",
       "      <th>count_vectorizer__involv</th>\n",
       "      <th>count_vectorizer__issu</th>\n",
       "      <th>count_vectorizer__keep</th>\n",
       "      <th>count_vectorizer__kin</th>\n",
       "      <th>count_vectorizer__know</th>\n",
       "      <th>count_vectorizer__last</th>\n",
       "      <th>count_vectorizer__late</th>\n",
       "      <th>count_vectorizer__law</th>\n",
       "      <th>count_vectorizer__leav</th>\n",
       "      <th>count_vectorizer__left</th>\n",
       "      <th>count_vectorizer__legal</th>\n",
       "      <th>count_vectorizer__let</th>\n",
       "      <th>count_vectorizer__letter</th>\n",
       "      <th>count_vectorizer__life</th>\n",
       "      <th>count_vectorizer__like</th>\n",
       "      <th>count_vectorizer__link</th>\n",
       "      <th>count_vectorizer__list</th>\n",
       "      <th>count_vectorizer__live</th>\n",
       "      <th>count_vectorizer__long</th>\n",
       "      <th>count_vectorizer__look</th>\n",
       "      <th>count_vectorizer__made</th>\n",
       "      <th>count_vectorizer__mail</th>\n",
       "      <th>count_vectorizer__mailman</th>\n",
       "      <th>count_vectorizer__make</th>\n",
       "      <th>count_vectorizer__manag</th>\n",
       "      <th>count_vectorizer__mani</th>\n",
       "      <th>count_vectorizer__matter</th>\n",
       "      <th>count_vectorizer__may</th>\n",
       "      <th>count_vectorizer__meet</th>\n",
       "      <th>count_vectorizer__member</th>\n",
       "      <th>count_vectorizer__messag</th>\n",
       "      <th>count_vectorizer__might</th>\n",
       "      <th>count_vectorizer__million</th>\n",
       "      <th>count_vectorizer__money</th>\n",
       "      <th>count_vectorizer__move</th>\n",
       "      <th>count_vectorizer__much</th>\n",
       "      <th>count_vectorizer__must</th>\n",
       "      <th>count_vectorizer__name</th>\n",
       "      <th>count_vectorizer__nation</th>\n",
       "      <th>count_vectorizer__necessari</th>\n",
       "      <th>count_vectorizer__need</th>\n",
       "      <th>count_vectorizer__net</th>\n",
       "      <th>count_vectorizer__never</th>\n",
       "      <th>count_vectorizer__new</th>\n",
       "      <th>count_vectorizer__next</th>\n",
       "      <th>count_vectorizer__note</th>\n",
       "      <th>count_vectorizer__number</th>\n",
       "      <th>count_vectorizer__offer</th>\n",
       "      <th>count_vectorizer__offic</th>\n",
       "      <th>count_vectorizer__offici</th>\n",
       "      <th>count_vectorizer__old</th>\n",
       "      <th>count_vectorizer__one</th>\n",
       "      <th>count_vectorizer__open</th>\n",
       "      <th>count_vectorizer__oper</th>\n",
       "      <th>count_vectorizer__order</th>\n",
       "      <th>count_vectorizer__part</th>\n",
       "      <th>count_vectorizer__partner</th>\n",
       "      <th>count_vectorizer__peopl</th>\n",
       "      <th>count_vectorizer__person</th>\n",
       "      <th>count_vectorizer__phone</th>\n",
       "      <th>count_vectorizer__place</th>\n",
       "      <th>count_vectorizer__pleas</th>\n",
       "      <th>count_vectorizer__polici</th>\n",
       "      <th>count_vectorizer__polit</th>\n",
       "      <th>count_vectorizer__posit</th>\n",
       "      <th>count_vectorizer__possibl</th>\n",
       "      <th>count_vectorizer__present</th>\n",
       "      <th>count_vectorizer__presid</th>\n",
       "      <th>count_vectorizer__privat</th>\n",
       "      <th>count_vectorizer__problem</th>\n",
       "      <th>count_vectorizer__process</th>\n",
       "      <th>count_vectorizer__propos</th>\n",
       "      <th>count_vectorizer__protect</th>\n",
       "      <th>count_vectorizer__provid</th>\n",
       "      <th>count_vectorizer__put</th>\n",
       "      <th>count_vectorizer__read</th>\n",
       "      <th>count_vectorizer__real</th>\n",
       "      <th>count_vectorizer__reason</th>\n",
       "      <th>count_vectorizer__receiv</th>\n",
       "      <th>count_vectorizer__recent</th>\n",
       "      <th>count_vectorizer__releas</th>\n",
       "      <th>count_vectorizer__reliabl</th>\n",
       "      <th>count_vectorizer__repli</th>\n",
       "      <th>count_vectorizer__request</th>\n",
       "      <th>count_vectorizer__reserv</th>\n",
       "      <th>count_vectorizer__respect</th>\n",
       "      <th>count_vectorizer__respons</th>\n",
       "      <th>count_vectorizer__result</th>\n",
       "      <th>count_vectorizer__right</th>\n",
       "      <th>count_vectorizer__risk</th>\n",
       "      <th>count_vectorizer__run</th>\n",
       "      <th>count_vectorizer__safe</th>\n",
       "      <th>count_vectorizer__said</th>\n",
       "      <th>count_vectorizer__say</th>\n",
       "      <th>count_vectorizer__search</th>\n",
       "      <th>count_vectorizer__secur</th>\n",
       "      <th>count_vectorizer__see</th>\n",
       "      <th>count_vectorizer__seek</th>\n",
       "      <th>count_vectorizer__send</th>\n",
       "      <th>count_vectorizer__sent</th>\n",
       "      <th>count_vectorizer__servic</th>\n",
       "      <th>count_vectorizer__set</th>\n",
       "      <th>count_vectorizer__shall</th>\n",
       "      <th>count_vectorizer__share</th>\n",
       "      <th>count_vectorizer__sinc</th>\n",
       "      <th>count_vectorizer__sincer</th>\n",
       "      <th>count_vectorizer__sir</th>\n",
       "      <th>count_vectorizer__site</th>\n",
       "      <th>count_vectorizer__son</th>\n",
       "      <th>count_vectorizer__soon</th>\n",
       "      <th>count_vectorizer__stand</th>\n",
       "      <th>count_vectorizer__start</th>\n",
       "      <th>count_vectorizer__state</th>\n",
       "      <th>count_vectorizer__still</th>\n",
       "      <th>count_vectorizer__success</th>\n",
       "      <th>count_vectorizer__sum</th>\n",
       "      <th>count_vectorizer__support</th>\n",
       "      <th>count_vectorizer__sure</th>\n",
       "      <th>count_vectorizer__system</th>\n",
       "      <th>count_vectorizer__take</th>\n",
       "      <th>count_vectorizer__telephon</th>\n",
       "      <th>count_vectorizer__th</th>\n",
       "      <th>count_vectorizer__thank</th>\n",
       "      <th>count_vectorizer__therefor</th>\n",
       "      <th>count_vectorizer__think</th>\n",
       "      <th>count_vectorizer__though</th>\n",
       "      <th>count_vectorizer__thousand</th>\n",
       "      <th>count_vectorizer__time</th>\n",
       "      <th>count_vectorizer__today</th>\n",
       "      <th>count_vectorizer__told</th>\n",
       "      <th>count_vectorizer__top</th>\n",
       "      <th>count_vectorizer__total</th>\n",
       "      <th>count_vectorizer__transact</th>\n",
       "      <th>count_vectorizer__transfer</th>\n",
       "      <th>count_vectorizer__tri</th>\n",
       "      <th>count_vectorizer__trust</th>\n",
       "      <th>count_vectorizer__two</th>\n",
       "      <th>count_vectorizer__understand</th>\n",
       "      <th>count_vectorizer__unit</th>\n",
       "      <th>count_vectorizer__updat</th>\n",
       "      <th>count_vectorizer__upon</th>\n",
       "      <th>count_vectorizer__urgent</th>\n",
       "      <th>count_vectorizer__us</th>\n",
       "      <th>count_vectorizer__use</th>\n",
       "      <th>count_vectorizer__user</th>\n",
       "      <th>count_vectorizer__valu</th>\n",
       "      <th>count_vectorizer__via</th>\n",
       "      <th>count_vectorizer__visit</th>\n",
       "      <th>count_vectorizer__want</th>\n",
       "      <th>count_vectorizer__way</th>\n",
       "      <th>count_vectorizer__well</th>\n",
       "      <th>count_vectorizer__wish</th>\n",
       "      <th>count_vectorizer__within</th>\n",
       "      <th>count_vectorizer__without</th>\n",
       "      <th>count_vectorizer__work</th>\n",
       "      <th>count_vectorizer__world</th>\n",
       "      <th>count_vectorizer__would</th>\n",
       "      <th>count_vectorizer__write</th>\n",
       "      <th>count_vectorizer__wrote</th>\n",
       "      <th>count_vectorizer__yahoo</th>\n",
       "      <th>count_vectorizer__year</th>\n",
       "      <th>remainder__unsecure_link_count</th>\n",
       "      <th>remainder__secure_link_count</th>\n",
       "      <th>remainder__numbers_count</th>\n",
       "      <th>remainder__word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count_vectorizer__abl  count_vectorizer__accept  count_vectorizer__access  \\\n",
       "0                      0                         0                         0   \n",
       "1                      0                         0                         0   \n",
       "2                      0                         0                         0   \n",
       "3                      0                         0                         0   \n",
       "4                      0                         0                         0   \n",
       "5                      0                         0                         0   \n",
       "6                      0                         0                         0   \n",
       "7                      0                         1                         0   \n",
       "8                      0                         0                         0   \n",
       "9                      0                         0                         0   \n",
       "\n",
       "   count_vectorizer__accord  count_vectorizer__account  \\\n",
       "0                         1                          7   \n",
       "1                         0                          0   \n",
       "2                         0                          3   \n",
       "3                         0                          2   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          2   \n",
       "8                         0                          1   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__actual  count_vectorizer__address  \\\n",
       "0                         1                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          1   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          0   \n",
       "8                         0                          1   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__agre  count_vectorizer__agreement  \\\n",
       "0                       0                            0   \n",
       "1                       0                            0   \n",
       "2                       1                            0   \n",
       "3                       0                            0   \n",
       "4                       0                            0   \n",
       "5                       0                            0   \n",
       "6                       0                            0   \n",
       "7                       0                            0   \n",
       "8                       0                            0   \n",
       "9                       0                            0   \n",
       "\n",
       "   count_vectorizer__along  count_vectorizer__also  count_vectorizer__amount  \\\n",
       "0                        0                       2                         1   \n",
       "1                        0                       0                         0   \n",
       "2                        0                       1                         0   \n",
       "3                        0                       2                         0   \n",
       "4                        0                       0                         0   \n",
       "5                        0                       0                         0   \n",
       "6                        0                       0                         0   \n",
       "7                        1                       0                         0   \n",
       "8                        0                       0                         0   \n",
       "9                        0                       0                         0   \n",
       "\n",
       "   count_vectorizer__anoth  count_vectorizer__arrang  count_vectorizer__ask  \\\n",
       "0                        0                         1                      1   \n",
       "1                        0                         0                      0   \n",
       "2                        0                         0                      0   \n",
       "3                        0                         0                      0   \n",
       "4                        0                         0                      0   \n",
       "5                        0                         0                      0   \n",
       "6                        0                         0                      0   \n",
       "7                        0                         0                      0   \n",
       "8                        1                         0                      0   \n",
       "9                        0                         0                      0   \n",
       "\n",
       "   count_vectorizer__assist  count_vectorizer__assur  \\\n",
       "0                         1                        0   \n",
       "1                         0                        0   \n",
       "2                         1                        0   \n",
       "3                         1                        0   \n",
       "4                         0                        0   \n",
       "5                         0                        0   \n",
       "6                         0                        0   \n",
       "7                         0                        0   \n",
       "8                         2                        0   \n",
       "9                         0                        0   \n",
       "\n",
       "   count_vectorizer__attent  count_vectorizer__back  count_vectorizer__bank  \\\n",
       "0                         0                       0                       9   \n",
       "1                         0                       0                       1   \n",
       "2                         0                       0                       1   \n",
       "3                         0                       2                       3   \n",
       "4                         0                       0                       4   \n",
       "5                         0                       0                       0   \n",
       "6                         0                       0                       0   \n",
       "7                         0                       1                       6   \n",
       "8                         0                       0                       3   \n",
       "9                         0                       0                       0   \n",
       "\n",
       "   count_vectorizer__base  count_vectorizer__behalf  count_vectorizer__believ  \\\n",
       "0                       0                         0                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       1                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       0                         0                         0   \n",
       "5                       0                         0                         0   \n",
       "6                       0                         0                         0   \n",
       "7                       0                         0                         0   \n",
       "8                       0                         0                         0   \n",
       "9                       0                         0                         0   \n",
       "\n",
       "   count_vectorizer__beneficiari  count_vectorizer__best  \\\n",
       "0                              0                       0   \n",
       "1                              0                       0   \n",
       "2                              0                       0   \n",
       "3                              0                       0   \n",
       "4                              0                       0   \n",
       "5                              0                       0   \n",
       "6                              0                       0   \n",
       "7                              0                       0   \n",
       "8                              3                       1   \n",
       "9                              0                       0   \n",
       "\n",
       "   count_vectorizer__bless  count_vectorizer__busi  count_vectorizer__call  \\\n",
       "0                        0                       2                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       1                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "5                        0                       0                       0   \n",
       "6                        0                       0                       0   \n",
       "7                        0                       1                       0   \n",
       "8                        0                       1                       0   \n",
       "9                        0                       0                       0   \n",
       "\n",
       "   count_vectorizer__care  count_vectorizer__case  count_vectorizer__chang  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       0                       0                        0   \n",
       "4                       0                       0                        0   \n",
       "5                       0                       0                        0   \n",
       "6                       0                       0                        0   \n",
       "7                       0                       0                        0   \n",
       "8                       0                       0                        0   \n",
       "9                       0                       0                        0   \n",
       "\n",
       "   count_vectorizer__choos  count_vectorizer__claim  count_vectorizer__click  \\\n",
       "0                        0                        2                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "5                        0                        0                        0   \n",
       "6                        0                        0                        0   \n",
       "7                        0                        2                        0   \n",
       "8                        0                        0                        0   \n",
       "9                        0                        0                        0   \n",
       "\n",
       "   count_vectorizer__client  count_vectorizer__close  count_vectorizer__come  \\\n",
       "0                         0                        0                       1   \n",
       "1                         0                        0                       0   \n",
       "2                         0                        0                       0   \n",
       "3                         0                        0                       1   \n",
       "4                         0                        0                       0   \n",
       "5                         0                        0                       0   \n",
       "6                         0                        0                       0   \n",
       "7                         0                        0                       1   \n",
       "8                         0                        0                       0   \n",
       "9                         0                        0                       0   \n",
       "\n",
       "   count_vectorizer__commun  count_vectorizer__compani  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         1                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__complet  count_vectorizer__concern  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__confid  count_vectorizer__confidenti  \\\n",
       "0                         0                             0   \n",
       "1                         0                             0   \n",
       "2                         0                             1   \n",
       "3                         0                             2   \n",
       "4                         0                             0   \n",
       "5                         0                             0   \n",
       "6                         0                             0   \n",
       "7                         0                             0   \n",
       "8                         0                             0   \n",
       "9                         0                             0   \n",
       "\n",
       "   count_vectorizer__confirm  count_vectorizer__contact  \\\n",
       "0                          1                          2   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          6                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__corpor  count_vectorizer__could  \\\n",
       "0                         0                        1   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "5                         0                        0   \n",
       "6                         0                        0   \n",
       "7                         0                        0   \n",
       "8                         0                        0   \n",
       "9                         0                        0   \n",
       "\n",
       "   count_vectorizer__countri  count_vectorizer__cours  \\\n",
       "0                          3                        0   \n",
       "1                          0                        0   \n",
       "2                          1                        0   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "5                          0                        0   \n",
       "6                          0                        0   \n",
       "7                          0                        0   \n",
       "8                          5                        0   \n",
       "9                          0                        0   \n",
       "\n",
       "   count_vectorizer__current  count_vectorizer__custom  count_vectorizer__day  \\\n",
       "0                          0                         0                      0   \n",
       "1                          0                         0                      0   \n",
       "2                          0                         0                      0   \n",
       "3                          0                         0                      0   \n",
       "4                          0                         2                      0   \n",
       "5                          0                         0                      0   \n",
       "6                          0                         0                      0   \n",
       "7                          0                         2                      0   \n",
       "8                          0                         0                      0   \n",
       "9                          0                         0                      0   \n",
       "\n",
       "   count_vectorizer__deal  count_vectorizer__dear  count_vectorizer__death  \\\n",
       "0                       2                       1                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       0                        0   \n",
       "3                       0                       1                        0   \n",
       "4                       0                       2                        0   \n",
       "5                       0                       0                        0   \n",
       "6                       0                       0                        0   \n",
       "7                       2                       1                        1   \n",
       "8                       0                       0                        3   \n",
       "9                       0                       0                        0   \n",
       "\n",
       "   count_vectorizer__deceas  count_vectorizer__decid  \\\n",
       "0                         2                        1   \n",
       "1                         0                        0   \n",
       "2                         0                        0   \n",
       "3                         0                        0   \n",
       "4                         0                        0   \n",
       "5                         0                        0   \n",
       "6                         0                        0   \n",
       "7                         1                        0   \n",
       "8                         0                        0   \n",
       "9                         0                        0   \n",
       "\n",
       "   count_vectorizer__depart  count_vectorizer__deposit  \\\n",
       "0                         2                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          1   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         2                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__develop  count_vectorizer__direct  \\\n",
       "0                          4                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         0   \n",
       "5                          0                         0   \n",
       "6                          0                         0   \n",
       "7                          1                         0   \n",
       "8                          0                         0   \n",
       "9                          0                         0   \n",
       "\n",
       "   count_vectorizer__discov  count_vectorizer__discuss  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         1                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__done  count_vectorizer__due  count_vectorizer__easi  \\\n",
       "0                       1                      2                       0   \n",
       "1                       0                      0                       0   \n",
       "2                       0                      0                       1   \n",
       "3                       0                      0                       0   \n",
       "4                       0                      0                       0   \n",
       "5                       0                      0                       0   \n",
       "6                       0                      0                       0   \n",
       "7                       0                      0                       1   \n",
       "8                       0                      2                       0   \n",
       "9                       0                      0                       0   \n",
       "\n",
       "   count_vectorizer__enabl  count_vectorizer__end  count_vectorizer__even  \\\n",
       "0                        0                      1                       0   \n",
       "1                        0                      0                       0   \n",
       "2                        0                      0                       0   \n",
       "3                        0                      0                       0   \n",
       "4                        0                      0                       0   \n",
       "5                        0                      0                       0   \n",
       "6                        0                      0                       0   \n",
       "7                        0                      1                       0   \n",
       "8                        0                      0                       0   \n",
       "9                        0                      0                       0   \n",
       "\n",
       "   count_vectorizer__everi  count_vectorizer__execut  count_vectorizer__fact  \\\n",
       "0                        0                         0                       1   \n",
       "1                        0                         0                       0   \n",
       "2                        0                         0                       0   \n",
       "3                        0                         0                       0   \n",
       "4                        0                         0                       0   \n",
       "5                        0                         0                       0   \n",
       "6                        0                         0                       0   \n",
       "7                        0                         0                       1   \n",
       "8                        0                         0                       0   \n",
       "9                        0                         0                       0   \n",
       "\n",
       "   count_vectorizer__faith  count_vectorizer__famili  \\\n",
       "0                        1                         1   \n",
       "1                        0                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "5                        0                         0   \n",
       "6                        0                         0   \n",
       "7                        0                         1   \n",
       "8                        0                         0   \n",
       "9                        0                         0   \n",
       "\n",
       "   count_vectorizer__father  count_vectorizer__file  count_vectorizer__final  \\\n",
       "0                         0                       0                        0   \n",
       "1                         0                       0                        0   \n",
       "2                         0                       0                        0   \n",
       "3                         0                       0                        1   \n",
       "4                         0                       0                        0   \n",
       "5                         0                       0                        0   \n",
       "6                         0                       0                        0   \n",
       "7                         0                       0                        0   \n",
       "8                         4                       0                        0   \n",
       "9                         0                       0                        0   \n",
       "\n",
       "   count_vectorizer__financi  count_vectorizer__find  count_vectorizer__first  \\\n",
       "0                          0                       0                        0   \n",
       "1                          0                       0                        0   \n",
       "2                          0                       0                        0   \n",
       "3                          0                       0                        1   \n",
       "4                          0                       0                        0   \n",
       "5                          0                       0                        1   \n",
       "6                          0                       0                        0   \n",
       "7                          0                       0                        0   \n",
       "8                          0                       0                        0   \n",
       "9                          0                       0                        0   \n",
       "\n",
       "   count_vectorizer__five  count_vectorizer__follow  \\\n",
       "0                       0                         0   \n",
       "1                       0                         0   \n",
       "2                       0                         2   \n",
       "3                       0                         0   \n",
       "4                       0                         2   \n",
       "5                       0                         0   \n",
       "6                       0                         0   \n",
       "7                       1                         0   \n",
       "8                       0                         1   \n",
       "9                       0                         0   \n",
       "\n",
       "   count_vectorizer__foreign  count_vectorizer__form  \\\n",
       "0                          3                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       0   \n",
       "3                          0                       0   \n",
       "4                          0                       0   \n",
       "5                          0                       0   \n",
       "6                          0                       0   \n",
       "7                          4                       0   \n",
       "8                          2                       0   \n",
       "9                          0                       0   \n",
       "\n",
       "   count_vectorizer__former  count_vectorizer__forward  \\\n",
       "0                         0                          1   \n",
       "1                         0                          0   \n",
       "2                         0                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         0                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__free  count_vectorizer__friend  count_vectorizer__full  \\\n",
       "0                       1                         0                       0   \n",
       "1                       0                         0                       0   \n",
       "2                       0                         1                       1   \n",
       "3                       0                         1                       0   \n",
       "4                       0                         0                       0   \n",
       "5                       0                         0                       0   \n",
       "6                       0                         0                       0   \n",
       "7                       0                         1                       0   \n",
       "8                       0                         0                       0   \n",
       "9                       0                         0                       0   \n",
       "\n",
       "   count_vectorizer__fund  count_vectorizer__futur  count_vectorizer__gener  \\\n",
       "0                       4                        0                        0   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        0   \n",
       "3                       2                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "5                       0                        0                        0   \n",
       "6                       0                        0                        0   \n",
       "7                       3                        0                        0   \n",
       "8                       2                        0                        0   \n",
       "9                       0                        0                        0   \n",
       "\n",
       "   count_vectorizer__get  count_vectorizer__give  count_vectorizer__given  \\\n",
       "0                      1                       0                        0   \n",
       "1                      0                       0                        0   \n",
       "2                      1                       2                        0   \n",
       "3                      0                       1                        0   \n",
       "4                      0                       0                        0   \n",
       "5                      0                       0                        0   \n",
       "6                      0                       0                        0   \n",
       "7                      1                       1                        0   \n",
       "8                      1                       0                        0   \n",
       "9                      0                       0                        0   \n",
       "\n",
       "   count_vectorizer__go  count_vectorizer__god  count_vectorizer__good  \\\n",
       "0                     0                      0                       0   \n",
       "1                     0                      0                       0   \n",
       "2                     0                      0                       0   \n",
       "3                     0                      0                       0   \n",
       "4                     0                      0                       0   \n",
       "5                     0                      0                       0   \n",
       "6                     0                      0                       1   \n",
       "7                     0                      0                       0   \n",
       "8                     0                      0                       0   \n",
       "9                     0                      0                       0   \n",
       "\n",
       "   count_vectorizer__got  count_vectorizer__govern  count_vectorizer__great  \\\n",
       "0                      1                         0                        1   \n",
       "1                      0                         0                        0   \n",
       "2                      0                         0                        0   \n",
       "3                      0                         0                        0   \n",
       "4                      0                         0                        0   \n",
       "5                      0                         0                        0   \n",
       "6                      0                         0                        0   \n",
       "7                      1                         0                        0   \n",
       "8                      0                         0                        0   \n",
       "9                      0                         0                        0   \n",
       "\n",
       "   count_vectorizer__group  count_vectorizer__hear  count_vectorizer__help  \\\n",
       "0                        0                       2                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        0                       0                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "5                        0                       0                       0   \n",
       "6                        0                       0                       0   \n",
       "7                        0                       0                       0   \n",
       "8                        0                       0                       1   \n",
       "9                        0                       0                       0   \n",
       "\n",
       "   count_vectorizer__henc  count_vectorizer__home  count_vectorizer__hope  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "5                       0                       0                       0   \n",
       "6                       0                       0                       0   \n",
       "7                       0                       0                       0   \n",
       "8                       0                       0                       0   \n",
       "9                       0                       0                       0   \n",
       "\n",
       "   count_vectorizer__hous  count_vectorizer__howev  count_vectorizer__hundr  \\\n",
       "0                       0                        0                        1   \n",
       "1                       0                        0                        0   \n",
       "2                       0                        0                        1   \n",
       "3                       0                        0                        0   \n",
       "4                       0                        0                        0   \n",
       "5                       0                        0                        0   \n",
       "6                       0                        0                        0   \n",
       "7                       0                        0                        1   \n",
       "8                       1                        0                        0   \n",
       "9                       0                        0                        0   \n",
       "\n",
       "   count_vectorizer__id  count_vectorizer__immedi  count_vectorizer__import  \\\n",
       "0                     0                         0                         0   \n",
       "1                     0                         0                         0   \n",
       "2                     0                         0                         2   \n",
       "3                     0                         0                         0   \n",
       "4                     0                         0                         0   \n",
       "5                     0                         0                         0   \n",
       "6                     0                         0                         0   \n",
       "7                     0                         0                         0   \n",
       "8                     0                         0                         2   \n",
       "9                     0                         0                         0   \n",
       "\n",
       "   count_vectorizer__includ  count_vectorizer__inform  \\\n",
       "0                         0                         4   \n",
       "1                         0                         0   \n",
       "2                         0                         1   \n",
       "3                         0                         1   \n",
       "4                         0                         0   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         1   \n",
       "8                         0                         1   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__interest  count_vectorizer__intern  \\\n",
       "0                           2                         1   \n",
       "1                           0                         0   \n",
       "2                           1                         0   \n",
       "3                           1                         0   \n",
       "4                           0                         0   \n",
       "5                           0                         0   \n",
       "6                           0                         0   \n",
       "7                           0                         1   \n",
       "8                           1                         0   \n",
       "9                           0                         0   \n",
       "\n",
       "   count_vectorizer__invest  count_vectorizer__involv  count_vectorizer__issu  \\\n",
       "0                         2                         0                       0   \n",
       "1                         0                         0                       0   \n",
       "2                         0                         0                       0   \n",
       "3                         0                         0                       0   \n",
       "4                         0                         0                       0   \n",
       "5                         0                         0                       0   \n",
       "6                         0                         0                       0   \n",
       "7                         0                         0                       0   \n",
       "8                         3                         0                       0   \n",
       "9                         0                         0                       0   \n",
       "\n",
       "   count_vectorizer__keep  count_vectorizer__kin  count_vectorizer__know  \\\n",
       "0                       1                      2                       1   \n",
       "1                       0                      0                       0   \n",
       "2                       0                      1                       0   \n",
       "3                       1                      0                       0   \n",
       "4                       0                      0                       0   \n",
       "5                       0                      0                       0   \n",
       "6                       0                      0                       0   \n",
       "7                       0                      5                       0   \n",
       "8                       0                      0                       0   \n",
       "9                       0                      0                       0   \n",
       "\n",
       "   count_vectorizer__last  count_vectorizer__late  count_vectorizer__law  \\\n",
       "0                       0                       0                      0   \n",
       "1                       0                       0                      0   \n",
       "2                       1                       1                      0   \n",
       "3                       1                       1                      0   \n",
       "4                       0                       0                      0   \n",
       "5                       0                       0                      0   \n",
       "6                       0                       0                      0   \n",
       "7                       0                       0                      1   \n",
       "8                       2                       2                      0   \n",
       "9                       0                       0                      0   \n",
       "\n",
       "   count_vectorizer__leav  count_vectorizer__left  count_vectorizer__legal  \\\n",
       "0                       0                       0                        0   \n",
       "1                       0                       0                        0   \n",
       "2                       0                       1                        0   \n",
       "3                       0                       0                        0   \n",
       "4                       0                       0                        0   \n",
       "5                       0                       0                        0   \n",
       "6                       0                       0                        0   \n",
       "7                       1                       0                        0   \n",
       "8                       0                       0                        0   \n",
       "9                       0                       0                        0   \n",
       "\n",
       "   count_vectorizer__let  count_vectorizer__letter  count_vectorizer__life  \\\n",
       "0                      0                         0                       0   \n",
       "1                      0                         0                       0   \n",
       "2                      0                         1                       0   \n",
       "3                      0                         0                       0   \n",
       "4                      0                         0                       0   \n",
       "5                      0                         0                       0   \n",
       "6                      0                         0                       0   \n",
       "7                      0                         0                       0   \n",
       "8                      1                         3                       1   \n",
       "9                      0                         0                       0   \n",
       "\n",
       "   count_vectorizer__like  count_vectorizer__link  count_vectorizer__list  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       0                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       2                       0   \n",
       "5                       1                       0                       0   \n",
       "6                       0                       0                       0   \n",
       "7                       0                       0                       0   \n",
       "8                       1                       0                       0   \n",
       "9                       0                       0                       0   \n",
       "\n",
       "   count_vectorizer__live  count_vectorizer__long  count_vectorizer__look  \\\n",
       "0                       0                       0                       0   \n",
       "1                       0                       0                       0   \n",
       "2                       1                       0                       0   \n",
       "3                       0                       0                       0   \n",
       "4                       0                       0                       0   \n",
       "5                       0                       0                       0   \n",
       "6                       0                       0                       0   \n",
       "7                       0                       0                       0   \n",
       "8                       0                       0                       0   \n",
       "9                       0                       0                       0   \n",
       "\n",
       "   count_vectorizer__made  count_vectorizer__mail  count_vectorizer__mailman  \\\n",
       "0                       0                       0                          0   \n",
       "1                       0                       0                          1   \n",
       "2                       0                       1                          0   \n",
       "3                       1                       0                          0   \n",
       "4                       0                       2                          0   \n",
       "5                       0                       0                          0   \n",
       "6                       0                       0                          0   \n",
       "7                       0                       0                          0   \n",
       "8                       0                       0                          0   \n",
       "9                       0                       0                          0   \n",
       "\n",
       "   count_vectorizer__make  count_vectorizer__manag  count_vectorizer__mani  \\\n",
       "0                       0                        2                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       0                        2                       0   \n",
       "3                       0                        2                       0   \n",
       "4                       0                        6                       0   \n",
       "5                       0                        0                       0   \n",
       "6                       0                        0                       0   \n",
       "7                       0                        1                       0   \n",
       "8                       0                        0                       0   \n",
       "9                       0                        0                       0   \n",
       "\n",
       "   count_vectorizer__matter  count_vectorizer__may  count_vectorizer__meet  \\\n",
       "0                         0                      2                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      1                       0   \n",
       "3                         0                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "5                         0                      0                       0   \n",
       "6                         0                      0                       0   \n",
       "7                         0                      0                       0   \n",
       "8                         0                      0                       0   \n",
       "9                         0                      0                       0   \n",
       "\n",
       "   count_vectorizer__member  count_vectorizer__messag  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         2   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         0   \n",
       "8                         0                         0   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__might  count_vectorizer__million  \\\n",
       "0                        0                          1   \n",
       "1                        0                          0   \n",
       "2                        0                          2   \n",
       "3                        0                          1   \n",
       "4                        0                          0   \n",
       "5                        0                          0   \n",
       "6                        0                          0   \n",
       "7                        1                          1   \n",
       "8                        0                          1   \n",
       "9                        0                          0   \n",
       "\n",
       "   count_vectorizer__money  count_vectorizer__move  count_vectorizer__much  \\\n",
       "0                        5                       0                       0   \n",
       "1                        0                       0                       0   \n",
       "2                        1                       0                       0   \n",
       "3                        0                       0                       0   \n",
       "4                        0                       0                       0   \n",
       "5                        0                       0                       0   \n",
       "6                        0                       0                       0   \n",
       "7                        4                       0                       0   \n",
       "8                        6                       0                       0   \n",
       "9                        0                       0                       0   \n",
       "\n",
       "   count_vectorizer__must  count_vectorizer__name  count_vectorizer__nation  \\\n",
       "0                       0                       0                         0   \n",
       "1                       0                       0                         0   \n",
       "2                       0                       0                         0   \n",
       "3                       1                       0                         0   \n",
       "4                       0                       0                         0   \n",
       "5                       0                       0                         0   \n",
       "6                       0                       0                         0   \n",
       "7                       0                       0                         0   \n",
       "8                       0                       4                         0   \n",
       "9                       0                       0                         0   \n",
       "\n",
       "   count_vectorizer__necessari  count_vectorizer__need  count_vectorizer__net  \\\n",
       "0                            1                       1                      0   \n",
       "1                            0                       0                      0   \n",
       "2                            0                       0                      0   \n",
       "3                            0                       0                      0   \n",
       "4                            0                       0                      0   \n",
       "5                            0                       0                      0   \n",
       "6                            0                       0                      0   \n",
       "7                            0                       0                      0   \n",
       "8                            0                       1                      0   \n",
       "9                            0                       0                      0   \n",
       "\n",
       "   count_vectorizer__never  count_vectorizer__new  count_vectorizer__next  \\\n",
       "0                        0                      0                       2   \n",
       "1                        0                      0                       0   \n",
       "2                        0                      0                       1   \n",
       "3                        0                      0                       0   \n",
       "4                        0                      0                       0   \n",
       "5                        0                      0                       0   \n",
       "6                        0                      0                       0   \n",
       "7                        0                      0                       5   \n",
       "8                        0                      0                       0   \n",
       "9                        0                      0                       0   \n",
       "\n",
       "   count_vectorizer__note  count_vectorizer__number  count_vectorizer__offer  \\\n",
       "0                       0                         1                        0   \n",
       "1                       0                         0                        0   \n",
       "2                       1                         1                        0   \n",
       "3                       1                         2                        0   \n",
       "4                       0                         0                        0   \n",
       "5                       0                         1                        0   \n",
       "6                       0                         0                        0   \n",
       "7                       0                         0                        0   \n",
       "8                       0                         0                        0   \n",
       "9                       0                         0                        0   \n",
       "\n",
       "   count_vectorizer__offic  count_vectorizer__offici  count_vectorizer__old  \\\n",
       "0                        0                         0                      0   \n",
       "1                        0                         0                      0   \n",
       "2                        0                         0                      1   \n",
       "3                        1                         0                      0   \n",
       "4                        0                         0                      0   \n",
       "5                        0                         0                      0   \n",
       "6                        0                         0                      0   \n",
       "7                        0                         0                      0   \n",
       "8                        0                         0                      1   \n",
       "9                        0                         0                      0   \n",
       "\n",
       "   count_vectorizer__one  count_vectorizer__open  count_vectorizer__oper  \\\n",
       "0                      1                       0                       1   \n",
       "1                      0                       0                       0   \n",
       "2                      1                       0                       2   \n",
       "3                      0                       0                       0   \n",
       "4                      0                       2                       0   \n",
       "5                      0                       0                       0   \n",
       "6                      0                       0                       0   \n",
       "7                      1                       0                       0   \n",
       "8                      1                       0                       0   \n",
       "9                      0                       0                       0   \n",
       "\n",
       "   count_vectorizer__order  count_vectorizer__part  count_vectorizer__partner  \\\n",
       "0                        0                       0                          1   \n",
       "1                        0                       0                          0   \n",
       "2                        0                       0                          0   \n",
       "3                        0                       0                          1   \n",
       "4                        0                       0                          0   \n",
       "5                        0                       0                          0   \n",
       "6                        0                       0                          0   \n",
       "7                        0                       0                          1   \n",
       "8                        1                       0                          3   \n",
       "9                        0                       0                          0   \n",
       "\n",
       "   count_vectorizer__peopl  count_vectorizer__person  count_vectorizer__phone  \\\n",
       "0                        0                         1                        0   \n",
       "1                        0                         0                        0   \n",
       "2                        0                         1                        0   \n",
       "3                        0                         1                        0   \n",
       "4                        0                         0                        0   \n",
       "5                        0                         0                        0   \n",
       "6                        0                         0                        0   \n",
       "7                        0                         1                        0   \n",
       "8                        0                         0                        0   \n",
       "9                        0                         0                        0   \n",
       "\n",
       "   count_vectorizer__place  count_vectorizer__pleas  count_vectorizer__polici  \\\n",
       "0                        1                        1                         0   \n",
       "1                        0                        0                         0   \n",
       "2                        0                        2                         0   \n",
       "3                        0                        4                         0   \n",
       "4                        0                        4                         0   \n",
       "5                        0                        0                         0   \n",
       "6                        0                        0                         0   \n",
       "7                        0                        0                         0   \n",
       "8                        1                        1                         0   \n",
       "9                        0                        0                         0   \n",
       "\n",
       "   count_vectorizer__polit  count_vectorizer__posit  \\\n",
       "0                        0                        1   \n",
       "1                        0                        0   \n",
       "2                        0                        0   \n",
       "3                        0                        0   \n",
       "4                        0                        0   \n",
       "5                        0                        0   \n",
       "6                        0                        0   \n",
       "7                        0                        0   \n",
       "8                        1                        0   \n",
       "9                        0                        0   \n",
       "\n",
       "   count_vectorizer__possibl  count_vectorizer__present  \\\n",
       "0                          0                          1   \n",
       "1                          0                          0   \n",
       "2                          0                          1   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__presid  count_vectorizer__privat  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         1   \n",
       "8                         0                         1   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__problem  count_vectorizer__process  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          1   \n",
       "8                          0                          0   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__propos  count_vectorizer__protect  \\\n",
       "0                         0                          0   \n",
       "1                         0                          0   \n",
       "2                         1                          0   \n",
       "3                         0                          0   \n",
       "4                         0                          0   \n",
       "5                         0                          0   \n",
       "6                         0                          0   \n",
       "7                         1                          0   \n",
       "8                         0                          0   \n",
       "9                         0                          0   \n",
       "\n",
       "   count_vectorizer__provid  count_vectorizer__put  count_vectorizer__read  \\\n",
       "0                         0                      2                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      0                       0   \n",
       "3                         2                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "5                         0                      0                       0   \n",
       "6                         0                      0                       0   \n",
       "7                         0                      0                       0   \n",
       "8                         1                      0                       0   \n",
       "9                         0                      0                       0   \n",
       "\n",
       "   count_vectorizer__real  count_vectorizer__reason  count_vectorizer__receiv  \\\n",
       "0                       0                         1                         0   \n",
       "1                       0                         0                         0   \n",
       "2                       0                         0                         0   \n",
       "3                       0                         0                         0   \n",
       "4                       0                         0                         0   \n",
       "5                       0                         0                         1   \n",
       "6                       0                         0                         0   \n",
       "7                       0                         0                         0   \n",
       "8                       0                         0                         1   \n",
       "9                       0                         0                         0   \n",
       "\n",
       "   count_vectorizer__recent  count_vectorizer__releas  \\\n",
       "0                         0                         0   \n",
       "1                         0                         0   \n",
       "2                         0                         0   \n",
       "3                         0                         0   \n",
       "4                         0                         0   \n",
       "5                         0                         0   \n",
       "6                         0                         0   \n",
       "7                         0                         0   \n",
       "8                         0                         0   \n",
       "9                         0                         0   \n",
       "\n",
       "   count_vectorizer__reliabl  count_vectorizer__repli  \\\n",
       "0                          0                        0   \n",
       "1                          0                        0   \n",
       "2                          0                        3   \n",
       "3                          0                        0   \n",
       "4                          0                        0   \n",
       "5                          0                        0   \n",
       "6                          0                        0   \n",
       "7                          0                        0   \n",
       "8                          0                        0   \n",
       "9                          0                        0   \n",
       "\n",
       "   count_vectorizer__request  count_vectorizer__reserv  \\\n",
       "0                          1                         0   \n",
       "1                          0                         0   \n",
       "2                          0                         0   \n",
       "3                          0                         0   \n",
       "4                          0                         2   \n",
       "5                          0                         0   \n",
       "6                          0                         0   \n",
       "7                          1                         0   \n",
       "8                          0                         0   \n",
       "9                          0                         0   \n",
       "\n",
       "   count_vectorizer__respect  count_vectorizer__respons  \\\n",
       "0                          1                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "5                          0                          0   \n",
       "6                          0                          0   \n",
       "7                          0                          0   \n",
       "8                          0                          1   \n",
       "9                          0                          0   \n",
       "\n",
       "   count_vectorizer__result  count_vectorizer__right  count_vectorizer__risk  \\\n",
       "0                         0                        0                       1   \n",
       "1                         0                        0                       0   \n",
       "2                         0                        0                       0   \n",
       "3                         0                        0                       0   \n",
       "4                         0                        0                       0   \n",
       "5                         0                        0                       0   \n",
       "6                         0                        0                       0   \n",
       "7                         0                        0                       0   \n",
       "8                         0                        0                       0   \n",
       "9                         0                        0                       0   \n",
       "\n",
       "   count_vectorizer__run  count_vectorizer__safe  count_vectorizer__said  \\\n",
       "0                      0                       0                       1   \n",
       "1                      0                       0                       0   \n",
       "2                      0                       0                       0   \n",
       "3                      0                       0                       0   \n",
       "4                      0                       0                       0   \n",
       "5                      0                       0                       0   \n",
       "6                      0                       0                       1   \n",
       "7                      0                       0                       0   \n",
       "8                      1                       0                       1   \n",
       "9                      0                       0                       0   \n",
       "\n",
       "   count_vectorizer__say  count_vectorizer__search  count_vectorizer__secur  \\\n",
       "0                      0                         1                        0   \n",
       "1                      0                         0                        0   \n",
       "2                      0                         0                        0   \n",
       "3                      0                         1                        0   \n",
       "4                      0                         0                        0   \n",
       "5                      0                         0                        0   \n",
       "6                      0                         0                        0   \n",
       "7                      0                         0                        0   \n",
       "8                      0                         0                        0   \n",
       "9                      0                         0                        0   \n",
       "\n",
       "   count_vectorizer__see  count_vectorizer__seek  count_vectorizer__send  \\\n",
       "0                      0                       0                       0   \n",
       "1                      1                       0                       0   \n",
       "2                      0                       0                       0   \n",
       "3                      0                       0                       0   \n",
       "4                      0                       0                       0   \n",
       "5                      0                       0                       0   \n",
       "6                      0                       0                       0   \n",
       "7                      0                       0                       0   \n",
       "8                      0                       0                       1   \n",
       "9                      0                       0                       0   \n",
       "\n",
       "   count_vectorizer__sent  count_vectorizer__servic  count_vectorizer__set  \\\n",
       "0                       1                         2                      0   \n",
       "1                       0                         0                      0   \n",
       "2                       0                         0                      0   \n",
       "3                       0                         0                      0   \n",
       "4                       0                         0                      0   \n",
       "5                       0                         0                      0   \n",
       "6                       1                         0                      0   \n",
       "7                       0                         0                      1   \n",
       "8                       0                         0                      0   \n",
       "9                       0                         0                      0   \n",
       "\n",
       "   count_vectorizer__shall  count_vectorizer__share  count_vectorizer__sinc  \\\n",
       "0                        0                        0                       0   \n",
       "1                        0                        0                       0   \n",
       "2                        0                        0                       0   \n",
       "3                        0                        0                       1   \n",
       "4                        0                        0                       0   \n",
       "5                        0                        0                       0   \n",
       "6                        0                        0                       0   \n",
       "7                        0                        0                       1   \n",
       "8                        0                        1                       0   \n",
       "9                        0                        0                       0   \n",
       "\n",
       "   count_vectorizer__sincer  count_vectorizer__sir  count_vectorizer__site  \\\n",
       "0                         0                      0                       0   \n",
       "1                         0                      0                       0   \n",
       "2                         0                      0                       0   \n",
       "3                         0                      0                       0   \n",
       "4                         0                      0                       0   \n",
       "5                         0                      0                       0   \n",
       "6                         0                      0                       0   \n",
       "7                         0                      0                       0   \n",
       "8                         0                      0                       0   \n",
       "9                         0                      0                       0   \n",
       "\n",
       "   count_vectorizer__son  count_vectorizer__soon  count_vectorizer__stand  \\\n",
       "0                      0                       1                        0   \n",
       "1                      0                       0                        0   \n",
       "2                      0                       0                        0   \n",
       "3                      0                       0                        0   \n",
       "4                      0                       0                        0   \n",
       "5                      0                       0                        0   \n",
       "6                      0                       0                        0   \n",
       "7                      0                       0                        1   \n",
       "8                      0                       0                        1   \n",
       "9                      0                       0                        0   \n",
       "\n",
       "   count_vectorizer__start  count_vectorizer__state  count_vectorizer__still  \\\n",
       "0                        0                        0                        1   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        0                        0   \n",
       "4                        0                        0                        0   \n",
       "5                        0                        0                        0   \n",
       "6                        0                        0                        0   \n",
       "7                        0                        0                        0   \n",
       "8                        0                        1                        0   \n",
       "9                        0                        0                        0   \n",
       "\n",
       "   count_vectorizer__success  count_vectorizer__sum  \\\n",
       "0                          0                      2   \n",
       "1                          0                      0   \n",
       "2                          0                      0   \n",
       "3                          0                      0   \n",
       "4                          0                      0   \n",
       "5                          0                      0   \n",
       "6                          0                      0   \n",
       "7                          0                      1   \n",
       "8                          0                      1   \n",
       "9                          0                      0   \n",
       "\n",
       "   count_vectorizer__support  count_vectorizer__sure  \\\n",
       "0                          0                       0   \n",
       "1                          0                       0   \n",
       "2                          0                       0   \n",
       "3                          0                       0   \n",
       "4                          0                       0   \n",
       "5                          0                       0   \n",
       "6                          0                       0   \n",
       "7                          0                       0   \n",
       "8                          0                       0   \n",
       "9                          0                       0   \n",
       "\n",
       "   count_vectorizer__system  count_vectorizer__take  \\\n",
       "0                         0                       0   \n",
       "1                         0                       0   \n",
       "2                         0                       0   \n",
       "3                         0                       0   \n",
       "4                         0                       0   \n",
       "5                         0                       0   \n",
       "6                         0                       0   \n",
       "7                         0                       0   \n",
       "8                         0                       0   \n",
       "9                         0                       0   \n",
       "\n",
       "   count_vectorizer__telephon  count_vectorizer__th  count_vectorizer__thank  \\\n",
       "0                           0                     0                        0   \n",
       "1                           0                     0                        0   \n",
       "2                           1                     1                        0   \n",
       "3                           1                     0                        0   \n",
       "4                           0                     0                        0   \n",
       "5                           0                     0                        0   \n",
       "6                           0                     0                        0   \n",
       "7                           1                     1                        0   \n",
       "8                           1                     0                        1   \n",
       "9                           0                     0                        0   \n",
       "\n",
       "   count_vectorizer__therefor  count_vectorizer__think  \\\n",
       "0                           0                        0   \n",
       "1                           0                        0   \n",
       "2                           0                        0   \n",
       "3                           0                        0   \n",
       "4                           0                        0   \n",
       "5                           0                        0   \n",
       "6                           0                        0   \n",
       "7                           0                        0   \n",
       "8                           0                        0   \n",
       "9                           0                        0   \n",
       "\n",
       "   count_vectorizer__though  count_vectorizer__thousand  \\\n",
       "0                         0                           0   \n",
       "1                         0                           0   \n",
       "2                         0                           1   \n",
       "3                         0                           0   \n",
       "4                         0                           0   \n",
       "5                         0                           0   \n",
       "6                         0                           0   \n",
       "7                         0                           1   \n",
       "8                         0                           0   \n",
       "9                         0                           0   \n",
       "\n",
       "   count_vectorizer__time  count_vectorizer__today  count_vectorizer__told  \\\n",
       "0                       0                        0                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       0                        0                       0   \n",
       "3                       0                        0                       0   \n",
       "4                       0                        0                       0   \n",
       "5                       0                        0                       0   \n",
       "6                       0                        0                       0   \n",
       "7                       0                        0                       0   \n",
       "8                       0                        0                       0   \n",
       "9                       0                        0                       0   \n",
       "\n",
       "   count_vectorizer__top  count_vectorizer__total  count_vectorizer__transact  \\\n",
       "0                      2                        1                           4   \n",
       "1                      0                        0                           0   \n",
       "2                      0                        0                           1   \n",
       "3                      0                        0                           1   \n",
       "4                      0                        0                           0   \n",
       "5                      0                        0                           0   \n",
       "6                      0                        0                           0   \n",
       "7                      0                        1                           0   \n",
       "8                      0                        0                           1   \n",
       "9                      0                        0                           0   \n",
       "\n",
       "   count_vectorizer__transfer  count_vectorizer__tri  count_vectorizer__trust  \\\n",
       "0                           2                      0                        2   \n",
       "1                           0                      0                        0   \n",
       "2                           1                      0                        0   \n",
       "3                           0                      1                        0   \n",
       "4                           0                      0                        0   \n",
       "5                           0                      0                        0   \n",
       "6                           0                      0                        0   \n",
       "7                           1                      0                        0   \n",
       "8                           2                      0                        0   \n",
       "9                           0                      1                        0   \n",
       "\n",
       "   count_vectorizer__two  count_vectorizer__understand  \\\n",
       "0                      0                             0   \n",
       "1                      0                             0   \n",
       "2                      0                             0   \n",
       "3                      0                             0   \n",
       "4                      0                             0   \n",
       "5                      0                             0   \n",
       "6                      0                             0   \n",
       "7                      0                             0   \n",
       "8                      0                             0   \n",
       "9                      0                             0   \n",
       "\n",
       "   count_vectorizer__unit  count_vectorizer__updat  count_vectorizer__upon  \\\n",
       "0                       0                        0                       0   \n",
       "1                       0                        0                       0   \n",
       "2                       1                        0                       0   \n",
       "3                       0                        0                       0   \n",
       "4                       2                        2                       0   \n",
       "5                       0                        0                       0   \n",
       "6                       0                        0                       0   \n",
       "7                       1                        0                       0   \n",
       "8                       0                        0                       1   \n",
       "9                       0                        0                       0   \n",
       "\n",
       "   count_vectorizer__urgent  count_vectorizer__us  count_vectorizer__use  \\\n",
       "0                         0                     3                      0   \n",
       "1                         0                     0                      0   \n",
       "2                         2                     0                      0   \n",
       "3                         0                     2                      0   \n",
       "4                         0                     0                      0   \n",
       "5                         0                     0                      0   \n",
       "6                         0                     0                      0   \n",
       "7                         0                     0                      0   \n",
       "8                         0                     0                      0   \n",
       "9                         0                     0                      0   \n",
       "\n",
       "   count_vectorizer__user  count_vectorizer__valu  count_vectorizer__via  \\\n",
       "0                       0                       0                      0   \n",
       "1                       0                       0                      0   \n",
       "2                       0                       0                      1   \n",
       "3                       0                       0                      1   \n",
       "4                       4                       0                      0   \n",
       "5                       0                       0                      0   \n",
       "6                       0                       0                      0   \n",
       "7                       0                       0                      0   \n",
       "8                       0                       0                      0   \n",
       "9                       0                       0                      0   \n",
       "\n",
       "   count_vectorizer__visit  count_vectorizer__want  count_vectorizer__way  \\\n",
       "0                        1                       0                      0   \n",
       "1                        0                       0                      0   \n",
       "2                        0                       0                      0   \n",
       "3                        1                       0                      0   \n",
       "4                        0                       0                      0   \n",
       "5                        0                       0                      0   \n",
       "6                        0                       0                      0   \n",
       "7                        0                       0                      0   \n",
       "8                        0                       1                      0   \n",
       "9                        0                       0                      0   \n",
       "\n",
       "   count_vectorizer__well  count_vectorizer__wish  count_vectorizer__within  \\\n",
       "0                       0                       0                         0   \n",
       "1                       0                       0                         0   \n",
       "2                       0                       0                         0   \n",
       "3                       0                       0                         1   \n",
       "4                       0                       0                         0   \n",
       "5                       0                       0                         0   \n",
       "6                       0                       0                         0   \n",
       "7                       1                       0                         0   \n",
       "8                       0                       0                         0   \n",
       "9                       0                       0                         0   \n",
       "\n",
       "   count_vectorizer__without  count_vectorizer__work  count_vectorizer__world  \\\n",
       "0                          1                       1                        1   \n",
       "1                          0                       0                        0   \n",
       "2                          0                       1                        0   \n",
       "3                          0                       0                        1   \n",
       "4                          0                       0                        0   \n",
       "5                          0                       1                        0   \n",
       "6                          0                       0                        0   \n",
       "7                          0                       0                        0   \n",
       "8                          0                       0                        0   \n",
       "9                          0                       0                        0   \n",
       "\n",
       "   count_vectorizer__would  count_vectorizer__write  count_vectorizer__wrote  \\\n",
       "0                        1                        0                        0   \n",
       "1                        0                        0                        0   \n",
       "2                        0                        0                        0   \n",
       "3                        0                        2                        0   \n",
       "4                        0                        0                        0   \n",
       "5                        0                        0                        0   \n",
       "6                        0                        0                        0   \n",
       "7                        0                        0                        0   \n",
       "8                        0                        0                        1   \n",
       "9                        0                        0                        0   \n",
       "\n",
       "   count_vectorizer__yahoo  count_vectorizer__year  \\\n",
       "0                        0                       0   \n",
       "1                        0                       0   \n",
       "2                        0                       0   \n",
       "3                        0                       1   \n",
       "4                        0                       0   \n",
       "5                        0                       0   \n",
       "6                        0                       0   \n",
       "7                        0                       0   \n",
       "8                        1                       0   \n",
       "9                        0                       0   \n",
       "\n",
       "   remainder__unsecure_link_count  remainder__secure_link_count  \\\n",
       "0                               1                             0   \n",
       "1                               1                             0   \n",
       "2                               1                             0   \n",
       "3                               1                             0   \n",
       "4                               2                             0   \n",
       "5                               0                             0   \n",
       "6                               0                             0   \n",
       "7                               0                             0   \n",
       "8                               2                             0   \n",
       "9                               0                             0   \n",
       "\n",
       "   remainder__numbers_count  remainder__word_count  \n",
       "0                        57                    504  \n",
       "1                         0                     29  \n",
       "2                         9                    218  \n",
       "3                         7                    170  \n",
       "4                         2                    154  \n",
       "5                         0                     32  \n",
       "6                         0                     15  \n",
       "7                         6                    259  \n",
       "8                         9                    386  \n",
       "9                         0                      3  "
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform the validation data using the fitted TFIDF vectorizer\n",
    "X_validation_tfidf = cv_transf.transform(X_validation)\n",
    "# Put the validation data into a data frame\n",
    "X_validation_tfidf = pd.DataFrame(\n",
    "    data=X_validation_tfidf.toarray(),\n",
    "    columns=cv_transf.get_feature_names_out(),\n",
    ")\n",
    "# Look at the top 10 columns from the validation data frame\n",
    "X_validation_tfidf.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "908cb2f7-9b93-49bd-9752-2776ee601721",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1984, 283)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the shape of the validation data\n",
    "X_validation_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f704e9f",
   "metadata": {},
   "source": [
    "### TFIDF Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20985dd",
   "metadata": {},
   "source": [
    "Now that the training and validation data has been transformed with the TFIDF vectorize, the simple models can be fit and evaluated using this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6574b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize TFIDF results dictionary\n",
    "tfidf_results_dict = {\n",
    "    'Model': [],\n",
    "    'Train Accuracy': [],\n",
    "    'Validation Accuracy': [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6e994894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PCA version of X_train and X_val\n",
    "pca_tranformer = PCA(n_components=10)\n",
    "X_train_tfidf_pca = pca_tranformer.fit_transform(X_train_tfidf)\n",
    "X_val_tfidf_pca = pca_tranformer.transform(X_validation_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "82bf5077-50e0-4580-9606-18d472645995",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.19909274193549\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the logistic regression model\n",
    "log_reg_model_tfidf_pca = LogisticRegression()\n",
    "# Fit the logistic regression model\n",
    "log_reg_model_tfidf_pca.fit(X_train_tfidf_pca, y_train)\n",
    "# Display the train accuracy of the logistic regression model\n",
    "train_acc_log_tfidf_pca = log_reg_model_tfidf_pca.score(X_train_tfidf_pca, y_train) * 100\n",
    "print(train_acc_log_tfidf_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "9dedc35d-d1ff-46ee-8c46-9853153a544b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.90322580645162\n"
     ]
    }
   ],
   "source": [
    "# Display the validation accuracy of the logistic regression model\n",
    "val_acc_log_tfidf = log_reg_model_tfidf_pca.score(X_val_tfidf_pca, y_validation) * 100\n",
    "print(val_acc_log_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "a909375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results to the results dictionary\n",
    "tfidf_results_dict['Model'].append('Logistic Regression')\n",
    "tfidf_results_dict['Train Accuracy'].append(train_acc_log_tfidf_pca)\n",
    "tfidf_results_dict['Validation Accuracy'].append(val_acc_log_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f1cb15",
   "metadata": {},
   "source": [
    "At first glance, it seems the accuracy of a default logistic regression using the TFIDF vectorized features is lower on both the train and validation scores than the logistic regression trained on the count vectorized features. However, the results of the TFIDF vectorized content will be compared using the other models to establish whether TFIDF should be used or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff906b4",
   "metadata": {},
   "source": [
    "### TFIDF SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0996d50",
   "metadata": {},
   "source": [
    "The next model that will be evaluated is a SVM model using standard settings. For this model, we will use a standard scaler on the feature data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "dc16eaf9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.21875\n"
     ]
    }
   ],
   "source": [
    "# Initialize scaler\n",
    "standardScalerTFIDF = StandardScaler()\n",
    "# Fit the scaler on the train data\n",
    "standardScalerTFIDF.fit(X_train_tfidf)\n",
    "# Transform the train data\n",
    "x_tfidf_ss_scaled_vec = standardScalerTFIDF.transform(X_train_tfidf)\n",
    "# Instantiate and fit the KNN model with cosine similarity\n",
    "svc_tfidf_model = SVC()\n",
    "svc_tfidf_model.fit(x_tfidf_ss_scaled_vec, y_train)\n",
    "# Get the train % accuracy and print it\n",
    "svc_tfidf_train_acc = svc_tfidf_model.score(x_tfidf_ss_scaled_vec, y_train) * 100\n",
    "print(svc_tfidf_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "64b05a3e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.5866935483871\n"
     ]
    }
   ],
   "source": [
    "# Scale the validation data set using the fitted scaler\n",
    "x_val_tfidf_ss_scaled_vec = standardScalerTFIDF.transform(X_validation_tfidf)\n",
    "svc_tfidf_val_acc = svc_tfidf_model.score(x_val_tfidf_ss_scaled_vec, y_validation) * 100\n",
    "print(svc_tfidf_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "3362507f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results of the KNN model to the results dictionary\n",
    "tfidf_results_dict['Model'].append('SVM')\n",
    "tfidf_results_dict['Train Accuracy'].append(svc_tfidf_train_acc)\n",
    "tfidf_results_dict['Validation Accuracy'].append(svc_tfidf_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd8f602",
   "metadata": {},
   "source": [
    "Although the train accuracy for the TFIDF model is very high with a value of 99% it appears the validation accuracy is much lower with a value at 55%. This indicates that TFIDF may cause the SVM model to over fit to the training data and not improve performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c5b04",
   "metadata": {},
   "source": [
    "### TFIDF KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96bcc58",
   "metadata": {},
   "source": [
    "Next the result of KNN with TFIDF vectorized content will be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bf24d82f-f601-456b-83a9-3b7050cd84ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97.60584677419355\n"
     ]
    }
   ],
   "source": [
    "minMaxScaler = MinMaxScaler()\n",
    "minMaxScaler.fit(X_train_tfidf)\n",
    "x_mm_scaled_tfidf = minMaxScaler.transform(X_train_tfidf)\n",
    "knn_model_tfidf = KNeighborsClassifier(n_neighbors=5, metric='cosine')\n",
    "knn_model_tfidf.fit(x_mm_scaled_tfidf, y_train)\n",
    "knn_tfidf_train_acc = knn_model_tfidf.score(x_mm_scaled_tfidf, y_train) * 100\n",
    "print(knn_tfidf_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "fffb8d5b-cb38-41cb-ae99-7536ce6864b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.16129032258065\n"
     ]
    }
   ],
   "source": [
    "x_mm_scaled_tfidf = minMaxScaler.transform(X_validation_vec)\n",
    "knn_tfidf_val_acc = knn_model.score(x_mm_scaled_tfidf, y_validation) * 100\n",
    "print(knn_tfidf_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "825dbfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results of the KNN model to the results dictionary\n",
    "tfidf_results_dict['Model'].append('KNN (Cosine Similarity)')\n",
    "tfidf_results_dict['Train Accuracy'].append(knn_tfidf_train_acc)\n",
    "tfidf_results_dict['Validation Accuracy'].append(knn_tfidf_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3697f",
   "metadata": {},
   "source": [
    "Compared to the count vectorized features, KNN using the TFIDF vectorized features improved both the train and validation accuracy slightly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c62c9",
   "metadata": {},
   "source": [
    "### TFIDF Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1765bc0e",
   "metadata": {},
   "source": [
    "The accuracy for the decision tree using the TFIDF vectorized features will be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "8a610940-5e08-4631-bc23-06f9b075a65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.92439516129032\n"
     ]
    }
   ],
   "source": [
    "tfidf_dec_tree_model = DecisionTreeClassifier()\n",
    "tfidf_dec_tree_model.fit(X_train_tfidf, y_train)\n",
    "tfidf_dec_train_acc = tfidf_dec_tree_model.score(X_train_tfidf, y_train) * 100\n",
    "print(tfidf_dec_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8f877789-33d2-4f65-823d-5728ed78203a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69.25403225806451\n"
     ]
    }
   ],
   "source": [
    "tfidf_dec_val_acc = tfidf_dec_tree_model.score(X_validation_tfidf, y_validation) * 100\n",
    "print(tfidf_dec_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0f01881a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results of the KNN model to the results dictionary\n",
    "tfidf_results_dict['Model'].append('Decision Tree')\n",
    "tfidf_results_dict['Train Accuracy'].append(tfidf_dec_train_acc)\n",
    "tfidf_results_dict['Validation Accuracy'].append(tfidf_dec_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8403c3e3",
   "metadata": {},
   "source": [
    "The accuracy result for the train set is similar to that of the count vectorized trained decision tree model, however the accuracy for the validation set is much worse at 69%."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f4442d",
   "metadata": {},
   "source": [
    "### TFIDF Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dda0ba0",
   "metadata": {},
   "source": [
    "Lastly, the Naive Bayes model will be trained on the TFIDF vectorized features and accuracy compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0a017ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.33971774193549\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the model\n",
    "tfidf_nb_model = BernoulliNB()\n",
    "# Train the model\n",
    "tfidf_nb_model.fit(X_train_vec, y_train)\n",
    "# Get the model % accuracy of the model on the train data set\n",
    "tfidf_nb_train_acc = nb_model.score(X_train_vec, y_train) * 100\n",
    "print(tfidf_nb_train_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "73554225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88.91129032258065\n"
     ]
    }
   ],
   "source": [
    "# Get the model % accuracy on the validation data set\n",
    "tfidf_nb_val_acc = nb_model.score(X_validation_vec, y_validation) * 100\n",
    "print(tfidf_nb_val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "4867edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the results to the results dictionary\n",
    "tfidf_results_dict['Model'].append('Naive Bayes')\n",
    "tfidf_results_dict['Train Accuracy'].append(tfidf_nb_train_acc)\n",
    "tfidf_results_dict['Validation Accuracy'].append(tfidf_nb_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28db8263",
   "metadata": {},
   "source": [
    "The results for the Naive Bayes model for the TFIDF vectorized features appears to be the very similar to the results for the Count Vectorized content."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e3c25",
   "metadata": {},
   "source": [
    "### Comparing TFIDF and Count Vectorized Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f26041",
   "metadata": {},
   "source": [
    "The results of the TFIDF vectorized and count vectorized will be plotted for a direct comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "6022f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame from the results dictionary\n",
    "tfidf_results_df = pd.DataFrame(tfidf_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a0acf80d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Validation Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>95.199093</td>\n",
       "      <td>87.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVM</td>\n",
       "      <td>99.218750</td>\n",
       "      <td>54.586694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN (Cosine Similarity)</td>\n",
       "      <td>97.605847</td>\n",
       "      <td>95.161290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>99.924395</td>\n",
       "      <td>69.254032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>89.339718</td>\n",
       "      <td>88.911290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Train Accuracy  Validation Accuracy\n",
       "0      Logistic Regression       95.199093            87.903226\n",
       "1                      SVM       99.218750            54.586694\n",
       "2  KNN (Cosine Similarity)       97.605847            95.161290\n",
       "3            Decision Tree       99.924395            69.254032\n",
       "4              Naive Bayes       89.339718            88.911290"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the results data frame\n",
    "tfidf_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "924203fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add identifier for TFIDF vectorized content\n",
    "tfidf_results_df['Vectorizer'] = 'TFIDF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "c9141397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add identifier for Count vectorized content\n",
    "results_df['Vectorizer'] = 'Count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f58f7a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined the results DFs\n",
    "combined_results_df = pd.concat([results_df, tfidf_results_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d38a6182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize the chart\n",
    "plt.figure(figsize=(10,5))\n",
    "# Create a bar plot from the validation accuracies in the results data frame\n",
    "mod_perf_fig = sns.barplot(\n",
    "    x='Model',\n",
    "    y='Validation Accuracy',\n",
    "    hue='Vectorizer',\n",
    "    data=combined_results_df.sort_values('Validation Accuracy', ascending=False),\n",
    ")\n",
    "# Add a title and labels\n",
    "plt.title('SVM with Count Vectorizer has Best Performance')\n",
    "plt.xlabel('Model Type')\n",
    "plt.ylabel('Validation Accuracy %')\n",
    "# Display the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd4002e",
   "metadata": {},
   "source": [
    "As demonstrated by the above chart, TFIDF did not improve performance for any models with the exception of KNN, which was still outperformed by SVM trained using a Count Vectorizer. Given this, all models except the KNN model will be trained on content vectorized using the count vectorizer instead of the TFIDF vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4aa85e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the chart\n",
    "mod_perf_fig.figure.savefig('./img/model_performance', bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7849a0b3-df81-498b-9b0f-39937e511066",
   "metadata": {},
   "source": [
    "### Build Test Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852d794e",
   "metadata": {},
   "source": [
    "Now that we have established some initial accuracy results with unoptimized models, these models should be tested and accuracies evaluated with some hyperparameter tuning. This grid search will utilize 5-fold cross validation and F1 scoring will be used as the primary method of evaluation as this represents a balance between precision and recall. The secondary scoring metric will be recall as for the purposes of fraud identification, it is better to have a false positive result than a false negative one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ee2e30bc-baec-4838-bbb0-454a578c7963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up temporary directory for pipeline cache\n",
    "cachedir = mkdtemp()\n",
    "# Initialize pipeline with count vectorizer, scaler and modelling stages\n",
    "mod_pipeline = Pipeline([\n",
    "        ('vectorize', cv_transf),\n",
    "        ('pca', PCA()),\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', LogisticRegression())\n",
    "    ],\n",
    "    # Set the cache the the temp cache directory\n",
    "    memory=cachedir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "149c6080-8fd4-462b-b4e8-74280d859c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the C values to be used to optimize the regularization strength of logistic regression\n",
    "c_range = [10**i for i in range(-3, 4)]\n",
    "\n",
    "# Initialize the parameter grid for use with the grid search for hyperparameter optimization\n",
    "grid_search_param_grid = [\n",
    "    # Set up hyperparameter optimization for Logistic Regression model\n",
    "    {\n",
    "        # Use standard and minmax scalers\n",
    "        'scaler': [None, StandardScaler(), MinMaxScaler()],\n",
    "        # Add PCA for logistic regression\n",
    "        'pca': [PCA()],\n",
    "        # Set the number of components for use with PCA\n",
    "        'pca__n_components': [10, 20],\n",
    "        # Set model to be used as Logistic Regression\n",
    "        'model': [LogisticRegression()],\n",
    "        # Set C values for use with Logistic Regression\n",
    "        'model__C': c_range, # Set regularization strength coefficients\n",
    "        # Adjust penalties used with Logistic Regression\n",
    "        'model__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        # Set solvers to be used with Logistic Regression\n",
    "        'model__solver': ['lbfgs', 'liblinear'],\n",
    "\n",
    "    },\n",
    "    # Set up hyperparameter optimization for SVM model\n",
    "    {\n",
    "        # Use Count Vectorizer\n",
    "        'vectorize': [cv_transf],\n",
    "        # PCA is set to none since it is not required\n",
    "        'pca': [None],\n",
    "        # Use standard and minmax scalers\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        # Set up model to be used as SVM\n",
    "        'model': [SVC()],\n",
    "        # Set C values for use with SVM\n",
    "        'model__C': c_range, # Set regularization strength coefficients\n",
    "        # Set the different SVM kernels for use with the model\n",
    "        'model__kernel':['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        # Set the different gamma options for SVM\n",
    "        'model__gamma': ['scale', 'auto'],\n",
    "    },\n",
    "    # Set up hyperparameter optimization for KNN model\n",
    "    {\n",
    "        # Use TFIDF and Count Vectorizers\n",
    "        'vectorize': [cv_transf, tfidf_transf],\n",
    "        # PCA is set to none since it is not required\n",
    "        'pca': [None],\n",
    "        # Use standard and minmax scalers\n",
    "        'scaler': [StandardScaler(), MinMaxScaler()],\n",
    "        # Set up model to be used as KNN\n",
    "        'model': [KNeighborsClassifier()],\n",
    "        # Set up range of neighbors to use with KNN\n",
    "        'model__n_neighbors': range(5, 51, 5),\n",
    "        # Set the different distances used to measure KNN distance\n",
    "        'model__metric':['minkowski', 'cosine'],\n",
    "    },\n",
    "    # Set up hyperparameter optimization with Decision Tree classifier\n",
    "    {\n",
    "        # No scaler is necessary for Decision Tree classifiers to set to none\n",
    "        'scaler': [None],\n",
    "        # PCA is set to none since it is not required\n",
    "        'pca': [None],\n",
    "        # Set model to be used as decision tree classifier\n",
    "        'model': [DecisionTreeClassifier()],\n",
    "        # Set max model depth\n",
    "        'model__max_depth': range(3, 21, 2),\n",
    "    },\n",
    "    # Set up hyperparameter optimization with Naive Bayes model\n",
    "    {\n",
    "        # No scaler necessary for Naive Bayes\n",
    "        'scaler': [None],\n",
    "        # PCA is set to none since it is not required\n",
    "        'pca': [None],\n",
    "        # Set model to be naive bayes\n",
    "        'model': [BernoulliNB()],\n",
    "        # Adjust the laplace smoothing parameter for Naive Bayes\n",
    "        'model__alpha': range(0, 100, 10),\n",
    "        \n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize grid search to optimize hyperparameters\n",
    "basic_model_cv = GridSearchCV(\n",
    "    # Set pipeline to be run for the grid search\n",
    "    estimator=mod_pipeline,\n",
    "    # Set the number of cross validation folds to be used\n",
    "    cv=5,\n",
    "    # Initialize the parameter grid\n",
    "    param_grid=grid_search_param_grid,\n",
    "    # Set the model evaluation to use F1 scoring\n",
    "    scoring=['f1', 'recall'],\n",
    "    # Set the grid to output statements for each grid search run\n",
    "    verbose=2,\n",
    "    # Set refit value to recall indicating this as the deciding factor\n",
    "    refit='recall',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "3fa86dfb-3694-4fe4-a5fa-d25ed75d854c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 463 candidates, totalling 2315 fits\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=  10.8s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=  10.8s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=  10.9s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=  10.7s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=  10.7s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.001, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.01, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=0.1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=10, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=100, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l1, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=l2, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=lbfgs, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=10, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=None; total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=StandardScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=LogisticRegression(), model__C=1000, model__penalty=elasticnet, model__solver=liblinear, pca=PCA(), pca__n_components=20, scaler=MinMaxScaler(); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.001, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.01, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=0.1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=10, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=100, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=scale, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=linear, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=poly, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=rbf, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=SVC(), model__C=1000, model__gamma=auto, model__kernel=sigmoid, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=  10.8s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=  10.8s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=  10.8s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=  10.7s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=  10.6s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=minkowski, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=5, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=10, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=15, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=20, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=25, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=30, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=35, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=40, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=45, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=StandardScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('count_vectorizer',\n",
      "                                 CountVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=KNeighborsClassifier(), model__metric=cosine, model__n_neighbors=50, pca=None, scaler=MinMaxScaler(), vectorize=ColumnTransformer(remainder='passthrough',\n",
      "                  transformers=[('tfidf_vectorizer',\n",
      "                                 TfidfVectorizer(min_df=0.05,\n",
      "                                                 tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
      "                                 'content')]); total time=   0.1s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=3, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=3, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=3, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=3, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=3, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=5, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=5, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=5, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=5, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=5, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=7, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=7, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=7, pca=None, scaler=None; total time=   2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=7, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=7, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=9, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=9, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=9, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=9, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=9, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=11, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=11, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=11, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=11, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=11, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=13, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=13, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=13, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=13, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=13, pca=None, scaler=None; total time=   3.0s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=15, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=15, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=15, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=15, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=15, pca=None, scaler=None; total time=   3.0s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=17, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=17, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=17, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=17, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=17, pca=None, scaler=None; total time=   3.0s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=19, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=19, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=19, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=19, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=DecisionTreeClassifier(), model__max_depth=19, pca=None, scaler=None; total time=   3.0s\n",
      "[CV] END model=BernoulliNB(), model__alpha=0, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=0, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=0, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=0, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=0, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=BernoulliNB(), model__alpha=10, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=10, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=10, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=10, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=10, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=BernoulliNB(), model__alpha=20, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=20, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=20, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=20, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=20, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=BernoulliNB(), model__alpha=30, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=30, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=30, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=30, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=30, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=BernoulliNB(), model__alpha=40, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=40, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=40, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=40, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=40, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=BernoulliNB(), model__alpha=50, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=50, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=50, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=50, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=50, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=BernoulliNB(), model__alpha=60, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=60, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=60, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=60, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=60, pca=None, scaler=None; total time=   2.8s\n",
      "[CV] END model=BernoulliNB(), model__alpha=70, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=70, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=70, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=70, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=70, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=BernoulliNB(), model__alpha=80, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=80, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=80, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=80, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=80, pca=None, scaler=None; total time=   2.9s\n",
      "[CV] END model=BernoulliNB(), model__alpha=90, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=90, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=90, pca=None, scaler=None; total time=   2.6s\n",
      "[CV] END model=BernoulliNB(), model__alpha=90, pca=None, scaler=None; total time=   2.7s\n",
      "[CV] END model=BernoulliNB(), model__alpha=90, pca=None, scaler=None; total time=   2.9s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(memory=&#x27;/var/folders/t9/4whyp65x6cqg_kdhc89_f_080000gn/T/tmpcmt2qld3&#x27;,\n",
       "                                steps=[(&#x27;vectorize&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                         CountVectorizer(min_df=0.05,\n",
       "                                                                                         tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;),\n",
       "                                                                         &#x27;content&#x27;)])),\n",
       "                                       (&#x27;pca&#x27;, PCA()),\n",
       "                                       (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;model&#x27;,...\n",
       "                                                          transformers=[(&#x27;tfidf_vectorizer&#x27;,\n",
       "                                                                         TfidfVectorizer(min_df=0.05,\n",
       "                                                                                         tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;),\n",
       "                                                                         &#x27;content&#x27;)])]},\n",
       "                         {&#x27;model&#x27;: [DecisionTreeClassifier(max_depth=19)],\n",
       "                          &#x27;model__max_depth&#x27;: range(3, 21, 2), &#x27;pca&#x27;: [None],\n",
       "                          &#x27;scaler&#x27;: [None]},\n",
       "                         {&#x27;model&#x27;: [BernoulliNB()],\n",
       "                          &#x27;model__alpha&#x27;: range(0, 100, 10), &#x27;pca&#x27;: [None],\n",
       "                          &#x27;scaler&#x27;: [None]}],\n",
       "             refit=&#x27;recall&#x27;, scoring=[&#x27;f1&#x27;, &#x27;recall&#x27;], verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(memory=&#x27;/var/folders/t9/4whyp65x6cqg_kdhc89_f_080000gn/T/tmpcmt2qld3&#x27;,\n",
       "                                steps=[(&#x27;vectorize&#x27;,\n",
       "                                        ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                                          transformers=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                                         CountVectorizer(min_df=0.05,\n",
       "                                                                                         tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;),\n",
       "                                                                         &#x27;content&#x27;)])),\n",
       "                                       (&#x27;pca&#x27;, PCA()),\n",
       "                                       (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;model&#x27;,...\n",
       "                                                          transformers=[(&#x27;tfidf_vectorizer&#x27;,\n",
       "                                                                         TfidfVectorizer(min_df=0.05,\n",
       "                                                                                         tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;),\n",
       "                                                                         &#x27;content&#x27;)])]},\n",
       "                         {&#x27;model&#x27;: [DecisionTreeClassifier(max_depth=19)],\n",
       "                          &#x27;model__max_depth&#x27;: range(3, 21, 2), &#x27;pca&#x27;: [None],\n",
       "                          &#x27;scaler&#x27;: [None]},\n",
       "                         {&#x27;model&#x27;: [BernoulliNB()],\n",
       "                          &#x27;model__alpha&#x27;: range(0, 100, 10), &#x27;pca&#x27;: [None],\n",
       "                          &#x27;scaler&#x27;: [None]}],\n",
       "             refit=&#x27;recall&#x27;, scoring=[&#x27;f1&#x27;, &#x27;recall&#x27;], verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=&#x27;/var/folders/t9/4whyp65x6cqg_kdhc89_f_080000gn/T/tmpcmt2qld3&#x27;,\n",
       "         steps=[(&#x27;vectorize&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                  CountVectorizer(min_df=0.05,\n",
       "                                                                  tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;),\n",
       "                                                  &#x27;content&#x27;)])),\n",
       "                (&#x27;pca&#x27;, PCA()), (&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;model&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">vectorize: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;count_vectorizer&#x27;,\n",
       "                                 CountVectorizer(min_df=0.05,\n",
       "                                                 tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;),\n",
       "                                 &#x27;content&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">count_vectorizer</label><div class=\"sk-toggleable__content\"><pre>content</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(min_df=0.05,\n",
       "                tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;unsecure_link_count&#x27;, &#x27;secure_link_count&#x27;, &#x27;numbers_count&#x27;, &#x27;word_count&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(memory='/var/folders/t9/4whyp65x6cqg_kdhc89_f_080000gn/T/tmpcmt2qld3',\n",
       "                                steps=[('vectorize',\n",
       "                                        ColumnTransformer(remainder='passthrough',\n",
       "                                                          transformers=[('count_vectorizer',\n",
       "                                                                         CountVectorizer(min_df=0.05,\n",
       "                                                                                         tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
       "                                                                         'content')])),\n",
       "                                       ('pca', PCA()),\n",
       "                                       ('scaler', StandardScaler()),\n",
       "                                       ('model',...\n",
       "                                                          transformers=[('tfidf_vectorizer',\n",
       "                                                                         TfidfVectorizer(min_df=0.05,\n",
       "                                                                                         tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
       "                                                                         'content')])]},\n",
       "                         {'model': [DecisionTreeClassifier(max_depth=19)],\n",
       "                          'model__max_depth': range(3, 21, 2), 'pca': [None],\n",
       "                          'scaler': [None]},\n",
       "                         {'model': [BernoulliNB()],\n",
       "                          'model__alpha': range(0, 100, 10), 'pca': [None],\n",
       "                          'scaler': [None]}],\n",
       "             refit='recall', scoring=['f1', 'recall'], verbose=2)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the grid search\n",
    "basic_model_cv.fit(X_remainder, y_remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "17d4a778-7bd3-48ca-a35f-7e5e0c25d9c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(memory=&#x27;/var/folders/t9/4whyp65x6cqg_kdhc89_f_080000gn/T/tmpcmt2qld3&#x27;,\n",
       "         steps=[(&#x27;vectorize&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                  CountVectorizer(min_df=0.05,\n",
       "                                                                  tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;),\n",
       "                                                  &#x27;content&#x27;)])),\n",
       "                (&#x27;pca&#x27;, None), (&#x27;scaler&#x27;, None),\n",
       "                (&#x27;model&#x27;, DecisionTreeClassifier(max_depth=19))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(memory=&#x27;/var/folders/t9/4whyp65x6cqg_kdhc89_f_080000gn/T/tmpcmt2qld3&#x27;,\n",
       "         steps=[(&#x27;vectorize&#x27;,\n",
       "                 ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                                   transformers=[(&#x27;count_vectorizer&#x27;,\n",
       "                                                  CountVectorizer(min_df=0.05,\n",
       "                                                                  tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;),\n",
       "                                                  &#x27;content&#x27;)])),\n",
       "                (&#x27;pca&#x27;, None), (&#x27;scaler&#x27;, None),\n",
       "                (&#x27;model&#x27;, DecisionTreeClassifier(max_depth=19))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">vectorize: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(remainder=&#x27;passthrough&#x27;,\n",
       "                  transformers=[(&#x27;count_vectorizer&#x27;,\n",
       "                                 CountVectorizer(min_df=0.05,\n",
       "                                                 tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;),\n",
       "                                 &#x27;content&#x27;)])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">count_vectorizer</label><div class=\"sk-toggleable__content\"><pre>content</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(min_df=0.05,\n",
       "                tokenizer=&lt;function custom_tokenizer at 0x7fe86b85a830&gt;)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">remainder</label><div class=\"sk-toggleable__content\"><pre>[&#x27;unsecure_link_count&#x27;, &#x27;secure_link_count&#x27;, &#x27;numbers_count&#x27;, &#x27;word_count&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">None</label><div class=\"sk-toggleable__content\"><pre>None</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=19)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(memory='/var/folders/t9/4whyp65x6cqg_kdhc89_f_080000gn/T/tmpcmt2qld3',\n",
       "         steps=[('vectorize',\n",
       "                 ColumnTransformer(remainder='passthrough',\n",
       "                                   transformers=[('count_vectorizer',\n",
       "                                                  CountVectorizer(min_df=0.05,\n",
       "                                                                  tokenizer=<function custom_tokenizer at 0x7fe86b85a830>),\n",
       "                                                  'content')])),\n",
       "                ('pca', None), ('scaler', None),\n",
       "                ('model', DecisionTreeClassifier(max_depth=19))])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the best parameters for the grid search\n",
    "basic_model_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "b6bdd41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_model</th>\n",
       "      <th>param_model__C</th>\n",
       "      <th>param_model__penalty</th>\n",
       "      <th>param_model__solver</th>\n",
       "      <th>param_pca</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "      <th>param_scaler</th>\n",
       "      <th>param_model__gamma</th>\n",
       "      <th>param_model__kernel</th>\n",
       "      <th>param_vectorize</th>\n",
       "      <th>param_model__metric</th>\n",
       "      <th>param_model__n_neighbors</th>\n",
       "      <th>param_model__max_depth</th>\n",
       "      <th>param_model__alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1</th>\n",
       "      <th>split1_test_f1</th>\n",
       "      <th>split2_test_f1</th>\n",
       "      <th>split3_test_f1</th>\n",
       "      <th>split4_test_f1</th>\n",
       "      <th>mean_test_f1</th>\n",
       "      <th>std_test_f1</th>\n",
       "      <th>rank_test_f1</th>\n",
       "      <th>split0_test_recall</th>\n",
       "      <th>split1_test_recall</th>\n",
       "      <th>split2_test_recall</th>\n",
       "      <th>split3_test_recall</th>\n",
       "      <th>split4_test_recall</th>\n",
       "      <th>mean_test_recall</th>\n",
       "      <th>std_test_recall</th>\n",
       "      <th>rank_test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>0.187308</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>2.647600</td>\n",
       "      <td>0.075741</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=19)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 19, 'pca': None, 'scaler': None}</td>\n",
       "      <td>0.951595</td>\n",
       "      <td>0.944072</td>\n",
       "      <td>0.934611</td>\n",
       "      <td>0.940523</td>\n",
       "      <td>0.950196</td>\n",
       "      <td>0.944199</td>\n",
       "      <td>0.006263</td>\n",
       "      <td>1</td>\n",
       "      <td>0.955801</td>\n",
       "      <td>0.932597</td>\n",
       "      <td>0.916022</td>\n",
       "      <td>0.934807</td>\n",
       "      <td>0.937086</td>\n",
       "      <td>0.935263</td>\n",
       "      <td>0.012670</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0.150276</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>2.656914</td>\n",
       "      <td>0.111791</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=19)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 13, 'pca': None, 'scaler': None}</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>0.951002</td>\n",
       "      <td>0.933636</td>\n",
       "      <td>0.938162</td>\n",
       "      <td>0.946957</td>\n",
       "      <td>0.944007</td>\n",
       "      <td>0.006909</td>\n",
       "      <td>2</td>\n",
       "      <td>0.950276</td>\n",
       "      <td>0.943646</td>\n",
       "      <td>0.909392</td>\n",
       "      <td>0.930387</td>\n",
       "      <td>0.935982</td>\n",
       "      <td>0.933937</td>\n",
       "      <td>0.014003</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>0.166091</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>2.655502</td>\n",
       "      <td>0.079993</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=19)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 15, 'pca': None, 'scaler': None}</td>\n",
       "      <td>0.951488</td>\n",
       "      <td>0.943017</td>\n",
       "      <td>0.932878</td>\n",
       "      <td>0.938162</td>\n",
       "      <td>0.950617</td>\n",
       "      <td>0.943232</td>\n",
       "      <td>0.007151</td>\n",
       "      <td>3</td>\n",
       "      <td>0.953591</td>\n",
       "      <td>0.932597</td>\n",
       "      <td>0.906077</td>\n",
       "      <td>0.930387</td>\n",
       "      <td>0.934879</td>\n",
       "      <td>0.931506</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>0.136447</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>2.651040</td>\n",
       "      <td>0.085515</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=19)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 11, 'pca': None, 'scaler': None}</td>\n",
       "      <td>0.948419</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.932955</td>\n",
       "      <td>0.937639</td>\n",
       "      <td>0.948546</td>\n",
       "      <td>0.942178</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>4</td>\n",
       "      <td>0.944751</td>\n",
       "      <td>0.938122</td>\n",
       "      <td>0.907182</td>\n",
       "      <td>0.930387</td>\n",
       "      <td>0.935982</td>\n",
       "      <td>0.931285</td>\n",
       "      <td>0.012899</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>0.177395</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>2.651001</td>\n",
       "      <td>0.077376</td>\n",
       "      <td>DecisionTreeClassifier(max_depth=19)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 17, 'pca': None, 'scaler': None}</td>\n",
       "      <td>0.951018</td>\n",
       "      <td>0.940123</td>\n",
       "      <td>0.932654</td>\n",
       "      <td>0.939276</td>\n",
       "      <td>0.945597</td>\n",
       "      <td>0.941734</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.954696</td>\n",
       "      <td>0.928177</td>\n",
       "      <td>0.910497</td>\n",
       "      <td>0.931492</td>\n",
       "      <td>0.930464</td>\n",
       "      <td>0.931065</td>\n",
       "      <td>0.014074</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "452       0.187308      0.002829         2.647600        0.075741   \n",
       "449       0.150276      0.003694         2.656914        0.111791   \n",
       "450       0.166091      0.004786         2.655502        0.079993   \n",
       "448       0.136447      0.003020         2.651040        0.085515   \n",
       "451       0.177395      0.005369         2.651001        0.077376   \n",
       "\n",
       "                              param_model param_model__C param_model__penalty  \\\n",
       "452  DecisionTreeClassifier(max_depth=19)            NaN                  NaN   \n",
       "449  DecisionTreeClassifier(max_depth=19)            NaN                  NaN   \n",
       "450  DecisionTreeClassifier(max_depth=19)            NaN                  NaN   \n",
       "448  DecisionTreeClassifier(max_depth=19)            NaN                  NaN   \n",
       "451  DecisionTreeClassifier(max_depth=19)            NaN                  NaN   \n",
       "\n",
       "    param_model__solver param_pca param_pca__n_components param_scaler  \\\n",
       "452                 NaN      None                     NaN         None   \n",
       "449                 NaN      None                     NaN         None   \n",
       "450                 NaN      None                     NaN         None   \n",
       "448                 NaN      None                     NaN         None   \n",
       "451                 NaN      None                     NaN         None   \n",
       "\n",
       "    param_model__gamma param_model__kernel param_vectorize  \\\n",
       "452                NaN                 NaN             NaN   \n",
       "449                NaN                 NaN             NaN   \n",
       "450                NaN                 NaN             NaN   \n",
       "448                NaN                 NaN             NaN   \n",
       "451                NaN                 NaN             NaN   \n",
       "\n",
       "    param_model__metric param_model__n_neighbors param_model__max_depth  \\\n",
       "452                 NaN                      NaN                     19   \n",
       "449                 NaN                      NaN                     13   \n",
       "450                 NaN                      NaN                     15   \n",
       "448                 NaN                      NaN                     11   \n",
       "451                 NaN                      NaN                     17   \n",
       "\n",
       "    param_model__alpha  \\\n",
       "452                NaN   \n",
       "449                NaN   \n",
       "450                NaN   \n",
       "448                NaN   \n",
       "451                NaN   \n",
       "\n",
       "                                                                                                   params  \\\n",
       "452  {'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 19, 'pca': None, 'scaler': None}   \n",
       "449  {'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 13, 'pca': None, 'scaler': None}   \n",
       "450  {'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 15, 'pca': None, 'scaler': None}   \n",
       "448  {'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 11, 'pca': None, 'scaler': None}   \n",
       "451  {'model': DecisionTreeClassifier(max_depth=19), 'model__max_depth': 17, 'pca': None, 'scaler': None}   \n",
       "\n",
       "     split0_test_f1  split1_test_f1  split2_test_f1  split3_test_f1  \\\n",
       "452        0.951595        0.944072        0.934611        0.940523   \n",
       "449        0.950276        0.951002        0.933636        0.938162   \n",
       "450        0.951488        0.943017        0.932878        0.938162   \n",
       "448        0.948419        0.943333        0.932955        0.937639   \n",
       "451        0.951018        0.940123        0.932654        0.939276   \n",
       "\n",
       "     split4_test_f1  mean_test_f1  std_test_f1  rank_test_f1  \\\n",
       "452        0.950196      0.944199     0.006263             1   \n",
       "449        0.946957      0.944007     0.006909             2   \n",
       "450        0.950617      0.943232     0.007151             3   \n",
       "448        0.948546      0.942178     0.006108             4   \n",
       "451        0.945597      0.941734     0.006200             5   \n",
       "\n",
       "     split0_test_recall  split1_test_recall  split2_test_recall  \\\n",
       "452            0.955801            0.932597            0.916022   \n",
       "449            0.950276            0.943646            0.909392   \n",
       "450            0.953591            0.932597            0.906077   \n",
       "448            0.944751            0.938122            0.907182   \n",
       "451            0.954696            0.928177            0.910497   \n",
       "\n",
       "     split3_test_recall  split4_test_recall  mean_test_recall  \\\n",
       "452            0.934807            0.937086          0.935263   \n",
       "449            0.930387            0.935982          0.933937   \n",
       "450            0.930387            0.934879          0.931506   \n",
       "448            0.930387            0.935982          0.931285   \n",
       "451            0.931492            0.930464          0.931065   \n",
       "\n",
       "     std_test_recall  rank_test_recall  \n",
       "452         0.012670                 1  \n",
       "449         0.014003                 2  \n",
       "450         0.015154                 4  \n",
       "448         0.012899                 5  \n",
       "451         0.014074                 6  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put results into data frame\n",
    "results_df = pd.DataFrame(basic_model_cv.cv_results_)\n",
    "# Sort data frame by best f1 score\n",
    "results_df.sort_values(by='mean_test_f1', ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "7141c984-9d3d-42b6-a01d-9838182312f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9352625224104496"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the best score for the grid search\n",
    "basic_model_cv.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f7048d",
   "metadata": {},
   "source": [
    "As a result of the grid search it seems the best performing model was a Decision Tree model with a max depth of 19, which receives a recall of 94% and an F1 score of 94%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "71f7191b-e2f3-4397-bf61-27c5cbc2b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values for the test set\n",
    "y_test_pred = basic_model_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "31fd36be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9467956469165659"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check accuracy score\n",
    "accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1964f992",
   "metadata": {},
   "source": [
    "This model results in a test accuracy score of 95% which seems fairly high. The confusion matrix for this model and the incorrectly categorized results will be examined further to see the shortcomings of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "306c6931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get confustion matrix for test set\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "# Get display for confusion matrix\n",
    "conf_disp = ConfusionMatrixDisplay(conf_matrix)\n",
    "# Plot the confusion matrix\n",
    "conf_disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "2a019c09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 93.28621908127208%\n",
      "Precision: 94.96402877697841%\n"
     ]
    }
   ],
   "source": [
    "# Calculate the recall of the model\n",
    "recall = conf_matrix[1][1] / (conf_matrix[1][0] + conf_matrix[1][1]) * 100\n",
    "# Calculate the precision of the model\n",
    "precision = conf_matrix[1][1] / (conf_matrix[0][1] + conf_matrix[1][1]) * 100\n",
    "# Print the precision and recall of the model\n",
    "print(f'Recall: {recall}%')\n",
    "print(f'Precision: {precision}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7163d44",
   "metadata": {},
   "source": [
    "As demonstrated by the confusion matrix above, the recall of the model is 93% and precision is 95%. These values seem to be fairly high, which could be expected considering the high F1 score. Next, where the model is incorrect will be examined more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "402c77bf-78f2-4018-9ee9-aa089005fd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the X values where the predicted value does not equal the test value\n",
    "wrong_pred = X_test[y_test_pred != y_test['fraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "1901bdbc-533c-4e1a-986a-1b16b6103614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Y values where the predicted value does not equal the test value\n",
    "wrong_pred_y = y_test[y_test_pred != y_test['fraud']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c97326eb-86b6-49e0-b3cf-d040707ba08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatinate the data frames with wrong X and Y predictions\n",
    "wrong_pred = pd.concat([wrong_pred, wrong_pred_y], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "71def78c-f532-4f4e-b37c-ff5df0228c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>unsecure_link_count</th>\n",
       "      <th>secure_link_count</th>\n",
       "      <th>numbers_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>After you fill in the registration form our operator will contact you through phone or your mail during from the moment of filling the form Hurry up The amount of in our company is limited</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Hi for LESS struggle going on apparently they are the bound man to A complete corruption of history</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Remain blessed in the name of the Lord Yours in Harry</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>My name is from and my late wife she worked with shell petroleum company in South for twelve before she in the year after a brief illness We were married for eight without a child She after a brief illness that for only four days before she give up since we married we were both couple Since she death I decided not to re marry or get a child outside my matrimonial home When my late wife was alive she the sum of Million Twelve Million ES with International Diplomatic service company in which i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>550</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Your registered name is included to show this message from Learn more width</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>mail it bin start target blank Sponsor virus ma non sai come i virus a virus A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>Dear Friend With great pleasure I Credit control Manager Bank name upheld is writing you in respect of a foreign customer anOil consultant contractor with the National Lee made a time Fixed Deposit calendar US Twenty five Million in my branch Upon maturity I sent a routine notification to his forwarding got no reply After a month we sent a reminder and finally from his contract the National that Lee in Air Flight in on August with other made further investigation and discovered that without ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>675</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>Content transfer printable sent this message to Your registered name is included to show this message from Learn More click to User Agreement and Privacy Policy Dear writing to let you know that the User Agreement and Privacy Policy have been effective immediately for as of and effective for current User Agreement click Privacy Policy click The and dispute resolution you originally agreed to have not in any substantive way The User Agreement been however to cover new such as in the collectio...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>Friend I am Barrister a solicitor at law in You are to assist in the transfer of US Contact me for further treat privately Best Barrister</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>con Free in In se ti gratis al non di it</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>late father and also a Civil Servant in the Ministry of Health know this proposal will come to you as a surprise because we have not met before either physically or through correspondence I got your contact through a friend working with chamber of commerce here in who have travelled far and wide and have in your ability to handle this proposal huge sum of money</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>Parker Home Try On New available to try at home We just added of new glasses to our Home Try On assortment Find out which you should try with our super easy quiz Get</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>FROM MISS IVORY COAST COTE APPEAL OR URGENT ASSISTANCE Dear Sir Permit me to inform you of my of going relationship with you Though this letter will be a surprise to you since you dont know I got your recent during for a stranger that can help me i mutual transaction and I over it your name among the other due to nature and the to me as and trust worthy person that I can with and by the recommendation I must to confide in you for this simple and I am MISS the only daughter of late And My fat...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>742</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>constrict abacus shape Choose the life and freedom you deserve and live the life of your more here Sincerely quahog velours seeing beast indemnify hobble trouser irritable diversionary nelson rapacious loon elm electrolyte lunacy veracity inclement spawn bode vacuole dunce formant gloom qualified counterattack enunciate sunny bantam perpendicular discriminant mediocre crowberry pendulum chromic inapt bettor penance pentane enamel</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>will simply nominate you as the next of kin and have them release the deposit to you I would have gone ahead to ask the funds be to me but that would have drawn a straight line in my involvement in the deposit I assure you that I could have the deposit to you within the coming I will simply inform the bank of the final of the file to the late customer I will then officially communicate with my Bank and instruct them to release the deposit to</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>We only sell premium Theres no bat in these re just like the real since they charge themselves as you move The second hand JUST like the real too These original sell in for of We se them for much less Replicated to the Detail Perfectly Accurate Signature Green Sticker Serial Number on Wa tch Back Quickset Date all Proper</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>ACCEPT CERTIFIED AND NOTABLE BANK FROM MY I ALSO DO NOT DISCLOSE YOUR PERSONAL INFORMATION TO MY OR ANYONE ELSE New Yahoo Messenger with Voice Call regular from your and save big</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>Of The Day Permit me to introduce you My name is a top Management the above Finance Corporation in I came to know about you in my private search for person company to handle an on behalf of my and myself</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>794</th>\n",
       "      <td>From Manager Street Island Marina</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>YOUR Friend Naturally this letter will come to you as a surprise since we have not met permit me however I am a white Farmer the owner of Diary limited in Zimbabwe I own three tobacco in and I am also majority owner of Glen Farm also situated in in Zimbabwe I am you as the need to for me to have a foreign partner in your country become necessary due to our to relocate to that country so that I can purchase some and start farming all over again as the present political instability in Zimbabwe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>SUNNY ROAD JO BORG SOUTH URGENT AND CONFIDENTIAL</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>Your contact information will be for easy communication Warm a a ca</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>Feel to drop your voice message and we shall been in Ruth Van Director</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>THE CARD PAYMENT CENTER BEEN TO AS PART PAYMENT FOR THIS FISCAL YEAR ALSO FOR YOUR INFORMATION YOU HAVE TO STOP ANY WITH ANY OTHER PERSON OR OFFICE TO AVOID ANY IN YOUR PAYMENT NOTE THAT BECAUSE OF WE HEREBY CODE OF CONDUCT WHICH IS SO YOU HAVE TO CODE WHEN THE CARD CENTER BY IT AS CHIEF AUDITOR TO THE REPUBLIC OF Phoenix Recover Pro de detail</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>and Respect Brown ni na On Air Son</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>SENIOR ADVOCATE OF SENIOR ADVOCATE OF</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>Dear Sir I take this opportunity to introduce myself as Limited working at of responsibility of Customer Reach Support This is for our New Business card Reader cum Photo scanner Model Plus Kindly ignore this if you have already the one the satisfied of the same Your name and contact are available in our that were keen to purchase Colour Business card Scanner cum Reader that like label printing both side scanning category setting reminder system import export with You were also looking for bu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>398</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956</th>\n",
       "      <td>I would like to apply through this medium for your operation and to secure an opportunity to invest and do joint business with you in your country as i do not have much about international business investment I have a substantial capital I honorably intend to invest in your a very lucrative venture of which you are to advise and execute venture over there for the mutual of both of us Your operation is to become my business partner trustee and your country and create an on how money will be p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>Would you like a Free Wireless Media Manager by in a unique Use this link net track fast example Feeling limited by your Receive a Free Pepper Pad or by in a unique Listen to music store or view and browse the all in the palm of your hand Use this link net track fast example Superb Gift Program is not endorsed by or with Pepper Pad or Palm One Such are registered of their respective Wireless plan not included This is exclusively by Superb and is subject to participation and Receipt of your i...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>COUNTRY SEX AGE MARITAL STATUS OCCUPATION MAIL ADDRESS TELEPHONE NUMBER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>Best VINCENT Free WEB MAIL Service by</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>Good afternoon dear client More and more illegal took place with Bank during last There are lots of when the confidential information of our is stolen by Many people send us to protect them from the loss of from their That is why the administration of Bank Bank will try to pay special attention to the problem of fraud next month All our should verify their new system of security till the st of We worked hard to improve the system of security The system is checked up by the leading of the sph...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>FONT aim Or you can send your number for me to call you Trusting to hear from you immediately for more detailed discussion FONT Director Diamond Security Storage</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>Security Security Warning From Security SECURITY WARNING Hello My name is Head of the Security Department here at If you are currently the are that your computer been subjected to a harmful parasite known as and have effectively as the computer privacy issue of connected Below are just a few of the many your computer will experience if infected with Much connection Constant bombardment of pop while the of annoying and BANNER What we have done is up with an exciting company to offer you a pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>Login Apply now for the Plus Credit Card and pay no interest on or balance until as long as you apply by August Dont wait to take advantage of this special introductory offer is easy and you may be in just Start earning with every purchase you make</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>NAME REQUEST FOR ASSISTANCE A CONFIDENTIAL I AM THE CHAIRMAN OF CONTRACT AWARD AND REVIEW COMMITTEE SET UP BY THE FEDERAL GOVERNMENT OF UNDER THE NEW CIVILIAN DISPENSATION TO AWARD NEW AND REVIEW I CAME TO KNOW OF YOU IN MY SEARCH FOR A RELIABLE AND REPUTABLE PERSON TO HANDLE A VERY CONFIDENTIAL TRANSACTION WHICH THE TRANSFER OF A HUGE SUM OF MONEY TO A FOREIGN ACCOUNT THERE WERE SERIES OF EXECUTED BY A CONSORTIUM OF IN THE OIL INDUSTRY IN OF EN THE ORIGINAL VALUE OF THESE WERE OVER TO THE S...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>324</td>\n",
       "      <td>1794</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1284</th>\n",
       "      <td>Yours truly Mona Add to your with Get FREE join page</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>Agricultural Research Institute of Northern</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>I am Barrister you today for a business be of immense benefit to you I am an attorney at law I have a I am the personal attorney to Stella the and wife to the president of the Federal Republic Of Unfortunately Stella in on the th of while undergoing medical treatment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>Hello I am Bill Cole i do care for Orphan and work for The And Orphan I live in United Kingdom with my two I have been working for the home since I was old That me about plus my age of experience I have my own orphan home in just now in united kingdom height our Village at In all more than through Over to Canada or and to raise over millions a year through generous their money time or energy These are crucial us improve people and rise to the needs we have care for the private and from all a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>386</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>want to transfer to overseas Thirty million United from a Bank in I want you look for a reliable and honest person be capable and fit to provide either an account or to set up a new Bank a to receive this money even an empty a serve to receive this money as long as you honest to me till the end for this trusting in you and believing in God will never let me down either now or in future I am the Auditor General of a bank during the course of our a floating fund in an account bank in and since...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>658</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>Hi from from from of useless knowledge the data that we were in tunnel at the place where it crossed I against the wall and was thinking seriously about going to sleep when I the thud of ascii Hi from from from of useless knowledge the data that we were in tunnel at the place where it crossed I against the wall and was thinking seriously about going to sleep when I the thud of</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>Best CIVIL MINISTRY AND</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>Finally accept my goodwill my dear friend Thank you once again and may God bless you Aku</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>Hi Hello Smart Player We know you want to avoid noisy Why dont you get better odds ist he best in the industry because we offer Excitement thrill and opportunity to enter the world of luxury gambling never been more rewarding Give us a try Free is ON THE HOUSE Good luck to you and may your lucky never end Start Winning Now check The fish will soon be caught that at every bait He Long Who Well He who with the devil should have a long spoon The Best Fish Swim Near the Bottom yuh eye see Yester...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>To report a PRIVATELY please wrote To report a PRIVATELY please hi this list to be for white so Ill add my contribution Even with low I believe I found through snort report about WEB remote include path Any contribution is welcome We are looking into it thanks list To report a PRIVATELY please mailman</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1652</th>\n",
       "      <td>Question from Member Respond Now sent this message on behalf of an member through My sent will not reach the member Question from Activity with last days I have bid on from Positive feedback Member since Location CA United Registered on This is the last time I send the money in advance to people like you Its been and no answer You stole my birthday money you thief This wont end like this I will contact and and go to jail Respond to this question in My will not include your address Thank you ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1654</th>\n",
       "      <td>Dear Sir Good day and how are you I the BUDGET TRIP INTERNATIONAL Could you please check through these group and get back to me best you assist with them ADD ADD</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>Check out the new free of storage and industry leading and us protection FE FA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1682</th>\n",
       "      <td>Furthermore contact your agent as instructed above and accept my Morgan West ordinator</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1721</th>\n",
       "      <td>me to the best pharmacy</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>THIS IS TO OFFICIALLY INFORM YOU THAT WE HAVE YOUR CONTRACT INHERITANCE FILE AND FOUND OUT THAT WHY YOU HAVE NOT RECEIVED YOUR PAYMENT IS BECAUSE YOU HAVE NOT THE GIVEN TO YOU IN RESPECT OF YOUR CONTRACT INHERITANCE PAYMENT SECONDLY WE HAVE BEEN INFORMED THAT YOU ARE STILL DEALING WITH THE NONE IN THE BANK AND ALL YOUR ATTEMPT TO SECURE THE RELEASE OF YOUR FUND PROVED ABORTIVE WE WISH TO ADVISE YOU THAT SUCH AN ILLEGAL ACT LIKE THIS HAVE TO STOP IF YOU WISH TO RECEIVE YOUR PAYMENT SINCE WE H...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>248</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1774</th>\n",
       "      <td>I have the fee for your Cheque Draft Because the manager of told me that before the check will get to you that it So i told him to cash however all the necessary the in cash was made with Global Company This is the information they need to delivery your you The only money you have to send to them is there security which is Us to received your package</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>Best Sunny Mail sent from service at</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1845</th>\n",
       "      <td>in this matter until the task is accomplished as I don want ing that will Jeopardize my due to the fact that i do not want or family standing in the way of my last wish love el Te Part</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>and all its own North Black White Butterfly Blue and Golden Beige All block production is sold to both the local and international The Group is very price on all its due to its low overhead structure All ar ideally produced for gang saw and dimension of are Smaller are also available for selection We will feel it an if we could serve you and welcome your inquiry i our Looking forward to hearing from you Sincerely yours Department STONE GROUP Fortune Building North China</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1942</th>\n",
       "      <td>Hi from from from How do we find it I havent the idea I just said that to get off my neck ascii Hi from from from How do we find it I havent the idea I just said that to get off my neck</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>that I shall provide you with more of this operation Your response to this letter will be I await your response POON</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>to you My name is and I am an artist I live in with my two four one dog and the love of my life It is definitely a full house I have been doing since I was a small child That me about of experience I in art in high school and took a few college art Most of my work is done in either pencil or air brush mixed with color I have recently added designing and art work on the computer I have been selling my art for the last and have had my work featured on trading and in I have sold and to private ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>for you as the foreign partner for I and my We shall be on your advice as regard investment of our share in any business in your country Be informed that this business is genuine and safe considering the high power government involved Send your private telephone Upon your response we shall provide you with further information on the your prompt positive response as I Look forward to a good business relationship with you Sincerely Baker</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>Mutual System Dear Mutual member By this letter we inform you that our bank is switching to security Mutual security require that your card is compatible with our new Mutual and hardware will be Go to Mutual Banking We offer you a new convenient and safe high quality level of service to handle your card Thank you for Mutual</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>We Welcome You To Your Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2176</th>\n",
       "      <td>am Camara From the Federal Republic but presently in political problem humbly wish to inform you in my proposal that I have about of metal carat and purity and Rough Diamond to my financial status I have decided to kilo quite below the world market price shall discuss other vital information and to the origin to you immediately your interest may reply through my alternate mail address me on my telephone line I am looking forward to receive your reply truly Patty</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2214</th>\n",
       "      <td>Find a local pizza ace movie theater and more then map the best route Find it</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2273</th>\n",
       "      <td>web mail and HALF PRICE for the first Save A a month Part</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2278</th>\n",
       "      <td>Dear Western Union We are sorry for invoice we had some in our data Please update your profile You can access your profile at asp asp For help please contact Western Union Customer Service immediately by at or call us at Thank you for</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>POT pour la elle de mille dont era sera sur place en te si bien en possession code dire A informer us imp en contact Numero de Tele phone Profession car in de de gain Pour inform</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>HOTEL COTE me la de mon re tait un de cacao bas la de la te em par de rencontre pour dis sur de cacao la mort de ma re mon re a si pour sa mort a la de sept millions un locale a confirm re de en a en outre tait cause de richesse a par un de de parole un de on aider mon argent depart ai la situation de la me ai jours a si de trouble sans En ce moment te parle la presence on la car dis la presence de a eu re ce me demander ton service ce service de aider un aider reception de ce message de man...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>Remain blessed in the name of the Lord Yours in Harry Hakeem</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2369</th>\n",
       "      <td>Dear Sir I should appreciate your surprise while this letter In I am left with no option but to contact you in this manner to you was informed by knowledge that being established you could be disposed to understand my predicament in order to give assistance I require I am Frank the son of a late Sierra late the owner of Mining Company who few ago when the Revolutionary United our residence on the of in Following the cease fire agreement which was last year with of United Nation peace keeping...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2387</th>\n",
       "      <td>MISSIONARY QUARTERS A CHURCH ROAD SEND REPLY TO MY PRIVATE BOX respectful feel good you today I have read from your add in quiet well that this contact will bring a lasting relationship With regard to your reputation and of God who will me nor deny me in faith I am this letter to you I am Miss the only daughter of of Zimbabwe in desire to get somebody who will safe guard that of my junior brother and this money Briefly was a Gold and Cocoa merchant who based in cote and had a branch office h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>445</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2401</th>\n",
       "      <td>Hello I am Barry Commercial Loan Officer at Bank in the ted Kingdom I am sorry for this medium to contact you as it is unsecure but I have no choice as it is the only medium I can use in contact with you that is quick as this matter is in dire need of urgent attention I would want you to assist in a business venture A Two Million Six Hundred Thousand but have to be sure that you are willing to indulge in this transaction Please kindly get back to me if you are interested so I can furnish you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2427</th>\n",
       "      <td>Loan Office Bank Lane New United Kingdom barry Hell I am Barry Commercial Loan Officer at Bank in the United Kingdom I am sorry for this medium to act you as it is highly unsecure but I have no choice as it is the only I can use in contact with you that is quick as this ma is in dire need of urgent attention I would want yo to assist in a business venture A Two Million Six Hundred Thousand but have to be sure that you are wi to indulge in this transaction Please kindly get back to me if you ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>Unpaid Item Strike Received You have received an Unpaid Item strike You were the winning buyer on item The seller informed that payment for the item still not been received or that the two of you were not able to come to agreement As a result you have received an Unpaid Item strike Remember Unpaid Item may result in your suspension from You can appeal this Unpaid Item strike if you believe it is not deserved First read the for appealing the strike If you meet them you can submit your appeal ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2441</th>\n",
       "      <td>Could you also include your contact address and your private mobile phone number for easy communication Best Son</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2461</th>\n",
       "      <td>looking forward to your punctual response Send also your contact phone number for oral Best Peter i jumpy it Directory</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  content  \\\n",
       "19                                                                                                                                                                                                                                                                                                                           After you fill in the registration form our operator will contact you through phone or your mail during from the moment of filling the form Hurry up The amount of in our company is limited   \n",
       "35                                                                                                                                                                                                                                                                                                                                                                                                                    Hi for LESS struggle going on apparently they are the bound man to A complete corruption of history   \n",
       "49                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Remain blessed in the name of the Lord Yours in Harry   \n",
       "138   My name is from and my late wife she worked with shell petroleum company in South for twelve before she in the year after a brief illness We were married for eight without a child She after a brief illness that for only four days before she give up since we married we were both couple Since she death I decided not to re marry or get a child outside my matrimonial home When my late wife was alive she the sum of Million Twelve Million ES with International Diplomatic service company in which i...   \n",
       "149                                                                                                                                                                                                                                                                                                                                                                                                                                           Your registered name is included to show this message from Learn more width   \n",
       "189                                                                                                                                                                                                                                                                                                                                                                                                                                        mail it bin start target blank Sponsor virus ma non sai come i virus a virus A   \n",
       "220   Dear Friend With great pleasure I Credit control Manager Bank name upheld is writing you in respect of a foreign customer anOil consultant contractor with the National Lee made a time Fixed Deposit calendar US Twenty five Million in my branch Upon maturity I sent a routine notification to his forwarding got no reply After a month we sent a reminder and finally from his contract the National that Lee in Air Flight in on August with other made further investigation and discovered that without ...   \n",
       "229   Content transfer printable sent this message to Your registered name is included to show this message from Learn More click to User Agreement and Privacy Policy Dear writing to let you know that the User Agreement and Privacy Policy have been effective immediately for as of and effective for current User Agreement click Privacy Policy click The and dispute resolution you originally agreed to have not in any substantive way The User Agreement been however to cover new such as in the collectio...   \n",
       "276                                                                                                                                                                                                                                                                                                                                                                             Friend I am Barrister a solicitor at law in You are to assist in the transfer of US Contact me for further treat privately Best Barrister   \n",
       "479                                                                                                                                                                                                                                                                                                                                                                                                                                                                              con Free in In se ti gratis al non di it   \n",
       "551                                                                                                                                           late father and also a Civil Servant in the Ministry of Health know this proposal will come to you as a surprise because we have not met before either physically or through correspondence I got your contact through a friend working with chamber of commerce here in who have travelled far and wide and have in your ability to handle this proposal huge sum of money   \n",
       "600                                                                                                                                                                                                                                                                                                                                                 Parker Home Try On New available to try at home We just added of new glasses to our Home Try On assortment Find out which you should try with our super easy quiz Get   \n",
       "601   FROM MISS IVORY COAST COTE APPEAL OR URGENT ASSISTANCE Dear Sir Permit me to inform you of my of going relationship with you Though this letter will be a surprise to you since you dont know I got your recent during for a stranger that can help me i mutual transaction and I over it your name among the other due to nature and the to me as and trust worthy person that I can with and by the recommendation I must to confide in you for this simple and I am MISS the only daughter of late And My fat...   \n",
       "603                                                                     constrict abacus shape Choose the life and freedom you deserve and live the life of your more here Sincerely quahog velours seeing beast indemnify hobble trouser irritable diversionary nelson rapacious loon elm electrolyte lunacy veracity inclement spawn bode vacuole dunce formant gloom qualified counterattack enunciate sunny bantam perpendicular discriminant mediocre crowberry pendulum chromic inapt bettor penance pentane enamel   \n",
       "608                                                         will simply nominate you as the next of kin and have them release the deposit to you I would have gone ahead to ask the funds be to me but that would have drawn a straight line in my involvement in the deposit I assure you that I could have the deposit to you within the coming I will simply inform the bank of the final of the file to the late customer I will then officially communicate with my Bank and instruct them to release the deposit to   \n",
       "641                                                                                                                                                                                    We only sell premium Theres no bat in these re just like the real since they charge themselves as you move The second hand JUST like the real too These original sell in for of We se them for much less Replicated to the Detail Perfectly Accurate Signature Green Sticker Serial Number on Wa tch Back Quickset Date all Proper   \n",
       "644                                                                                                                                                                                                                                                                                                                                    ACCEPT CERTIFIED AND NOTABLE BANK FROM MY I ALSO DO NOT DISCLOSE YOUR PERSONAL INFORMATION TO MY OR ANYONE ELSE New Yahoo Messenger with Voice Call regular from your and save big   \n",
       "761                                                                                                                                                                                                                                                                                                           Of The Day Permit me to introduce you My name is a top Management the above Finance Corporation in I came to know about you in my private search for person company to handle an on behalf of my and myself   \n",
       "794                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     From Manager Street Island Marina   \n",
       "818   YOUR Friend Naturally this letter will come to you as a surprise since we have not met permit me however I am a white Farmer the owner of Diary limited in Zimbabwe I own three tobacco in and I am also majority owner of Glen Farm also situated in in Zimbabwe I am you as the need to for me to have a foreign partner in your country become necessary due to our to relocate to that country so that I can purchase some and start farming all over again as the present political instability in Zimbabwe...   \n",
       "823                                                                                                                                                                                                                                                                                                                                                                                                                                                                      SUNNY ROAD JO BORG SOUTH URGENT AND CONFIDENTIAL   \n",
       "851                                                                                                                                                                                                                                                                                                                                                                                                                                                   Your contact information will be for easy communication Warm a a ca   \n",
       "852                                                                                                                                                                                                                                                                                                                                                                                                                                                Feel to drop your voice message and we shall been in Ruth Van Director   \n",
       "868                                                                                                                                                             THE CARD PAYMENT CENTER BEEN TO AS PART PAYMENT FOR THIS FISCAL YEAR ALSO FOR YOUR INFORMATION YOU HAVE TO STOP ANY WITH ANY OTHER PERSON OR OFFICE TO AVOID ANY IN YOUR PAYMENT NOTE THAT BECAUSE OF WE HEREBY CODE OF CONDUCT WHICH IS SO YOU HAVE TO CODE WHEN THE CARD CENTER BY IT AS CHIEF AUDITOR TO THE REPUBLIC OF Phoenix Recover Pro de detail   \n",
       "932                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    and Respect Brown ni na On Air Son   \n",
       "939                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 SENIOR ADVOCATE OF SENIOR ADVOCATE OF   \n",
       "946   Dear Sir I take this opportunity to introduce myself as Limited working at of responsibility of Customer Reach Support This is for our New Business card Reader cum Photo scanner Model Plus Kindly ignore this if you have already the one the satisfied of the same Your name and contact are available in our that were keen to purchase Colour Business card Scanner cum Reader that like label printing both side scanning category setting reminder system import export with You were also looking for bu...   \n",
       "956   I would like to apply through this medium for your operation and to secure an opportunity to invest and do joint business with you in your country as i do not have much about international business investment I have a substantial capital I honorably intend to invest in your a very lucrative venture of which you are to advise and execute venture over there for the mutual of both of us Your operation is to become my business partner trustee and your country and create an on how money will be p...   \n",
       "989   Would you like a Free Wireless Media Manager by in a unique Use this link net track fast example Feeling limited by your Receive a Free Pepper Pad or by in a unique Listen to music store or view and browse the all in the palm of your hand Use this link net track fast example Superb Gift Program is not endorsed by or with Pepper Pad or Palm One Such are registered of their respective Wireless plan not included This is exclusively by Superb and is subject to participation and Receipt of your i...   \n",
       "998                                                                                                                                                                                                                                                                                                                                                                                                                                               COUNTRY SEX AGE MARITAL STATUS OCCUPATION MAIL ADDRESS TELEPHONE NUMBER   \n",
       "1026                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Best VINCENT Free WEB MAIL Service by   \n",
       "1044  Good afternoon dear client More and more illegal took place with Bank during last There are lots of when the confidential information of our is stolen by Many people send us to protect them from the loss of from their That is why the administration of Bank Bank will try to pay special attention to the problem of fraud next month All our should verify their new system of security till the st of We worked hard to improve the system of security The system is checked up by the leading of the sph...   \n",
       "1087                                                                                                                                                                                                                                                                                                                                                    FONT aim Or you can send your number for me to call you Trusting to hear from you immediately for more detailed discussion FONT Director Diamond Security Storage   \n",
       "1105  Security Security Warning From Security SECURITY WARNING Hello My name is Head of the Security Department here at If you are currently the are that your computer been subjected to a harmful parasite known as and have effectively as the computer privacy issue of connected Below are just a few of the many your computer will experience if infected with Much connection Constant bombardment of pop while the of annoying and BANNER What we have done is up with an exciting company to offer you a pro...   \n",
       "1198                                                                                                                                                                                                                                                             Login Apply now for the Plus Credit Card and pay no interest on or balance until as long as you apply by August Dont wait to take advantage of this special introductory offer is easy and you may be in just Start earning with every purchase you make   \n",
       "1278  NAME REQUEST FOR ASSISTANCE A CONFIDENTIAL I AM THE CHAIRMAN OF CONTRACT AWARD AND REVIEW COMMITTEE SET UP BY THE FEDERAL GOVERNMENT OF UNDER THE NEW CIVILIAN DISPENSATION TO AWARD NEW AND REVIEW I CAME TO KNOW OF YOU IN MY SEARCH FOR A RELIABLE AND REPUTABLE PERSON TO HANDLE A VERY CONFIDENTIAL TRANSACTION WHICH THE TRANSFER OF A HUGE SUM OF MONEY TO A FOREIGN ACCOUNT THERE WERE SERIES OF EXECUTED BY A CONSORTIUM OF IN THE OIL INDUSTRY IN OF EN THE ORIGINAL VALUE OF THESE WERE OVER TO THE S...   \n",
       "1284                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Yours truly Mona Add to your with Get FREE join page   \n",
       "1289                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Agricultural Research Institute of Northern   \n",
       "1317                                                                                                                                                                                                                                          I am Barrister you today for a business be of immense benefit to you I am an attorney at law I have a I am the personal attorney to Stella the and wife to the president of the Federal Republic Of Unfortunately Stella in on the th of while undergoing medical treatment   \n",
       "1407  Hello I am Bill Cole i do care for Orphan and work for The And Orphan I live in United Kingdom with my two I have been working for the home since I was old That me about plus my age of experience I have my own orphan home in just now in united kingdom height our Village at In all more than through Over to Canada or and to raise over millions a year through generous their money time or energy These are crucial us improve people and rise to the needs we have care for the private and from all a...   \n",
       "1426  want to transfer to overseas Thirty million United from a Bank in I want you look for a reliable and honest person be capable and fit to provide either an account or to set up a new Bank a to receive this money even an empty a serve to receive this money as long as you honest to me till the end for this trusting in you and believing in God will never let me down either now or in future I am the Auditor General of a bank during the course of our a floating fund in an account bank in and since...   \n",
       "1459                                                                                                                          Hi from from from of useless knowledge the data that we were in tunnel at the place where it crossed I against the wall and was thinking seriously about going to sleep when I the thud of ascii Hi from from from of useless knowledge the data that we were in tunnel at the place where it crossed I against the wall and was thinking seriously about going to sleep when I the thud of   \n",
       "1611                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              Best CIVIL MINISTRY AND   \n",
       "1613                                                                                                                                                                                                                                                                                                                                                                                                                             Finally accept my goodwill my dear friend Thank you once again and may God bless you Aku   \n",
       "1632  Hi Hello Smart Player We know you want to avoid noisy Why dont you get better odds ist he best in the industry because we offer Excitement thrill and opportunity to enter the world of luxury gambling never been more rewarding Give us a try Free is ON THE HOUSE Good luck to you and may your lucky never end Start Winning Now check The fish will soon be caught that at every bait He Long Who Well He who with the devil should have a long spoon The Best Fish Swim Near the Bottom yuh eye see Yester...   \n",
       "1636                                                                                                                                                                                                       To report a PRIVATELY please wrote To report a PRIVATELY please hi this list to be for white so Ill add my contribution Even with low I believe I found through snort report about WEB remote include path Any contribution is welcome We are looking into it thanks list To report a PRIVATELY please mailman   \n",
       "1652  Question from Member Respond Now sent this message on behalf of an member through My sent will not reach the member Question from Activity with last days I have bid on from Positive feedback Member since Location CA United Registered on This is the last time I send the money in advance to people like you Its been and no answer You stole my birthday money you thief This wont end like this I will contact and and go to jail Respond to this question in My will not include your address Thank you ...   \n",
       "1654                                                                                                                                                                                                                                                                                                                                                    Dear Sir Good day and how are you I the BUDGET TRIP INTERNATIONAL Could you please check through these group and get back to me best you assist with them ADD ADD   \n",
       "1657                                                                                                                                                                                                                                                                                                                                                                                                                                       Check out the new free of storage and industry leading and us protection FE FA   \n",
       "1682                                                                                                                                                                                                                                                                                                                                                                                                                               Furthermore contact your agent as instructed above and accept my Morgan West ordinator   \n",
       "1721                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              me to the best pharmacy   \n",
       "1767  THIS IS TO OFFICIALLY INFORM YOU THAT WE HAVE YOUR CONTRACT INHERITANCE FILE AND FOUND OUT THAT WHY YOU HAVE NOT RECEIVED YOUR PAYMENT IS BECAUSE YOU HAVE NOT THE GIVEN TO YOU IN RESPECT OF YOUR CONTRACT INHERITANCE PAYMENT SECONDLY WE HAVE BEEN INFORMED THAT YOU ARE STILL DEALING WITH THE NONE IN THE BANK AND ALL YOUR ATTEMPT TO SECURE THE RELEASE OF YOUR FUND PROVED ABORTIVE WE WISH TO ADVISE YOU THAT SUCH AN ILLEGAL ACT LIKE THIS HAVE TO STOP IF YOU WISH TO RECEIVE YOUR PAYMENT SINCE WE H...   \n",
       "1774                                                                                                                                                     I have the fee for your Cheque Draft Because the manager of told me that before the check will get to you that it So i told him to cash however all the necessary the in cash was made with Global Company This is the information they need to delivery your you The only money you have to send to them is there security which is Us to received your package   \n",
       "1781                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Best Sunny Mail sent from service at   \n",
       "1845                                                                                                                                                                                                                                                                                                                             in this matter until the task is accomplished as I don want ing that will Jeopardize my due to the fact that i do not want or family standing in the way of my last wish love el Te Part   \n",
       "1875                           and all its own North Black White Butterfly Blue and Golden Beige All block production is sold to both the local and international The Group is very price on all its due to its low overhead structure All ar ideally produced for gang saw and dimension of are Smaller are also available for selection We will feel it an if we could serve you and welcome your inquiry i our Looking forward to hearing from you Sincerely yours Department STONE GROUP Fortune Building North China   \n",
       "1942                                                                                                                                                                                                                                                                                                                            Hi from from from How do we find it I havent the idea I just said that to get off my neck ascii Hi from from from How do we find it I havent the idea I just said that to get off my neck   \n",
       "2018                                                                                                                                                                                                                                                                                                                                                                                                 that I shall provide you with more of this operation Your response to this letter will be I await your response POON   \n",
       "2022  to you My name is and I am an artist I live in with my two four one dog and the love of my life It is definitely a full house I have been doing since I was a small child That me about of experience I in art in high school and took a few college art Most of my work is done in either pencil or air brush mixed with color I have recently added designing and art work on the computer I have been selling my art for the last and have had my work featured on trading and in I have sold and to private ...   \n",
       "2046                                                              for you as the foreign partner for I and my We shall be on your advice as regard investment of our share in any business in your country Be informed that this business is genuine and safe considering the high power government involved Send your private telephone Upon your response we shall provide you with further information on the your prompt positive response as I Look forward to a good business relationship with you Sincerely Baker   \n",
       "2143                                                                                                                                                                                Mutual System Dear Mutual member By this letter we inform you that our bank is switching to security Mutual security require that your card is compatible with our new Mutual and hardware will be Go to Mutual Banking We offer you a new convenient and safe high quality level of service to handle your card Thank you for Mutual   \n",
       "2161                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         We Welcome You To Your Offer   \n",
       "2176                                   am Camara From the Federal Republic but presently in political problem humbly wish to inform you in my proposal that I have about of metal carat and purity and Rough Diamond to my financial status I have decided to kilo quite below the world market price shall discuss other vital information and to the origin to you immediately your interest may reply through my alternate mail address me on my telephone line I am looking forward to receive your reply truly Patty   \n",
       "2214                                                                                                                                                                                                                                                                                                                                                                                                                                        Find a local pizza ace movie theater and more then map the best route Find it   \n",
       "2273                                                                                                                                                                                                                                                                                                                                                                                                                                                            web mail and HALF PRICE for the first Save A a month Part   \n",
       "2278                                                                                                                                                                                                                                                                           Dear Western Union We are sorry for invoice we had some in our data Please update your profile You can access your profile at asp asp For help please contact Western Union Customer Service immediately by at or call us at Thank you for   \n",
       "2313                                                                                                                                                                                                                                                                                                                                   POT pour la elle de mille dont era sera sur place en te si bien en possession code dire A informer us imp en contact Numero de Tele phone Profession car in de de gain Pour inform   \n",
       "2327  HOTEL COTE me la de mon re tait un de cacao bas la de la te em par de rencontre pour dis sur de cacao la mort de ma re mon re a si pour sa mort a la de sept millions un locale a confirm re de en a en outre tait cause de richesse a par un de de parole un de on aider mon argent depart ai la situation de la me ai jours a si de trouble sans En ce moment te parle la presence on la car dis la presence de a eu re ce me demander ton service ce service de aider un aider reception de ce message de man...   \n",
       "2330                                                                                                                                                                                                                                                                                                                                                                                                                                                         Remain blessed in the name of the Lord Yours in Harry Hakeem   \n",
       "2369  Dear Sir I should appreciate your surprise while this letter In I am left with no option but to contact you in this manner to you was informed by knowledge that being established you could be disposed to understand my predicament in order to give assistance I require I am Frank the son of a late Sierra late the owner of Mining Company who few ago when the Revolutionary United our residence on the of in Following the cease fire agreement which was last year with of United Nation peace keeping...   \n",
       "2387  MISSIONARY QUARTERS A CHURCH ROAD SEND REPLY TO MY PRIVATE BOX respectful feel good you today I have read from your add in quiet well that this contact will bring a lasting relationship With regard to your reputation and of God who will me nor deny me in faith I am this letter to you I am Miss the only daughter of of Zimbabwe in desire to get somebody who will safe guard that of my junior brother and this money Briefly was a Gold and Cocoa merchant who based in cote and had a branch office h...   \n",
       "2401  Hello I am Barry Commercial Loan Officer at Bank in the ted Kingdom I am sorry for this medium to contact you as it is unsecure but I have no choice as it is the only medium I can use in contact with you that is quick as this matter is in dire need of urgent attention I would want you to assist in a business venture A Two Million Six Hundred Thousand but have to be sure that you are willing to indulge in this transaction Please kindly get back to me if you are interested so I can furnish you...   \n",
       "2427  Loan Office Bank Lane New United Kingdom barry Hell I am Barry Commercial Loan Officer at Bank in the United Kingdom I am sorry for this medium to act you as it is highly unsecure but I have no choice as it is the only I can use in contact with you that is quick as this ma is in dire need of urgent attention I would want yo to assist in a business venture A Two Million Six Hundred Thousand but have to be sure that you are wi to indulge in this transaction Please kindly get back to me if you ...   \n",
       "2439  Unpaid Item Strike Received You have received an Unpaid Item strike You were the winning buyer on item The seller informed that payment for the item still not been received or that the two of you were not able to come to agreement As a result you have received an Unpaid Item strike Remember Unpaid Item may result in your suspension from You can appeal this Unpaid Item strike if you believe it is not deserved First read the for appealing the strike If you meet them you can submit your appeal ...   \n",
       "2441                                                                                                                                                                                                                                                                                                                                                                                                     Could you also include your contact address and your private mobile phone number for easy communication Best Son   \n",
       "2461                                                                                                                                                                                                                                                                                                                                                                                               looking forward to your punctual response Send also your contact phone number for oral Best Peter i jumpy it Directory   \n",
       "\n",
       "      unsecure_link_count  secure_link_count  numbers_count  word_count  fraud  \n",
       "19                      0                  0              1          35      1  \n",
       "35                      1                  0              1          18      1  \n",
       "49                      0                  0              0          11      1  \n",
       "138                     0                  0             55         550      1  \n",
       "149                     1                  0              1          13      1  \n",
       "189                     1                  0             15          17      1  \n",
       "220                     0                  0             23         675      1  \n",
       "229                     7                  0             49         606      1  \n",
       "276                     0                  0             11          32      1  \n",
       "479                     1                  0              5          11      1  \n",
       "551                     0                  0              0          66      1  \n",
       "600                     0                  0              3          34      1  \n",
       "601                     3                  0            121         742      1  \n",
       "603                     0                  0              2          58      1  \n",
       "608                     0                  0              0          89      1  \n",
       "641                     0                  0              1          60      1  \n",
       "644                     0                  0              4          32      1  \n",
       "761                     0                  0              0          41      1  \n",
       "794                     0                  0              2           5      1  \n",
       "818                     0                  0              0         100      1  \n",
       "823                     0                  0              7           8      1  \n",
       "851                     0                  0             11          12      1  \n",
       "852                     0                  0              0          14      1  \n",
       "868                     1                  0              7          69      1  \n",
       "932                     1                  0              8           8      1  \n",
       "939                     0                  0              0           6      1  \n",
       "946                     0                  0             18         398      1  \n",
       "956                     0                  0              0         184      1  \n",
       "989                     4                  0             19         202      1  \n",
       "998                     0                  0              0          10      1  \n",
       "1026                    0                  0              0           7      1  \n",
       "1044                    0                  1              2         239      1  \n",
       "1087                    0                  0              1          28      1  \n",
       "1105                    0                  0              9         137      1  \n",
       "1198                    0                  0              3          48      1  \n",
       "1278                    0                  0            324        1794      1  \n",
       "1284                    1                  0              2          11      1  \n",
       "1289                    0                  0              2           5      1  \n",
       "1317                    0                  0              2          52      1  \n",
       "1407                    1                  0              8         386      1  \n",
       "1426                    1                  0             21         658      1  \n",
       "1459                    2                  0             16          76      1  \n",
       "1611                    0                  0              0           4      1  \n",
       "1613                    0                  0              0          17      1  \n",
       "1632                    1                  0              6         110      1  \n",
       "1636                    1                  0              3          55      1  \n",
       "1652                    3                  0             13         248      1  \n",
       "1654                    0                  0              1          32      1  \n",
       "1657                    0                  0             10          16      1  \n",
       "1682                    0                  0              0          13      1  \n",
       "1721                    1                  0              2           5      1  \n",
       "1767                    0                  0             11         248      1  \n",
       "1774                    0                  0              8          71      1  \n",
       "1781                    0                  0              0           7      1  \n",
       "1845                    0                  0              3          40      1  \n",
       "1875                    0                  0              5          85      1  \n",
       "1942                    2                  0             12          46      1  \n",
       "2018                    0                  0              0          22      1  \n",
       "2022                    0                  0              8         363      1  \n",
       "2046                    0                  0              5          76      1  \n",
       "2143                    0                  0              0          59      1  \n",
       "2161                    0                  0              0           6      1  \n",
       "2176                    0                  0             29          82      1  \n",
       "2214                    0                  0             10          16      1  \n",
       "2273                    0                  0              7          13      1  \n",
       "2278                    0                  1              4          44      1  \n",
       "2313                    0                  0             20          37      1  \n",
       "2327                    1                  0             73         152      1  \n",
       "2330                    0                  0              0          12      1  \n",
       "2369                    0                  0             12         436      1  \n",
       "2387                    0                  0             15         445      1  \n",
       "2401                    0                  0             24         137      1  \n",
       "2427                    0                  0             14         147      1  \n",
       "2439                    0                  0              2         133      1  \n",
       "2441                    0                  0              9          19      1  \n",
       "2461                    1                  0              1          20      1  "
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the false negative predictions\n",
    "wrong_pred[wrong_pred['fraud'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870a3589",
   "metadata": {},
   "source": [
    "Looking at the messages the model identified as false negatives seem to often relate to several forms of fraud. One such example is when the sender pretends to be starting a business venture with a need for initial capital, a legal institution or some unusual business. The others seem to be short with a link potentially leading to a fraudulent website. These were likely missed by the model due to a lack of words within them relating to fraudulent emails thus preventing the model from identifying them. With further examples and training, it is possible would be able to correctly identify these types of emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ddb8144c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>unsecure_link_count</th>\n",
       "      <th>secure_link_count</th>\n",
       "      <th>numbers_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Weekly Newsletter Reseller Corp Net One World Hosting Superb More Live tech help now Choice million open News Top Senior editor and Dear Your if its anything like mine works like a very large boat It slowly it turns slowly and sometimes it Take rogue wireless for example For many now some mischievous have been hacking into major and off for neighborhood wireless Only now later are doing something about it And what about Could they break into your service provider Probably Thankfully you can ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>371</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Investor Dispatch Quote symbol Symbol My Portfolio Broker Live tech help NOW tech award million open News Top TECH News Vision News exclusive of top Vision Series home Tech stocks drop again on criminal probe news Word International is being by the office in send technology lower Despite a Lynch upgrade of Cisco and the fact that Morgan coverage on Time Warner with a buy rating Tech index fell or percent to The tech heavy composite index lost or percent to a year low also shed value dragged ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>hope you are well i in on a little i sent to he got screwed with just like and countless the will help you will see that they haVe a group of sexual over there no they are not in the ass per say but they are shay i think in this business are pretty much some of the best and some of it is the responsibility to the good from the bad until they and can be removed in this case the ugly are running the damn thing or incase of joe are too to recognize the truth or no power to change it in the even...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>The Public Library Board the library on city of does not a bank loan of up to million and property tax receipts are</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>Digital Dispatch Weekly Newsletter All The Web Apple to expand display It aint heavy its my Gateway chic yet cheap comes to Dell coming to a mall near you More News Quintessential Player AI Picture Utility a Build Deck for the Mac Dell Latitude series In Hardware Pocket In Electronics In In Wireless editor in chief Dear It was a crushing blow to discover that my all time favorite Palm was no longer free Twenty five wasnt steep but the principle of paying for a former was hard to swallow Not ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>Open Source Convention From the of Research to the Heart of the Enterprise San Hotel and Marina San CA os CONFERENCE NEWSLETTER UPDATE Conference News One Day Pass Offer Conference Sterling on Open Source See Do Out at World Its not just about you know Conference In the tradition of their get past the fluff and of other and home in directly on the meat of the technology Hall from Plug the area Group CONFERENCE NEWS ONE DAY PASS ADDED TO CONFERENCE If you cant swing the whole conference but c...</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>Dear Our indicate that you have either or the Fall Commuter Application If you no longer wish to have a commuter meal plan for the spring semester you do not need to do anything If you are an commuter student and wish to have a Spring meal plan you will need to complete the Spring Commuter Application and select a meal plan for the Spring Term If you are an athlete that a meal plan scholarship Please note that the meal plan is covered under that scholarship If you select a meal plan other th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>You are this because you up to receive one of our free If you would prefer not to receive of this type please by following the at the bottom of this message Dear Investor Thank you again for our free special report The One Stock that Wall Street BUZZING We The Motley Fool in with the idea that like you deserved better Better than Wall Streets all too often research Better than who speak in secret them to hedge or spin any recommendation and better than what for full financial disclosure in b...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>607</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>by Dull by ex From Bell Lori yahoo Inside me theres a thin woman screaming to get out But I can usually shut the bitch up with some chocolate</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>Investor Dispatch Quote symbol Symbol My Portfolio Broker Live tech help NOW tech award million open News Top TECH fall again with Dow below The day after Group for bankruptcy protection and drag down the tech sector stock tumbled percent after it Wall Streets earnings target and a worse than outlook With of International Sprint and AT also dropping Tech index shed or percent to The tech heavy composite index fell or percent to With a report raising about and Morgan Chase role in the fiasco ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>504</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>be careful when this one Also that really cute thing that do of leaving their panties on one leg while making love Dare I ask what a girl is Yahoo Sponsor Free Join Now us click yahoo To from this group send an to Your use of Yahoo is subject to yahoo</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627</th>\n",
       "      <td>BIG OR BUST This weekend you can see the State State and the University of LIVE AND EXCLUSIVELY ON THE BIG football Now you can see your favorite play even if you cant get to a live game or its not on with to bring Big football LIVE that put you in the even from home The best part you can get ALL of the and exclusive Big news and coverage by becoming a member of With you get All Big and exclusive coverage Unaired video footage from FOX Sports and FOX Sports Net Exclusive video from like and ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>the free was a senior fellow at the Institution from to and as the and director of the Global Economy and Development program from June to March been nominated by President to be Under Secretary of the Treasury as Deputy National Economic Adviser and Chair of the Deputy Committee Economics during the Administration As Deputy Director of the National she build a new White House organization to address global economic such as financial crisis and China entry As the US to the she shape the Deve...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>lead to bankruptcy Search News All The Web Live tech help NOW tech award million open News Top lead to bankruptcy flaw Web wing for firm out new Adobe flaw finish Grid foundation science Building chips Do we need a national ID plan A White House proposal a privacy Read Full Story lead to bankruptcy giant for bankruptcy the such action in history though its hardly alone The company it will emerge may get caught holding a dead line AM Read Full Story flaw Web A flaw found in of the Web server ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>596</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>Just saw the to account Will follow up with and Nelson</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>from The Register To from this daily news update see the at the end of this message ADVERTISEMENT WIN to a FORMULA ONE GRAND Group business continuity expert driver of the team Click here to find out more and win For every new customer that between the Grand season Group will grant to a Grand hospitality event with us next season goes gold good content contract with Unfortunate deal minister content to use for home wireless security Its tagged as a possible for a future client content Enterp...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>71</td>\n",
       "      <td>345</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>Dear we schedule a call I have several I like to discuss you this weekend and was we can schedule a call I free tomorrow am and ham and after Do any of those times work for you And by the way I still laughing about the yurt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>Good afternoon I understand from the COVID Main that you have received your second dose of the COVID vaccine however we are trouble opening the picture you sent of your ID card Please send the picture again to this address As soon as we receive and are able to open it I add you to our system Drake Contact Tracing Team</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>Here is the situation as I understand it The film festival returned funds that it had received from the Embassy after from some film Ken Loach and solidarity The director is now being funded directly by the festival The a sort of apology today We have not been able to locate any State response to similar in the past toa conference</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>Here are some I haven raised you but to get your reaction Was there any to offer to help advise on Re your memo about for and Will we be the global fund and or other at Are we closely the and its Council How can we strengthen the AID office Are the Congress our work and so far What about the budget Who will be the UN voice on the inside and outside How will we mark th of Let do a thorough review about strategy Should we ask to be on contract to lead What Are you working Alec Ross Are you wor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>Good morning As we prepare for Weekend we want to state the following each and every one of us Drake University Respect each other respect yourself and watch over each other during as we continue to navigate COVID If you plan on in any please do so in a manner that ultimately the best of who you are and who we are as Drake University you do not want to be a headline in a news story Be very conscientious of theme based we are an institution that If you or someone you are with needs assistance...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>936</th>\n",
       "      <td>Tech Specialist and crackers respect only one thing strong security Keep the bad out of your or network with the advanced technology thats by millions Pro This best in class personal cold your privacy and up in Click here to now As if there werent enough hypocrisy and misinformation being by marketing and This time a startling revelation that to use their own Server to protect themselves from the very the product is meant to stop and intrusion was turned loose within and chosen series securi...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>925</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>955</th>\n",
       "      <td>I didnt get it to my State account So but I see it here now I get going on them</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>to say hello to you Please look out for him Thanks</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>Weekly Newsletter All he Web Site Map Input Memory Storage Electronics Digital th Socket Processor Micron Pioneer Video Bit Sound Card Ultra Bidding at Dont miss out place your bid now Drive Starting Bid Printer Copier All in One Starting Bid Starting Bid Digital Starting Bid Gateway inch Flat Panel Color Monitor Starting Bid Bit Sound Starting Bid inch All Starting at Ending Ending Ending Ending inch inch Sun inch Sun inch inch Canon Bit Scanner Starting Bid Gateway Starting Bid IDE Hard Dr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>me know if I can be of any help to your department and will happy to do and please on behalf of me and supporting Thank</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211</th>\n",
       "      <td>Attached and below is the concept for a technology dinner that would lead up to speech Concept Paper for Dinner on Connection Warrior CISCO Carol Yahoo and Ford Foundation Chairman or Apple and Pesa Ory Jack Twitter Square Eric Mobile Accord Slim or Mo former and now Mo Clay Shirky</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234</th>\n",
       "      <td>We re the Access Agreement When you enrolled in Business Mobile or you and accepted our Access Agreement An version of the will go into effect on May You can view a summary of and view the This notice is simply to let you know of these you don need to do anything Your continued use or access of Business Mobile or your agreement with these Thank you for choosing Investment and Insurance are Not Insured by the or Any Federal Government Agency Not a Deposit or Other Obligation of or by the Bank...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>Madame you re to give a minute talk at a gala by the Task Force a moderate pro peace organization Here a quick overview of our speech which we with NEA Please let us know if you have any The audience in the room will include who are influential in their business Of course a much audience beyond the room will read this speech aswell This is your first opportunity to address this issue in a serious way since the end of the moratorium Key</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>Oh darn it sorry I your message I was engrossed in the script If you re still up please call</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1303</th>\n",
       "      <td>Virus Security Newsletter Associate and Dear So far been a year marked with on If you update your antivirus on a regular basis these new of and shouldnt be a nuisance But if you havent in a while these plus the threat of should motivate you In security news a flaw in certain of encryption could affect Outlook Read on to learn whether vulnerable worm to give you a password An mail message that to reveal secret information with a password is yet another variant from the pesky worm family techn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>As I last week I was on a panel at the forum with Lady who everyone call president and Senator and I essentially each other at and a very positive vision of US EU partnership She scored some significant lately that development will be included in the Action Service rather than sitting at a separate desk the formula we are seeking rather than the formula EU defense staff will also be included in the the Council whenever the foreign development or defense the ultimate frame She also control ov...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>Did some research on Saving like it is funded interior is Senate Norm is house chair will likely take over for as he to take over defense subcommittee Happy to weigh in with both but you are also seeing Senator this week for dinner We can prepare paper for her staff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>Hi Thanks for the help why do I have the feeling that will answer this one sorry if I disappointed you no not at all Faithful Red Hat user since Registered User counter li Get your free from Powered by Outblaze List list net mailman list</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>From one of the we hired who had been working with from the and Donor Trust Fund The Government of to the Tsunami by issuing a series of government immediately organized both overview and relief to ensure a rational and The first task was to produce a Damage and Loss Assessment The was more detailed Master Plan for Rehabilitation and Reconstruction The provided in spatial the governance and supervision of attention to how to avoid or minimize corruption The process behind the with a wide ran...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1541</th>\n",
       "      <td>Mohr said If you plan to spend most of your time in that broke unemployed unexceptional mode please leave North for I might at least got affordable there and havent a like law yet mailman fork</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Alert When make sure the reseller manufacturer the rebate coupon you need Get a car adapter and power adapter FREE with Rio Volt August off SideWinder Strategic Commander off Rio off off March off Natural Keyboard Pro Digital Premier merchant Connection Premier merchant Connection Premier merchant A Shot Premier merchant Gateway More Top Selling Dear Reader Basic electronic theyre not but if searching for a pocket sized computer for music and then these are well worth a look All four feature...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>Attached and below is the and letter that went out reflecting your SUBJECT LETTER PRIOR TO AUGUST A STATE STATE This is an action request see On August the and agreed ad referendum to the text of Defense Agreement We expect the final agreement may be in a month following a final review by both sides in the would permit the United to several military bases and bilateral on security It would authorize establishment of bases or nor would it result in an in the number of military personnel citiz...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>578</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>Please print for in color if possible</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1692</th>\n",
       "      <td>chief of staff at By the chief of staff to House Republican Leader unexpectedly night according to the leader office She was It is with profound sadness and shock that I announce the passing of chief of staff aide and friend who suddenly last night in a statement early afternoon can not adequately express the disbelief I and every member of our team are grappling with today in the wake of news A aide said the cause was an apparent heart attack President and Speaker Nancy were among those to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>778</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1732</th>\n",
       "      <td>to Remove Assistance for From Foreign Aid Oversight on Corruption in In light of two troubling news on corruption within the government Chairwoman of the State and Foreign Subcommittee today is removing for beyond humanitarian aid from her bill for markup this week The shipment of in donor funds out of and of government corruption are outrageous said I do not intend to appropriate one more dime to until I have confidence that taxpayer money is not being to line the government drug and Furthe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>Importance Secretary You have about the regarding the from in from the New Refuge who are currently being with child abduction and criminal association law Depending on the intent we believe the would have the following basic Please let us know if you need more information and especially if you would like us to contact further</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771</th>\n",
       "      <td>Jake IN state Re Are you there yet Declassify on As usual your showing up in my State account Still working on that problem We met with Bibi for today Happy to talk secure at your convenience The are as On Wed at wrote Anything happening</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1812</th>\n",
       "      <td>Good day On wrote as I see it there is a valid need for a razor cache server that is available to the local host would also be a nice feature giving us the option to link to the burden on the razor it could also allow us to setup local razor for private that can bypass the razor all together any razor proxy is what looking for for the razor protocol The equivalent for razor is on hold pending documentation of the razor protocol Jordan is that still in the finishing stage smile betting that t...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>Please print the message below from Embassy which some further background From Embassy I was the Huntsman me to give you a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>This document in text below is coming up the line to you as material for your trip This is separate but related to today This on the the tsunami model as a guide I also have Jean to put together a think piece for this evening that we can look at re the issue efficient effective of lateral investment and private fund that come together in a coherent fashion Of not in this memo is fact that in tsunami there was a GOI below on the Mu It Donor Trust BUT UNCLASSIFIED INFORMATION MEMO FOR THE SECR...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1935</th>\n",
       "      <td>Below is the article I Tack on Discuss Plan to Rid Region of Nuclear in Effort to Steal Thunder at JAY and JOE is with a proposal to make the Middle East a region free of nuclear as the prevent from a conference on nuclear that familiar with the move call it an important step in assuring that by its silence about undeclared nuclear arsenal will equitably address proliferation across the region to shift focus away from its own nuclear program also reassured it won foist a nuclear free zone on...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>704</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>been about this whole deal but this whole experience been fascinating Some absolutely no for and then pop out of nowhere and say yes like for then decide not to give us a penny Therefore we have to keep these We WILL raise the money We are at this came in for and and need Ideally we would like to raise to to cover any it getting more expensive because the US late we are paying more now to build it Where it will come from A Right now we have three big talking to us in the range may go from If...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>The following that are registered as belonging to you are due to expire within the next days If you would like to renew them please contact otherwise they will be and may be registered by another Domain Name Expiry Date</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>Hi Happy You previously applied to our Data Analytics Analyst Life opportunity with was with your application it with another manager for a different position he you could be a good fit for if you re interested This position is a Life Product Support Analyst to Mike Here is the direct link to learn more about the opportunity home requisition Please let me know either way if you are interested If you are I can move your application without you to go through the application process again We lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>news hi Yahoo Sponsor Free Join Now us click yahoo To from this group send an to Your use of Yahoo is subject to yahoo</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051</th>\n",
       "      <td>March on that will appear on page to make sure you had a up Slaughter is a professor of politics and international at By the noose is around Col al In fact it around the as Colonel the most of the world rebel tow The United and are temporizing on a no flight the Organization of the Conference the Gulf Council and now the have all on the United Security Council to authorize one of a no flight zone have put forth five main none of which on closer examination hold up It not in our interest Gen ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2081</th>\n",
       "      <td>Jake Want to make sure you saw the front page story below It really about the tragedy of wrongfully but it clear that is doing the a great service and been more courageous in this regard than most world although is in many ways more vulnerable to China The Secretary re this was a right after upset the as you feared in a meeting I will give you a confidential report on separately Jeff Grim Tale Of Loyalty And Leave Post Staff a at the military prison at Bay learned a few ago that island natio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>937</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>Red Hat Network determined that the following advisory is applicable to one or more of the you have registered Complete information about this errata can be found at the following location network errata Security Advisory Summary New kernel update available i video several security kernel are now available which fix an in the i kernel code This kernel update also a difficult to trigger race in the cache code as well as some potential security although we are not currently aware of any Descri...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>On August at AM wrote An information leakage vulnerability in and access the unique community string As a result an attacker can query the community string and gain the ability to change system configuration Wired Equivalent Privacy and Domain Name Service information I think this is missing the point a bit Yes you can query the community string And yes its the default not to mention the and last of the default key But theyre all easily and indeed it is highly to do so in the manual Anyone w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2353</th>\n",
       "      <td>First Happy New Year to and Stern clan Hope to talk soon about our way forward for I received the following from over the I intend to respond in kind but to run for advice Dear Madam Secretary of State It was wonderful catching up with you in The opportunity to interact with President and you at last minute to salvage the Accord at the US BASIC Summit Meeting was fantastic and unforgettable forme personally I am still from that historic With for and best for the New</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  content  \\\n",
       "89    Weekly Newsletter Reseller Corp Net One World Hosting Superb More Live tech help now Choice million open News Top Senior editor and Dear Your if its anything like mine works like a very large boat It slowly it turns slowly and sometimes it Take rogue wireless for example For many now some mischievous have been hacking into major and off for neighborhood wireless Only now later are doing something about it And what about Could they break into your service provider Probably Thankfully you can ...   \n",
       "93    Investor Dispatch Quote symbol Symbol My Portfolio Broker Live tech help NOW tech award million open News Top TECH News Vision News exclusive of top Vision Series home Tech stocks drop again on criminal probe news Word International is being by the office in send technology lower Despite a Lynch upgrade of Cisco and the fact that Morgan coverage on Time Warner with a buy rating Tech index fell or percent to The tech heavy composite index lost or percent to a year low also shed value dragged ...   \n",
       "171   hope you are well i in on a little i sent to he got screwed with just like and countless the will help you will see that they haVe a group of sexual over there no they are not in the ass per say but they are shay i think in this business are pretty much some of the best and some of it is the responsibility to the good from the bad until they and can be removed in this case the ugly are running the damn thing or incase of joe are too to recognize the truth or no power to change it in the even...   \n",
       "266                                                                                                                                                                                                                                                                                                                                                                                                   The Public Library Board the library on city of does not a bank loan of up to million and property tax receipts are   \n",
       "278   Digital Dispatch Weekly Newsletter All The Web Apple to expand display It aint heavy its my Gateway chic yet cheap comes to Dell coming to a mall near you More News Quintessential Player AI Picture Utility a Build Deck for the Mac Dell Latitude series In Hardware Pocket In Electronics In In Wireless editor in chief Dear It was a crushing blow to discover that my all time favorite Palm was no longer free Twenty five wasnt steep but the principle of paying for a former was hard to swallow Not ...   \n",
       "331   Open Source Convention From the of Research to the Heart of the Enterprise San Hotel and Marina San CA os CONFERENCE NEWSLETTER UPDATE Conference News One Day Pass Offer Conference Sterling on Open Source See Do Out at World Its not just about you know Conference In the tradition of their get past the fluff and of other and home in directly on the meat of the technology Hall from Plug the area Group CONFERENCE NEWS ONE DAY PASS ADDED TO CONFERENCE If you cant swing the whole conference but c...   \n",
       "363   Dear Our indicate that you have either or the Fall Commuter Application If you no longer wish to have a commuter meal plan for the spring semester you do not need to do anything If you are an commuter student and wish to have a Spring meal plan you will need to complete the Spring Commuter Application and select a meal plan for the Spring Term If you are an athlete that a meal plan scholarship Please note that the meal plan is covered under that scholarship If you select a meal plan other th...   \n",
       "382   You are this because you up to receive one of our free If you would prefer not to receive of this type please by following the at the bottom of this message Dear Investor Thank you again for our free special report The One Stock that Wall Street BUZZING We The Motley Fool in with the idea that like you deserved better Better than Wall Streets all too often research Better than who speak in secret them to hedge or spin any recommendation and better than what for full financial disclosure in b...   \n",
       "435                                                                                                                                                                                                                                                                                                                                                                         by Dull by ex From Bell Lori yahoo Inside me theres a thin woman screaming to get out But I can usually shut the bitch up with some chocolate   \n",
       "554   Investor Dispatch Quote symbol Symbol My Portfolio Broker Live tech help NOW tech award million open News Top TECH fall again with Dow below The day after Group for bankruptcy protection and drag down the tech sector stock tumbled percent after it Wall Streets earnings target and a worse than outlook With of International Sprint and AT also dropping Tech index shed or percent to The tech heavy composite index fell or percent to With a report raising about and Morgan Chase role in the fiasco ...   \n",
       "618                                                                                                                                                                                                                                                           be careful when this one Also that really cute thing that do of leaving their panties on one leg while making love Dare I ask what a girl is Yahoo Sponsor Free Join Now us click yahoo To from this group send an to Your use of Yahoo is subject to yahoo   \n",
       "627   BIG OR BUST This weekend you can see the State State and the University of LIVE AND EXCLUSIVELY ON THE BIG football Now you can see your favorite play even if you cant get to a live game or its not on with to bring Big football LIVE that put you in the even from home The best part you can get ALL of the and exclusive Big news and coverage by becoming a member of With you get All Big and exclusive coverage Unaired video footage from FOX Sports and FOX Sports Net Exclusive video from like and ...   \n",
       "628   the free was a senior fellow at the Institution from to and as the and director of the Global Economy and Development program from June to March been nominated by President to be Under Secretary of the Treasury as Deputy National Economic Adviser and Chair of the Deputy Committee Economics during the Administration As Deputy Director of the National she build a new White House organization to address global economic such as financial crisis and China entry As the US to the she shape the Deve...   \n",
       "631   lead to bankruptcy Search News All The Web Live tech help NOW tech award million open News Top lead to bankruptcy flaw Web wing for firm out new Adobe flaw finish Grid foundation science Building chips Do we need a national ID plan A White House proposal a privacy Read Full Story lead to bankruptcy giant for bankruptcy the such action in history though its hardly alone The company it will emerge may get caught holding a dead line AM Read Full Story flaw Web A flaw found in of the Web server ...   \n",
       "679                                                                                                                                                                                                                                                                                                                                                                                                                                                                Just saw the to account Will follow up with and Nelson   \n",
       "697   from The Register To from this daily news update see the at the end of this message ADVERTISEMENT WIN to a FORMULA ONE GRAND Group business continuity expert driver of the team Click here to find out more and win For every new customer that between the Grand season Group will grant to a Grand hospitality event with us next season goes gold good content contract with Unfortunate deal minister content to use for home wireless security Its tagged as a possible for a future client content Enterp...   \n",
       "893                                                                                                                                                                                                                                                                                       Dear we schedule a call I have several I like to discuss you this weekend and was we can schedule a call I free tomorrow am and ham and after Do any of those times work for you And by the way I still laughing about the yurt   \n",
       "901                                                                                                                                                                                       Good afternoon I understand from the COVID Main that you have received your second dose of the COVID vaccine however we are trouble opening the picture you sent of your ID card Please send the picture again to this address As soon as we receive and are able to open it I add you to our system Drake Contact Tracing Team   \n",
       "929                                                                                                                                                                          Here is the situation as I understand it The film festival returned funds that it had received from the Embassy after from some film Ken Loach and solidarity The director is now being funded directly by the festival The a sort of apology today We have not been able to locate any State response to similar in the past toa conference   \n",
       "934   Here are some I haven raised you but to get your reaction Was there any to offer to help advise on Re your memo about for and Will we be the global fund and or other at Are we closely the and its Council How can we strengthen the AID office Are the Congress our work and so far What about the budget Who will be the UN voice on the inside and outside How will we mark th of Let do a thorough review about strategy Should we ask to be on contract to lead What Are you working Alec Ross Are you wor...   \n",
       "935   Good morning As we prepare for Weekend we want to state the following each and every one of us Drake University Respect each other respect yourself and watch over each other during as we continue to navigate COVID If you plan on in any please do so in a manner that ultimately the best of who you are and who we are as Drake University you do not want to be a headline in a news story Be very conscientious of theme based we are an institution that If you or someone you are with needs assistance...   \n",
       "936   Tech Specialist and crackers respect only one thing strong security Keep the bad out of your or network with the advanced technology thats by millions Pro This best in class personal cold your privacy and up in Click here to now As if there werent enough hypocrisy and misinformation being by marketing and This time a startling revelation that to use their own Server to protect themselves from the very the product is meant to stop and intrusion was turned loose within and chosen series securi...   \n",
       "955                                                                                                                                                                                                                                                                                                                                                                                                                                       I didnt get it to my State account So but I see it here now I get going on them   \n",
       "1059                                                                                                                                                                                                                                                                                                                                                                                                                                                                   to say hello to you Please look out for him Thanks   \n",
       "1076  Weekly Newsletter All he Web Site Map Input Memory Storage Electronics Digital th Socket Processor Micron Pioneer Video Bit Sound Card Ultra Bidding at Dont miss out place your bid now Drive Starting Bid Printer Copier All in One Starting Bid Starting Bid Digital Starting Bid Gateway inch Flat Panel Color Monitor Starting Bid Bit Sound Starting Bid inch All Starting at Ending Ending Ending Ending inch inch Sun inch Sun inch inch Canon Bit Scanner Starting Bid Gateway Starting Bid IDE Hard Dr...   \n",
       "1186                                                                                                                                                                                                                                                                                                                                                                                              me know if I can be of any help to your department and will happy to do and please on behalf of me and supporting Thank   \n",
       "1211                                                                                                                                                                                                                           Attached and below is the concept for a technology dinner that would lead up to speech Concept Paper for Dinner on Connection Warrior CISCO Carol Yahoo and Ford Foundation Chairman or Apple and Pesa Ory Jack Twitter Square Eric Mobile Accord Slim or Mo former and now Mo Clay Shirky   \n",
       "1234  We re the Access Agreement When you enrolled in Business Mobile or you and accepted our Access Agreement An version of the will go into effect on May You can view a summary of and view the This notice is simply to let you know of these you don need to do anything Your continued use or access of Business Mobile or your agreement with these Thank you for choosing Investment and Insurance are Not Insured by the or Any Federal Government Agency Not a Deposit or Other Obligation of or by the Bank...   \n",
       "1254                                                              Madame you re to give a minute talk at a gala by the Task Force a moderate pro peace organization Here a quick overview of our speech which we with NEA Please let us know if you have any The audience in the room will include who are influential in their business Of course a much audience beyond the room will read this speech aswell This is your first opportunity to address this issue in a serious way since the end of the moratorium Key   \n",
       "1296                                                                                                                                                                                                                                                                                                                                                                                                                         Oh darn it sorry I your message I was engrossed in the script If you re still up please call   \n",
       "1303  Virus Security Newsletter Associate and Dear So far been a year marked with on If you update your antivirus on a regular basis these new of and shouldnt be a nuisance But if you havent in a while these plus the threat of should motivate you In security news a flaw in certain of encryption could affect Outlook Read on to learn whether vulnerable worm to give you a password An mail message that to reveal secret information with a password is yet another variant from the pesky worm family techn...   \n",
       "1355  As I last week I was on a panel at the forum with Lady who everyone call president and Senator and I essentially each other at and a very positive vision of US EU partnership She scored some significant lately that development will be included in the Action Service rather than sitting at a separate desk the formula we are seeking rather than the formula EU defense staff will also be included in the the Council whenever the foreign development or defense the ultimate frame She also control ov...   \n",
       "1439                                                                                                                                                                                                                                           Did some research on Saving like it is funded interior is Senate Norm is house chair will likely take over for as he to take over defense subcommittee Happy to weigh in with both but you are also seeing Senator this week for dinner We can prepare paper for her staff   \n",
       "1489                                                                                                                                                                                                                                                                        Hi Thanks for the help why do I have the feeling that will answer this one sorry if I disappointed you no not at all Faithful Red Hat user since Registered User counter li Get your free from Powered by Outblaze List list net mailman list   \n",
       "1514  From one of the we hired who had been working with from the and Donor Trust Fund The Government of to the Tsunami by issuing a series of government immediately organized both overview and relief to ensure a rational and The first task was to produce a Damage and Loss Assessment The was more detailed Master Plan for Rehabilitation and Reconstruction The provided in spatial the governance and supervision of attention to how to avoid or minimize corruption The process behind the with a wide ran...   \n",
       "1541                                                                                                                                                                                                                                                                                                                     Mohr said If you plan to spend most of your time in that broke unemployed unexceptional mode please leave North for I might at least got affordable there and havent a like law yet mailman fork   \n",
       "1599  Alert When make sure the reseller manufacturer the rebate coupon you need Get a car adapter and power adapter FREE with Rio Volt August off SideWinder Strategic Commander off Rio off off March off Natural Keyboard Pro Digital Premier merchant Connection Premier merchant Connection Premier merchant A Shot Premier merchant Gateway More Top Selling Dear Reader Basic electronic theyre not but if searching for a pocket sized computer for music and then these are well worth a look All four feature...   \n",
       "1609  Attached and below is the and letter that went out reflecting your SUBJECT LETTER PRIOR TO AUGUST A STATE STATE This is an action request see On August the and agreed ad referendum to the text of Defense Agreement We expect the final agreement may be in a month following a final review by both sides in the would permit the United to several military bases and bilateral on security It would authorize establishment of bases or nor would it result in an in the number of military personnel citiz...   \n",
       "1669                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Please print for in color if possible   \n",
       "1692  chief of staff at By the chief of staff to House Republican Leader unexpectedly night according to the leader office She was It is with profound sadness and shock that I announce the passing of chief of staff aide and friend who suddenly last night in a statement early afternoon can not adequately express the disbelief I and every member of our team are grappling with today in the wake of news A aide said the cause was an apparent heart attack President and Speaker Nancy were among those to ...   \n",
       "1732  to Remove Assistance for From Foreign Aid Oversight on Corruption in In light of two troubling news on corruption within the government Chairwoman of the State and Foreign Subcommittee today is removing for beyond humanitarian aid from her bill for markup this week The shipment of in donor funds out of and of government corruption are outrageous said I do not intend to appropriate one more dime to until I have confidence that taxpayer money is not being to line the government drug and Furthe...   \n",
       "1746                                                                                                                                                                             Importance Secretary You have about the regarding the from in from the New Refuge who are currently being with child abduction and criminal association law Depending on the intent we believe the would have the following basic Please let us know if you need more information and especially if you would like us to contact further   \n",
       "1771                                                                                                                                                                                                                                                                        Jake IN state Re Are you there yet Declassify on As usual your showing up in my State account Still working on that problem We met with Bibi for today Happy to talk secure at your convenience The are as On Wed at wrote Anything happening   \n",
       "1812  Good day On wrote as I see it there is a valid need for a razor cache server that is available to the local host would also be a nice feature giving us the option to link to the burden on the razor it could also allow us to setup local razor for private that can bypass the razor all together any razor proxy is what looking for for the razor protocol The equivalent for razor is on hold pending documentation of the razor protocol Jordan is that still in the finishing stage smile betting that t...   \n",
       "1819                                                                                                                                                                                                                                                                                                                                                                                           Please print the message below from Embassy which some further background From Embassy I was the Huntsman me to give you a   \n",
       "1866  This document in text below is coming up the line to you as material for your trip This is separate but related to today This on the the tsunami model as a guide I also have Jean to put together a think piece for this evening that we can look at re the issue efficient effective of lateral investment and private fund that come together in a coherent fashion Of not in this memo is fact that in tsunami there was a GOI below on the Mu It Donor Trust BUT UNCLASSIFIED INFORMATION MEMO FOR THE SECR...   \n",
       "1935  Below is the article I Tack on Discuss Plan to Rid Region of Nuclear in Effort to Steal Thunder at JAY and JOE is with a proposal to make the Middle East a region free of nuclear as the prevent from a conference on nuclear that familiar with the move call it an important step in assuring that by its silence about undeclared nuclear arsenal will equitably address proliferation across the region to shift focus away from its own nuclear program also reassured it won foist a nuclear free zone on...   \n",
       "1964  been about this whole deal but this whole experience been fascinating Some absolutely no for and then pop out of nowhere and say yes like for then decide not to give us a penny Therefore we have to keep these We WILL raise the money We are at this came in for and and need Ideally we would like to raise to to cover any it getting more expensive because the US late we are paying more now to build it Where it will come from A Right now we have three big talking to us in the range may go from If...   \n",
       "2009                                                                                                                                                                                                                                                                                          The following that are registered as belonging to you are due to expire within the next days If you would like to renew them please contact otherwise they will be and may be registered by another Domain Name Expiry Date   \n",
       "2024  Hi Happy You previously applied to our Data Analytics Analyst Life opportunity with was with your application it with another manager for a different position he you could be a good fit for if you re interested This position is a Life Product Support Analyst to Mike Here is the direct link to learn more about the opportunity home requisition Please let me know either way if you are interested If you are I can move your application without you to go through the application process again We lo...   \n",
       "2032                                                                                                                                                                                                                                                                                                                                                                                               news hi Yahoo Sponsor Free Join Now us click yahoo To from this group send an to Your use of Yahoo is subject to yahoo   \n",
       "2051  March on that will appear on page to make sure you had a up Slaughter is a professor of politics and international at By the noose is around Col al In fact it around the as Colonel the most of the world rebel tow The United and are temporizing on a no flight the Organization of the Conference the Gulf Council and now the have all on the United Security Council to authorize one of a no flight zone have put forth five main none of which on closer examination hold up It not in our interest Gen ...   \n",
       "2081  Jake Want to make sure you saw the front page story below It really about the tragedy of wrongfully but it clear that is doing the a great service and been more courageous in this regard than most world although is in many ways more vulnerable to China The Secretary re this was a right after upset the as you feared in a meeting I will give you a confidential report on separately Jeff Grim Tale Of Loyalty And Leave Post Staff a at the military prison at Bay learned a few ago that island natio...   \n",
       "2088  Red Hat Network determined that the following advisory is applicable to one or more of the you have registered Complete information about this errata can be found at the following location network errata Security Advisory Summary New kernel update available i video several security kernel are now available which fix an in the i kernel code This kernel update also a difficult to trigger race in the cache code as well as some potential security although we are not currently aware of any Descri...   \n",
       "2118  On August at AM wrote An information leakage vulnerability in and access the unique community string As a result an attacker can query the community string and gain the ability to change system configuration Wired Equivalent Privacy and Domain Name Service information I think this is missing the point a bit Yes you can query the community string And yes its the default not to mention the and last of the default key But theyre all easily and indeed it is highly to do so in the manual Anyone w...   \n",
       "2353                               First Happy New Year to and Stern clan Hope to talk soon about our way forward for I received the following from over the I intend to respond in kind but to run for advice Dear Madam Secretary of State It was wonderful catching up with you in The opportunity to interact with President and you at last minute to salvage the Accord at the US BASIC Summit Meeting was fantastic and unforgettable forme personally I am still from that historic With for and best for the New   \n",
       "\n",
       "      unsecure_link_count  secure_link_count  numbers_count  word_count  fraud  \n",
       "89                      0                  0             27         371      0  \n",
       "93                      0                  0             96         500      0  \n",
       "171                     0                  0              2         262      0  \n",
       "266                     0                  0              3          23      0  \n",
       "278                     0                  0             57         792      0  \n",
       "331                    13                  2             50         453      0  \n",
       "363                     0                  0              9         163      0  \n",
       "382                     4                  0             15         607      0  \n",
       "435                     0                  0              2          29      0  \n",
       "554                     0                  0            101         504      0  \n",
       "618                     2                  0              4          52      0  \n",
       "627                     0                  0              5         132      0  \n",
       "628                     0                  0             24         351      0  \n",
       "631                     0                  0             54         596      0  \n",
       "679                     0                  0              2          11      0  \n",
       "697                    25                  0             71         345      0  \n",
       "893                     0                  0             10          48      0  \n",
       "901                     0                  0              1          61      0  \n",
       "929                     0                  0              0          61      0  \n",
       "934                     0                  0              4         129      0  \n",
       "935                     0                  0              6         119      0  \n",
       "936                     7                  0             66         925      0  \n",
       "955                     0                  0              0          20      0  \n",
       "1059                    0                  0              0          11      0  \n",
       "1076                    0                  0             85         136      0  \n",
       "1186                    0                  0             14          26      0  \n",
       "1211                    0                  0             19          50      0  \n",
       "1234                    0                  0             16         146      0  \n",
       "1254                    0                  0              1          85      0  \n",
       "1296                    0                  0              0          20      0  \n",
       "1303                    0                  0             22         239      0  \n",
       "1355                    0                  0              1         174      0  \n",
       "1439                    0                  0              0          51      0  \n",
       "1489                    2                  0              2          46      0  \n",
       "1514                    0                  0             31         578      0  \n",
       "1541                    1                  0              0          36      0  \n",
       "1599                    0                  0             64         451      0  \n",
       "1609                    0                  0             16         578      0  \n",
       "1669                    0                  0              0           7      0  \n",
       "1692                    0                  0             26         778      0  \n",
       "1732                    0                  0              4         209      0  \n",
       "1746                    0                  0              1          56      0  \n",
       "1771                    0                  0             31          46      0  \n",
       "1812                    3                  1              9         214      0  \n",
       "1819                    0                  0              7          22      0  \n",
       "1866                    0                  0              1          97      0  \n",
       "1935                    0                  0              4         704      0  \n",
       "1964                    0                  0              9         285      0  \n",
       "2009                    0                  0              4          40      0  \n",
       "2024                    0                  1              7         108      0  \n",
       "2032                    3                  0              6          25      0  \n",
       "2051                    0                  0             41         853      0  \n",
       "2081                    0                  0             26         937      0  \n",
       "2088                    1                  5             23         409      0  \n",
       "2118                    0                  0             10         157      0  \n",
       "2353                    0                  0              2          88      0  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the false positive predictions\n",
    "wrong_pred[wrong_pred['fraud'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a08f6cb",
   "metadata": {},
   "source": [
    "The messages the model falsely identified as fraud seem to largely relate to banking, security, or a government institution. This makes sense since many fraud emails tend to falsely identify themselves as coming from one of these institutions or organizations. It may be difficult to prevent the model from making these types of identifications but it is possible a model like XG-Boost could be used to prevent errors such as this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba6354f",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e9077",
   "metadata": {},
   "source": [
    "Now that the model has been evaluated, the fitted vectorizer and best model should be saved for further use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "fb98f302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the column transformer\n",
    "cv_col_transf = cv_transf.fit(X_remainder, y_remainder)\n",
    "# Transform the remainder set\n",
    "X_rem_transf = cv_col_transf.transform(X_remainder)\n",
    "# Fit logistic regression model with best parameters\n",
    "best_dec_tree = DecisionTreeClassifier(max_depth = 19).fit(X_rem_transf, y_remainder)\n",
    "# Save the fitted transformer to a pickle file\n",
    "with open('./models/count_vec_col_transf.pkl', 'wb') as handle:\n",
    "    pickle.dump(cv_col_transf, handle)\n",
    "# Save the fittted log reg model to a pickle file\n",
    "with open('./models/best_dec_tree.pkl', 'wb') as handle:\n",
    "    pickle.dump(best_dec_tree, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe9177a",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f873d5",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
